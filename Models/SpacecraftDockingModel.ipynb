{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07860aa6-c8c1-41e0-9af8-b2be6281c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\utils\\framework.py:180: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'poliastro.plotting.matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mEnvironment_Creator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Environments_enum\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpoliastro\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrbitPlotter2D\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'poliastro.plotting.matplotlib'"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.wrappers import RescaleAction\n",
    "from gymnasium.envs import register\n",
    "\n",
    "import torch\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env\n",
    "from ray.air import RunConfig\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.ppo import PPO\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from ray.rllib.algorithms.algorithm_config import AlgorithmConfig\n",
    "\n",
    "from stable_baselines3 import PPO as PPO_sb3\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Import modules\n",
    "from Environment_Creator import env_creator\n",
    "from Environment_Creator import Environments_enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from poliastro.plotting.matplotlib import OrbitPlotter2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7c4bfe-cc04-43e6-8c2d-40127ddb2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cb7375-644e-426f-b5da-31239664bda6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_thrust' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m      4\u001b[0m     action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m----> 5\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Done: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdone\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "File \u001b[1;32m~\\Desktop\\Softuni\\Deep Learning\\Project\\Models\\SpacecraftDockingEnv.py:72\u001b[0m, in \u001b[0;36mSpacecraftDockingEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     69\u001b[0m thrust \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(action, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Limit thrust values\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Apply thrust (scaled by max thrust)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m thrust \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(action, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[43mmax_thrust\u001b[49m\n\u001b[0;32m     73\u001b[0m vx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m thrust[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m     74\u001b[0m vy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m thrust[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_thrust' is not defined"
     ]
    }
   ],
   "source": [
    "env = env_creator(Environments_enum.Docking.value)\n",
    "obs, info = env.reset()\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    print(f\"Step Reward: {reward}, Done: {done}\")\n",
    "    if done:\n",
    "        print(\"Episode finished!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076c755-5795-491a-b3ff-77493ca16b1e",
   "metadata": {},
   "source": [
    "Negative Rewards:\n",
    "\n",
    "The rewards are consistently negative, ranging from approximately -5.0 to -5.08. This indicates that the agent is not making progress toward docking and is being penalized for factors like distance, velocity, orientation, and fuel usage. The episode terminated with a significant penalty (Step Reward: -105.04660590061656, Done: True).\n",
    "\n",
    "Iteration 0: reward = -874.9319077697345\n",
    "Iteration 1: reward = -883.2991542661196\n",
    "Iteration 2: reward = -894.7726563013313\n",
    "Iteration 3: reward = -897.2621181717333\n",
    "Iteration 4: reward = -902.9811782013743\n",
    "Iteration 5: reward = -902.9323393113254\n",
    "Iteration 6: reward = -896.381981113382\n",
    "Iteration 7: reward = -891.0903634893743\n",
    "Iteration 8: reward = -885.130290251768\n",
    "Iteration 9: reward = -880.9021828443313\n",
    "Iteration 10: reward = -882.3590025921812\n",
    "Iteration 11: reward = -881.0212335095692\n",
    "Iteration 12: reward = -880.7137428521378\n",
    "Iteration 13: reward = -879.7922666245744\n",
    "Iteration 14: reward = -877.0553465643769\n",
    "Iteration 15: reward = -878.6386467195485\n",
    "Iteration 16: reward = -882.5826651526473\n",
    "Iteration 17: reward = -885.1248865746318\n",
    "Iteration 18: reward = -890.8558077303621\n",
    "Iteration 19: reward = -896.7296670570367\n",
    "Iteration 20: reward = -900.3710521450374\n",
    "Iteration 21: reward = -903.4963432088731\n",
    "Iteration 22: reward = -903.6208917163982\n",
    "Iteration 23: reward = -902.5116290917001\n",
    "Iteration 24: reward = -907.0092657350216\n",
    "Iteration 25: reward = -914.1737386438025\n",
    "Iteration 26: reward = -924.592101995897\n",
    "Iteration 27: reward = -933.1690004306192\n",
    "Iteration 28: reward = -935.0036832729257\n",
    "\n",
    "Initial tests show that there might not be any positive rewards, so the reward function needs to be refactored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780e5f62-d46f-4e81-987d-a125a8f545a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "result = algo.train()\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7fc04e-413e-493a-9fa9-a7019b3ca9d2",
   "metadata": {},
   "source": [
    "The distance threshold (< 0.1) is too small.\n",
    "Spacecraft might never reach exactly that position. Updating 0.5 or 1.0 instead.\n",
    "Fuel may not be decreasing fast enough.\n",
    "If np.linalg.norm(thrust) * 0.01 is too small, fuel might last too long.\n",
    "\n",
    "Adjusted reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5635968f-340f-4e1c-9b0d-e65208be06ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 13:53:06,398\tWARNING deprecation.py:50 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!\n",
      "2025-02-04 13:53:06,405\tWARNING algorithm_config.py:4702 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:579: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-02-04 13:53:10,517\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=34420)\u001b[0m C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=34420)\u001b[0m   gym.logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=34420)\u001b[0m C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=34420)\u001b[0m   gym.logger.warn(\n",
      "C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=34420)\u001b[0m 2025-02-04 13:53:17,674\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-02-04 13:53:18,039\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-02-04 13:53:18,079\tWARNING algorithm_config.py:4702 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-02-04 13:53:18,141\tWARNING rl_module.py:419 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
      "2025-02-04 13:53:19,529\tINFO trainable.py:161 -- Trainable.setup took 13.084 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2025-02-04 13:53:19,535\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: reward = -859.4403044390851\n",
      "Iteration 1: reward = -858.6353767912351\n",
      "Iteration 2: reward = -859.4736073241496\n",
      "Iteration 3: reward = -858.6872924779195\n",
      "Iteration 4: reward = -857.4062494890251\n",
      "Iteration 5: reward = -856.4162910985478\n",
      "Iteration 6: reward = -855.5460703368261\n",
      "Iteration 7: reward = -854.8011551179528\n",
      "Iteration 8: reward = -854.0535589047805\n",
      "Iteration 9: reward = -852.9985558207298\n",
      "Iteration 10: reward = -851.746866860893\n",
      "Iteration 11: reward = -851.1594997007124\n",
      "Iteration 12: reward = -850.6701021385853\n",
      "Iteration 13: reward = -851.0826938358919\n",
      "Iteration 14: reward = -850.6361244536306\n",
      "Iteration 15: reward = -851.2486215248474\n",
      "Iteration 16: reward = -851.6948416949766\n",
      "Iteration 17: reward = -851.6024269626531\n",
      "Iteration 18: reward = -851.6567324672465\n",
      "Iteration 19: reward = -852.3169407495485\n",
      "Iteration 20: reward = -853.1113546497104\n",
      "Iteration 21: reward = -853.8038479822999\n",
      "Iteration 22: reward = -854.4460440833133\n",
      "Iteration 23: reward = -854.4838290740112\n",
      "Iteration 24: reward = -854.0728912717052\n",
      "Iteration 25: reward = -854.5177799950453\n",
      "Iteration 26: reward = -854.6585753679922\n",
      "Iteration 27: reward = -854.9519513922662\n",
      "Iteration 28: reward = -854.7999664305373\n",
      "Iteration 29: reward = -855.3401393991334\n",
      "Iteration 30: reward = -856.0293613581823\n",
      "Iteration 31: reward = -856.5740086279299\n",
      "Iteration 32: reward = -857.2687623320276\n",
      "Iteration 33: reward = -858.207780637771\n",
      "Iteration 34: reward = -859.0466527096268\n",
      "Iteration 35: reward = -859.3429427533705\n",
      "Iteration 36: reward = -859.5912592530462\n",
      "Iteration 37: reward = -860.301172518427\n",
      "Iteration 38: reward = -861.1624581152984\n",
      "Iteration 39: reward = -862.6198597355178\n",
      "Iteration 40: reward = -863.4233555139368\n",
      "Iteration 41: reward = -864.4200407470927\n",
      "Iteration 42: reward = -865.4713879144921\n",
      "Iteration 43: reward = -866.9264426961252\n",
      "Iteration 44: reward = -867.5760105556376\n",
      "Iteration 45: reward = -867.7755063995769\n",
      "Iteration 46: reward = -867.9295648411427\n",
      "Iteration 47: reward = -867.4767176578666\n",
      "Iteration 48: reward = -867.4733203208033\n",
      "Iteration 49: reward = -867.3737430827844\n",
      "Iteration 50: reward = -867.4780399488222\n",
      "Iteration 51: reward = -868.2776540884948\n",
      "Iteration 52: reward = -869.5794021513423\n",
      "Iteration 53: reward = -870.5795073460092\n",
      "Iteration 54: reward = -871.8809023002243\n",
      "Iteration 55: reward = -874.133591495856\n",
      "Iteration 56: reward = -875.3818052647858\n",
      "Iteration 57: reward = -877.0361731824116\n",
      "Iteration 58: reward = -878.8388837171227\n",
      "Iteration 59: reward = -880.1429746106339\n",
      "Iteration 60: reward = -881.6915714645552\n",
      "Iteration 61: reward = -882.3921723752283\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m algo \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mbuild()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: reward = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv_runners\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_reward_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\tune\\trainable\\trainable.py:328\u001b[0m, in \u001b[0;36mTrainable.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    330\u001b[0m     skipped \u001b[38;5;241m=\u001b[39m skip_exceptions(e)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:999\u001b[0m, in \u001b[0;36mAlgorithm.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39menable_env_runner_and_connector_v2:\n\u001b[1;32m--> 999\u001b[0m         train_results, train_iter_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1001\u001b[0m         (\n\u001b[0;32m   1002\u001b[0m             train_results,\n\u001b[0;32m   1003\u001b[0m             train_iter_ctx,\n\u001b[0;32m   1004\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_one_training_iteration_old_api_stack()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:3350\u001b[0m, in \u001b[0;36mAlgorithm._run_one_training_iteration\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3348\u001b[0m \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[0;32m   3349\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mlog_time((TIMERS, TRAINING_STEP_TIMER)):\n\u001b[1;32m-> 3350\u001b[0m     training_step_return_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3351\u001b[0m     has_run_once \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3353\u001b[0m \u001b[38;5;66;03m# On the new API stack, results should NOT be returned anymore as\u001b[39;00m\n\u001b[0;32m   3354\u001b[0m \u001b[38;5;66;03m# a dict, but purely logged through the `MetricsLogger` API. This\u001b[39;00m\n\u001b[0;32m   3355\u001b[0m \u001b[38;5;66;03m# way, we make sure to never miss a single stats/counter/timer\u001b[39;00m\n\u001b[0;32m   3356\u001b[0m \u001b[38;5;66;03m# when calling `self.training_step()` more than once within the same\u001b[39;00m\n\u001b[0;32m   3357\u001b[0m \u001b[38;5;66;03m# iteration.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\algorithms\\ppo\\ppo.py:408\u001b[0m, in \u001b[0;36mPPO.training_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m     episodes, env_runner_results \u001b[38;5;241m=\u001b[39m synchronous_parallel_sample(\n\u001b[0;32m    399\u001b[0m         worker_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_runner_group,\n\u001b[0;32m    400\u001b[0m         max_agent_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtotal_train_batch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    405\u001b[0m         _return_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    406\u001b[0m     )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 408\u001b[0m     episodes, env_runner_results \u001b[38;5;241m=\u001b[39m \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_runner_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_env_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_timeout_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_uses_new_env_runners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_env_runner_and_connector_v2\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_return_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Return early if all our workers failed.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m episodes:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\execution\\rollout_ops.py:106\u001b[0m, in \u001b[0;36msynchronous_parallel_sample\u001b[1;34m(worker_set, max_agent_steps, max_env_steps, concat, sample_timeout_s, random_actions, _uses_new_env_runners, _return_metrics)\u001b[0m\n\u001b[0;32m    103\u001b[0m         stats_dicts \u001b[38;5;241m=\u001b[39m [worker_set\u001b[38;5;241m.\u001b[39mlocal_env_runner\u001b[38;5;241m.\u001b[39mget_metrics()]\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     sampled_data \u001b[38;5;241m=\u001b[39m \u001b[43mworker_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_env_runner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrandom_action_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_return_metrics\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrandom_action_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_env_runner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# Nothing was returned (maybe all workers are stalling) or no healthy\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# remote workers left: Break.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# There is no point staying in this loop, since we will not be able to\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# get any new samples if we don't have any healthy remote workers left.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampled_data \u001b[38;5;129;01mor\u001b[39;00m worker_set\u001b[38;5;241m.\u001b[39mnum_healthy_remote_workers() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\env\\env_runner_group.py:932\u001b[0m, in \u001b[0;36mEnvRunnerGroup.foreach_env_runner\u001b[1;34m(self, func, local_env_runner, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_manager\u001b[38;5;241m.\u001b[39mactor_ids():\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m local_result\n\u001b[1;32m--> 932\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhealthy_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_worker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    941\u001b[0m FaultTolerantActorManager\u001b[38;5;241m.\u001b[39mhandle_remote_call_result_errors(\n\u001b[0;32m    942\u001b[0m     remote_results, ignore_ray_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_ray_errors_on_env_runners\n\u001b[0;32m    943\u001b[0m )\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# With application errors handled, return good results.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py:456\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[1;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    450\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_actors(\n\u001b[0;32m    451\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    452\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[0;32m    453\u001b[0m )\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\rllib\\utils\\actor_manager.py:781\u001b[0m, in \u001b[0;36mFaultTolerantActorManager._fetch_result\u001b[1;34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[1;32m--> 781\u001b[0m readies, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     20\u001b[0m     auto_init_ray()\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ray\\_private\\worker.py:3003\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[0;32m   3001\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[0;32m   3002\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m-> 3003\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3008\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3009\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "register_env(\"SpacecraftDocking-v0\", lambda config: env_creator(Environments_enum.Docking.value))\n",
    "\n",
    "# Configure PPO training\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(\"SpacecraftDocking-v0\")\n",
    "    .framework(\"torch\")  # Use PyTorch\n",
    "    .env_runners(num_env_runners=1)  # Reduce for debugging\n",
    "    .training(gamma=0.99, lr=1e-4, train_batch_size=1000)\n",
    "    .resources(num_gpus=0.5)  # Adjust GPU usage\n",
    ")\n",
    "\n",
    "# Train the agent\n",
    "algo = config.build()\n",
    "\n",
    "for i in range(1000):\n",
    "    result = algo.train()\n",
    "\n",
    "    if result.get(\"episode_reward_mean\") != None:\n",
    "        print(f\"Iteration {i}: reward = {result['env_runners']['episode_reward_mean']}\")\n",
    "    \n",
    "    print(f\"Iteration {i}: reward = {result['env_runners']['episode_return_mean']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fdaa9-298d-4b7f-a875-ca20d1cc9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['env_runners']['episode_return_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9905c646-5c1f-4f49-9013-7a1779019033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    result = algo.train()\n",
    "    print(result.get(\"episode_reward_mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc61ee4-bf76-43d5-8d85-d740b9205899",
   "metadata": {},
   "source": [
    "Done condition seems to be too rare.  \n",
    "In 100 steps, only one episode terminated.  \n",
    "Ideally, RL algorithms need more frequent resets to learn effectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfdbe72f-7d87-4246-aaa9-a48df888dabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Reward Mean: None\n"
     ]
    }
   ],
   "source": [
    "result = algo.train()\n",
    "print(\"Episode Reward Mean:\", result.get(\"episode_reward_mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e8a259-4763-4d8b-ad5c-72ec6da84eff",
   "metadata": {},
   "source": [
    "\"Episode Reward Mean: None\": episodes might not be tracked correctly due to long episode lengths or improper resets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae4116-aff4-4937-b43f-bff8c1869511",
   "metadata": {},
   "source": [
    "Currerntly thrust is applyed directly with a constant multiplier (0.05) and constrain using np.clip(action, -1, 1). This can lead to erratic behavior if the action space range isn't properly scaled or if the spacecraft needs more precise control.\n",
    "Improvement:\n",
    "```python\n",
    "# Apply thrust (scaled by max thrust)\n",
    "thrust = np.clip(action, -1, 1) * max_thrust\n",
    "vx += thrust[0] * 0.1\n",
    "vy += thrust[1] * 0.1\n",
    "vz += thrust[2] * 0.1\n",
    "```\n",
    "\n",
    "Add `thrust` and udpate 0.05 to 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b13797f-f095-409b-bc99-eb72a8ef7fa0",
   "metadata": {},
   "source": [
    "Fuel update: The fuel penalty is linear in its current form (-np.linalg.norm(thrust) * 0.01), which might not encourage fuel conservation well enough. Increasing the fuel penalty when fuel is low, introduces an exponential or logarithmic penalty to simulate resource scarcity more realistically.  \n",
    "```python\n",
    "reward_fuel = -np.linalg.norm(thrust) * 0.01 * (fuel + 0.1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1c67e-2dea-4053-9770-b0ae2af123a7",
   "metadata": {},
   "source": [
    "# Simple docking environment\n",
    "#### SimpleDockingEnv:  \n",
    "Simpler 2D version of the environment and no orientation control.\n",
    "\n",
    "Key parameters to optimize:\n",
    "\n",
    "- Discount factor (gamma): **0.99-0.999**\n",
    "\n",
    "- Entropy coefficient: **0.01-0.1**\n",
    "\n",
    "- Learning rate: **1e-5 to 3e-4**\n",
    "\n",
    "- Batch size: **64-2048**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0455c411-7745-44b1-88dc-ba14c27e8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training & Evaluation Process\n",
    "# Create environment\n",
    "env = env_creator(Environments_enum.Docking_simple.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb74b26c-f275-4aa8-8807-3efebbf68936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhech\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Evaluation callback\n",
    "eval_callback = EvalCallback(\n",
    "    env,\n",
    "    eval_freq=10000,\n",
    "    n_eval_episodes=10,\n",
    "    best_model_save_path=\"./best_model\",\n",
    "    deterministic=True\n",
    ")\n",
    "# Initialize PPO model\n",
    "model = PPO_sb3(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-3,  # Increased learning rate\n",
    "    gamma=0.99,\n",
    "    n_steps=2048,\n",
    "    batch_size=512,  # Larger batch size\n",
    "    ent_coef=0.01,  # Higher entropy coefficient\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    tensorboard_log=\"./ppo_docking_tensorboard/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af474b72-00f4-4581-b13d-4f34843b22ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_docking_tensorboard/PPO_6\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | 0.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 1853     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.0563     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1469        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010883335 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 0.295       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.478      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1428        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014194248 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0779      |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    std                  | 0.892       |\n",
      "|    value_loss           | 0.297       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.4       |\n",
      "|    ep_rew_mean          | -0.234     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1389       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01233913 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.61      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.214      |\n",
      "|    n_updates            | 4920       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 0.904      |\n",
      "|    value_loss           | 0.575      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=8528, episode_reward=-0.93 +/- 4.15\n",
      "Episode length: 30.30 +/- 7.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | -0.926      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8528        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009888926 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.204       |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.685       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.017    |\n",
      "| time/              |          |\n",
      "|    fps             | 1329     |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1369        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012641802 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.207      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1410        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008815567 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 0.0654      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -0.365      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1421        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014205427 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.181       |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33.3       |\n",
      "|    ep_rew_mean          | -0.74      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1411       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00880555 |\n",
      "|    clip_fraction        | 0.0806     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.6       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.148      |\n",
      "|    n_updates            | 4970       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 0.903      |\n",
      "|    value_loss           | 0.521      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=18528, episode_reward=0.01 +/- 2.35\n",
      "Episode length: 30.00 +/- 3.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30           |\n",
      "|    mean_reward          | 0.0148       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073942663 |\n",
      "|    clip_fraction        | 0.0576       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.61        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.267        |\n",
      "|    n_updates            | 4980         |\n",
      "|    policy_gradient_loss | -0.0086      |\n",
      "|    std                  | 0.899        |\n",
      "|    value_loss           | 0.786        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.391   |\n",
      "| time/              |          |\n",
      "|    fps             | 1408     |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31         |\n",
      "|    ep_rew_mean          | -0.198     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1399       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00574184 |\n",
      "|    clip_fraction        | 0.0819     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.61      |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.671      |\n",
      "|    n_updates            | 4990       |\n",
      "|    policy_gradient_loss | -0.00742   |\n",
      "|    std                  | 0.907      |\n",
      "|    value_loss           | 1.8        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.468      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010892676 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0658      |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.89        |\n",
      "|    value_loss           | 0.302       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.209       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1391         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071582682 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 5010         |\n",
      "|    policy_gradient_loss | -0.00974     |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 0.579        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=28528, episode_reward=2.81 +/- 5.39\n",
      "Episode length: 25.90 +/- 7.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.9        |\n",
      "|    mean_reward          | 2.81        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 28528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012294204 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.88        |\n",
      "|    value_loss           | 0.428       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.579   |\n",
      "| time/              |          |\n",
      "|    fps             | 1382     |\n",
      "|    iterations      | 14       |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 28672    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.5       |\n",
      "|    ep_rew_mean          | 0.148      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1377       |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01195411 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.55      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.325      |\n",
      "|    n_updates            | 5030       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 0.879      |\n",
      "|    value_loss           | 0.66       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.297      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1372        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013737192 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.886       |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | -0.436     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1380       |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 25         |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01272777 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.57      |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.107      |\n",
      "|    n_updates            | 5050       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    std                  | 0.888      |\n",
      "|    value_loss           | 0.415      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -1.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1393        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018316122 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.345       |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 0.714       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38528, episode_reward=0.96 +/- 7.54\n",
      "Episode length: 29.80 +/- 15.51\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.8       |\n",
      "|    mean_reward          | 0.958      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 38528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01068172 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.56      |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.12       |\n",
      "|    n_updates            | 5070       |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 0.88       |\n",
      "|    value_loss           | 0.583      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.887   |\n",
      "| time/              |          |\n",
      "|    fps             | 1384     |\n",
      "|    iterations      | 19       |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 38912    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.227       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1412        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019017497 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 0.514       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | 0.0571       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1407         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126438225 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0743       |\n",
      "|    n_updates            | 5090         |\n",
      "|    policy_gradient_loss | -0.00795     |\n",
      "|    std                  | 0.877        |\n",
      "|    value_loss           | 0.252        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | -0.458       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1402         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142335575 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.56        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.178        |\n",
      "|    n_updates            | 5100         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 0.894        |\n",
      "|    value_loss           | 0.664        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.976      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1397        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009950812 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.287       |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 0.811       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=48528, episode_reward=-2.59 +/- 3.59\n",
      "Episode length: 32.80 +/- 5.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -2.59       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 48528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010713743 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.314       |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 0.89        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.23    |\n",
      "| time/              |          |\n",
      "|    fps             | 1412     |\n",
      "|    iterations      | 24       |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 49152    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.0897     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1408        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010547271 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.749       |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.877       |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.0363      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1403        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015700772 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.52       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.274       |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.727       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.597      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014366628 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00208    |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.381      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1395        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013961289 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.375       |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.861       |\n",
      "|    value_loss           | 0.71        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=58528, episode_reward=-1.46 +/- 3.56\n",
      "Episode length: 32.10 +/- 4.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.1        |\n",
      "|    mean_reward          | -1.46       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 58528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009293967 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.239       |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.872       |\n",
      "|    value_loss           | 0.71        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | 0.261    |\n",
      "| time/              |          |\n",
      "|    fps             | 1391     |\n",
      "|    iterations      | 29       |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 59392    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.103      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013932751 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.077       |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.566      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1402        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014798874 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 0.493       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | -1.71       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012861966 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.204       |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 0.493       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -0.974      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1401        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011444071 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.437       |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=68528, episode_reward=-2.69 +/- 5.14\n",
      "Episode length: 35.10 +/- 11.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.1        |\n",
      "|    mean_reward          | -2.69       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 68528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012454614 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00129     |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.885       |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.184   |\n",
      "| time/              |          |\n",
      "|    fps             | 1394     |\n",
      "|    iterations      | 34       |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 69632    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.564       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1391        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011912996 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.259       |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.897       |\n",
      "|    value_loss           | 0.689       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.1       |\n",
      "|    ep_rew_mean          | -0.593     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1388       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01158368 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.59      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0118     |\n",
      "|    n_updates            | 5240       |\n",
      "|    policy_gradient_loss | -0.00821   |\n",
      "|    std                  | 0.899      |\n",
      "|    value_loss           | 0.217      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.457      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1386        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010680478 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 0.348       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.648      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1389        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014062462 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 0.813       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=78528, episode_reward=1.68 +/- 2.55\n",
      "Episode length: 29.00 +/- 3.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 1.68        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 78528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012830826 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0809      |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 0.331       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.3     |\n",
      "|    ep_rew_mean     | -1.41    |\n",
      "| time/              |          |\n",
      "|    fps             | 1384     |\n",
      "|    iterations      | 39       |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 79872    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | 0.103       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1392        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009538349 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.355       |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    std                  | 0.891       |\n",
      "|    value_loss           | 0.874       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.127      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1393        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013812826 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.227       |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 0.592       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.669      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1389        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011732095 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 0.651       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -1.39       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011250523 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 0.425       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=88528, episode_reward=-0.71 +/- 7.37\n",
      "Episode length: 29.50 +/- 9.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.5        |\n",
      "|    mean_reward          | -0.708      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 88528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014312312 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0468      |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.176   |\n",
      "| time/              |          |\n",
      "|    fps             | 1384     |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.204      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1388        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009184795 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0195      |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.762      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1387        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012385113 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.233       |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 0.641       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.972      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1385        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015265698 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 0.0479      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.103       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1384        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009440879 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 0.469       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=98528, episode_reward=-1.43 +/- 4.64\n",
      "Episode length: 31.80 +/- 4.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.8        |\n",
      "|    mean_reward          | -1.43       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 98528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013693519 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.268       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.9     |\n",
      "|    ep_rew_mean     | 0.424    |\n",
      "| time/              |          |\n",
      "|    fps             | 1380     |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.506      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1379        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012093681 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.354       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.173      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1377        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013330832 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010934534 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=108528, episode_reward=-0.79 +/- 5.60\n",
      "Episode length: 29.70 +/- 8.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | -0.787      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 108528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099054 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.631       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.756   |\n",
      "| time/              |          |\n",
      "|    fps             | 1375     |\n",
      "|    iterations      | 53       |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 108544   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.548       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1373        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012863444 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.788       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.39       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1372        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011431543 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00932     |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.899       |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1374        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011541465 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.899       |\n",
      "|    value_loss           | 0.585       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.124      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013829639 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.32        |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 0.735       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=118528, episode_reward=-1.98 +/- 4.94\n",
      "Episode length: 32.00 +/- 9.20\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 32       |\n",
      "|    mean_reward          | -1.98    |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 118528   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.009988 |\n",
      "|    clip_fraction        | 0.103    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -2.63    |\n",
      "|    explained_variance   | 0.975    |\n",
      "|    learning_rate        | 0.001    |\n",
      "|    loss                 | 0.0841   |\n",
      "|    n_updates            | 5460     |\n",
      "|    policy_gradient_loss | -0.0109  |\n",
      "|    std                  | 0.923    |\n",
      "|    value_loss           | 0.342    |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | 0.106    |\n",
      "| time/              |          |\n",
      "|    fps             | 1382     |\n",
      "|    iterations      | 58       |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 118784   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.366      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1379        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018029409 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.435       |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1377        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011469869 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.478       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1381        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013110302 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.283       |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 0.789       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.035      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1380        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498051 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128528, episode_reward=-0.08 +/- 6.17\n",
      "Episode length: 30.50 +/- 8.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.5        |\n",
      "|    mean_reward          | -0.0849     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 128528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010621676 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.643       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.23    |\n",
      "| time/              |          |\n",
      "|    fps             | 1378     |\n",
      "|    iterations      | 63       |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 129024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.1       |\n",
      "|    ep_rew_mean          | -0.703     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1378       |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 95         |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01428978 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.66      |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.225      |\n",
      "|    n_updates            | 5520       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 0.93       |\n",
      "|    value_loss           | 0.579      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.187      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1377        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014110641 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.225      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1376        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013283521 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0386     |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 0.914       |\n",
      "|    value_loss           | 0.0534      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.093       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1375        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020027697 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.909       |\n",
      "|    value_loss           | 0.564       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=138528, episode_reward=-2.56 +/- 4.15\n",
      "Episode length: 34.00 +/- 5.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34          |\n",
      "|    mean_reward          | -2.56       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 138528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012705069 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.378       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.0911  |\n",
      "| time/              |          |\n",
      "|    fps             | 1372     |\n",
      "|    iterations      | 68       |\n",
      "|    time_elapsed    | 101      |\n",
      "|    total_timesteps | 139264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.267      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1371        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011272756 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 0.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.049       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1370        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011182193 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.893       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.6       |\n",
      "|    ep_rew_mean          | 0.172      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1369       |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 106        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01603997 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.64      |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.202      |\n",
      "|    n_updates            | 5590       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 0.925      |\n",
      "|    value_loss           | 0.609      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.868      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012617603 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=148528, episode_reward=-3.87 +/- 3.47\n",
      "Episode length: 34.70 +/- 5.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.7        |\n",
      "|    mean_reward          | -3.87       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 148528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013893743 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 0.922       |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.432    |\n",
      "| time/              |          |\n",
      "|    fps             | 1366     |\n",
      "|    iterations      | 73       |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 149504   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.524       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1365        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012767658 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.000311    |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1364        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013735646 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.00903    |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.228      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1364        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016868759 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.924       |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1363        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014053752 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0426      |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=158528, episode_reward=-3.40 +/- 5.03\n",
      "Episode length: 33.70 +/- 7.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.7        |\n",
      "|    mean_reward          | -3.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 158528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009159932 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.42        |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.6     |\n",
      "|    ep_rew_mean     | -1.14    |\n",
      "| time/              |          |\n",
      "|    fps             | 1360     |\n",
      "|    iterations      | 78       |\n",
      "|    time_elapsed    | 117      |\n",
      "|    total_timesteps | 159744   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -0.759      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1360        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014745037 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.412       |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.121       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1360         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084366035 |\n",
      "|    clip_fraction        | 0.0892       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.479        |\n",
      "|    n_updates            | 5680         |\n",
      "|    policy_gradient_loss | -0.00963     |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 1.12         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.728      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1359        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007938364 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0531      |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 0.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.2        |\n",
      "|    ep_rew_mean          | -1.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1359        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011120644 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.276       |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    std                  | 0.946       |\n",
      "|    value_loss           | 0.684       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=168528, episode_reward=-3.55 +/- 4.00\n",
      "Episode length: 35.10 +/- 4.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.1        |\n",
      "|    mean_reward          | -3.55       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 168528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008547537 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 0.798       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -0.703   |\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 83       |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 169984   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.527      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008400749 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 0.676       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.611      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1355        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012506949 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.453       |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.755       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1355         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111522805 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.64        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.172        |\n",
      "|    n_updates            | 5740         |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    std                  | 0.923        |\n",
      "|    value_loss           | 0.517        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | 0.408      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1354       |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01181077 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.64      |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.122      |\n",
      "|    n_updates            | 5750       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 0.905      |\n",
      "|    value_loss           | 0.363      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=178528, episode_reward=0.30 +/- 4.82\n",
      "Episode length: 30.30 +/- 6.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | 0.296       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 178528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010419797 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.045       |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | 0.227    |\n",
      "| time/              |          |\n",
      "|    fps             | 1352     |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 180224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.251      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1351        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015722547 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.466       |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.743       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.178      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013361692 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.507      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013439691 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.763      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013585173 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.422       |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.813       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=188528, episode_reward=2.31 +/- 4.98\n",
      "Episode length: 26.30 +/- 8.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.3        |\n",
      "|    mean_reward          | 2.31        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 188528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012455596 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 0.504       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.342   |\n",
      "| time/              |          |\n",
      "|    fps             | 1352     |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 140      |\n",
      "|    total_timesteps | 190464   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.781      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009507839 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | -1.42       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1358        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012919577 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.394       |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.4        |\n",
      "|    ep_rew_mean          | -0.915      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1357        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008415012 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.289       |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 0.918       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=198528, episode_reward=-0.59 +/- 4.25\n",
      "Episode length: 30.20 +/- 6.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.2         |\n",
      "|    mean_reward          | -0.593       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 198528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077180527 |\n",
      "|    clip_fraction        | 0.0435       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.251        |\n",
      "|    n_updates            | 5850         |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    std                  | 0.948        |\n",
      "|    value_loss           | 0.764        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 97       |\n",
      "|    time_elapsed    | 146      |\n",
      "|    total_timesteps | 198656   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.205       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010881069 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 0.568       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.453      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009974035 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.207       |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.933       |\n",
      "|    value_loss           | 0.702       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.645      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1355        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014514323 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    std                  | 0.924       |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.142      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1355        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010558402 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0827      |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.909       |\n",
      "|    value_loss           | 0.529       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=208528, episode_reward=0.99 +/- 5.83\n",
      "Episode length: 27.80 +/- 8.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.8        |\n",
      "|    mean_reward          | 0.986       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 208528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017545478 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0932      |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.413       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -0.76    |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 102      |\n",
      "|    time_elapsed    | 154      |\n",
      "|    total_timesteps | 208896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.803      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1355        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014861479 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0641      |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.399       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.324      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013163323 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.256       |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.686      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1354        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016044348 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 0.302       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.5      |\n",
      "|    ep_rew_mean          | -0.0647   |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1354      |\n",
      "|    iterations           | 106       |\n",
      "|    time_elapsed         | 160       |\n",
      "|    total_timesteps      | 217088    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0157662 |\n",
      "|    clip_fraction        | 0.141     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.59     |\n",
      "|    explained_variance   | 0.963     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.234     |\n",
      "|    n_updates            | 5940      |\n",
      "|    policy_gradient_loss | -0.0121   |\n",
      "|    std                  | 0.884     |\n",
      "|    value_loss           | 0.681     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=218528, episode_reward=0.21 +/- 5.40\n",
      "Episode length: 30.30 +/- 7.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | 0.214       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 218528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014017521 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    std                  | 0.889       |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.596    |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 107      |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 219136   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | 0.277        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1353         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106331045 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.6         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.249        |\n",
      "|    n_updates            | 5960         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 0.707        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.498       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1353        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011253298 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0223     |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 0.099       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.336       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1352        |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012866518 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.413       |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.901       |\n",
      "|    value_loss           | 0.844       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.4       |\n",
      "|    ep_rew_mean          | -0.00838   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1352       |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 168        |\n",
      "|    total_timesteps      | 227328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01204193 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.62      |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0246    |\n",
      "|    n_updates            | 5990       |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 0.901      |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=228528, episode_reward=0.06 +/- 4.07\n",
      "Episode length: 29.40 +/- 5.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.0601      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 228528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013592469 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 0.0426      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29       |\n",
      "|    ep_rew_mean     | 0.293    |\n",
      "| time/              |          |\n",
      "|    fps             | 1351     |\n",
      "|    iterations      | 112      |\n",
      "|    time_elapsed    | 169      |\n",
      "|    total_timesteps | 229376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.641       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014968012 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0994      |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.911       |\n",
      "|    value_loss           | 0.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.439       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012782915 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.64       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.406       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.133      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012723498 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.922       |\n",
      "|    value_loss           | 0.312       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -1.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012464363 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.676       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=238528, episode_reward=-1.51 +/- 4.78\n",
      "Episode length: 32.70 +/- 6.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.7        |\n",
      "|    mean_reward          | -1.51       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 238528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015904222 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.453       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.0152   |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 117      |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 239616   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.298       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011669298 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.417       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012507668 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.5        |\n",
      "|    ep_rew_mean          | -1.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 182         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012812208 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.422       |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.6        |\n",
      "|    ep_rew_mean          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253226 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.509       |\n",
      "|    n_updates            | 6090        |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=248528, episode_reward=1.23 +/- 7.60\n",
      "Episode length: 30.40 +/- 17.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.4        |\n",
      "|    mean_reward          | 1.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 248528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012307516 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.733       |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.899       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.551    |\n",
      "| time/              |          |\n",
      "|    fps             | 1347     |\n",
      "|    iterations      | 122      |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 249856   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.163       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012259811 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 0.282       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.186      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015052533 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.89        |\n",
      "|    value_loss           | 0.414       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.2       |\n",
      "|    ep_rew_mean          | -0.51      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1348       |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 189        |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01389932 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.58      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.169      |\n",
      "|    n_updates            | 6130       |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 0.897      |\n",
      "|    value_loss           | 0.641      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012764538 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    std                  | 0.903       |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=258528, episode_reward=0.16 +/- 3.65\n",
      "Episode length: 29.90 +/- 6.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.157       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 258528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013800625 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0541      |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.197   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 192      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.526      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014802974 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.281       |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    std                  | 0.899       |\n",
      "|    value_loss           | 0.908       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.177      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014386057 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 0.383       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012701837 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.132      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007316768 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.217       |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    std                  | 0.911       |\n",
      "|    value_loss           | 0.382       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=268528, episode_reward=0.41 +/- 5.61\n",
      "Episode length: 28.10 +/- 9.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.1        |\n",
      "|    mean_reward          | 0.407       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 268528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013465581 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 0.576       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -0.162   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 200      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.416       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016276086 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.683       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.467      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015844537 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0308     |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.0629      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.649      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013627595 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00151    |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.9         |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=278528, episode_reward=-3.01 +/- 5.60\n",
      "Episode length: 35.20 +/- 12.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.2        |\n",
      "|    mean_reward          | -3.01       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013908245 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.61       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.28        |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 0.628       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.904   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 136      |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 278528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.229      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014325596 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 0.446       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.2       |\n",
      "|    ep_rew_mean          | -0.141     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1349       |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01327495 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.69      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0514     |\n",
      "|    n_updates            | 6260       |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    std                  | 0.949      |\n",
      "|    value_loss           | 0.317      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.223       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010433786 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 0.705       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.592       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012872808 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 0.0885      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288528, episode_reward=1.48 +/- 5.35\n",
      "Episode length: 26.10 +/- 9.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.1        |\n",
      "|    mean_reward          | 1.48        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 288528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012468503 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.386       |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.343   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 141      |\n",
      "|    time_elapsed    | 214      |\n",
      "|    total_timesteps | 288768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.0289     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 215         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013810723 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0195     |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 0.0888      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.971      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012804899 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 0.713       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.296      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1351        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 218         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014082898 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.8       |\n",
      "|    ep_rew_mean          | -0.717     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1350       |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 219        |\n",
      "|    total_timesteps      | 296960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00941039 |\n",
      "|    clip_fraction        | 0.08       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.71      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0678     |\n",
      "|    n_updates            | 6330       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 0.305      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=298528, episode_reward=-1.37 +/- 3.30\n",
      "Episode length: 32.60 +/- 3.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.6         |\n",
      "|    mean_reward          | -1.37        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 298528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140851075 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.28         |\n",
      "|    n_updates            | 6340         |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 0.575        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | 0.0497   |\n",
      "| time/              |          |\n",
      "|    fps             | 1349     |\n",
      "|    iterations      | 146      |\n",
      "|    time_elapsed    | 221      |\n",
      "|    total_timesteps | 299008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.228       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018575808 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.431       |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014073976 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 0.604       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.528       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011364849 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 0.692       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.176       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010420514 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.476       |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=308528, episode_reward=1.62 +/- 4.57\n",
      "Episode length: 29.80 +/- 7.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 1.62        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 308528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010617381 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 0.598       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | 0.0708   |\n",
      "| time/              |          |\n",
      "|    fps             | 1347     |\n",
      "|    iterations      | 151      |\n",
      "|    time_elapsed    | 229      |\n",
      "|    total_timesteps | 309248   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -0.633      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013602484 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.719       |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.571      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014255229 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.569       |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.496      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009133312 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.172       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014885921 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.434       |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=318528, episode_reward=-2.60 +/- 3.57\n",
      "Episode length: 33.30 +/- 4.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.3        |\n",
      "|    mean_reward          | -2.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 318528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011593362 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | 0.519    |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 156      |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 319488   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.2        |\n",
      "|    ep_rew_mean          | -0.706      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013103195 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.714       |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | 0.00808     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009778791 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.397       |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.361       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1346         |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 325632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105985105 |\n",
      "|    clip_fraction        | 0.0926       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.75        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0906       |\n",
      "|    n_updates            | 6470         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 0.299        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.34       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009813897 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.86        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=328528, episode_reward=-2.97 +/- 6.12\n",
      "Episode length: 35.60 +/- 12.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.6        |\n",
      "|    mean_reward          | -2.97       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 328528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014342238 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 0.413       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.0265   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 161      |\n",
      "|    time_elapsed    | 244      |\n",
      "|    total_timesteps | 329728   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.499      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010648478 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.611       |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -0.774      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013669245 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.603       |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.633      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010991954 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0687      |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.374       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1351        |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010653937 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    std                  | 0.963       |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=338528, episode_reward=-2.55 +/- 6.56\n",
      "Episode length: 36.30 +/- 15.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 36.3        |\n",
      "|    mean_reward          | -2.55       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 338528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014496342 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0227     |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.0465      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.171   |\n",
      "| time/              |          |\n",
      "|    fps             | 1350     |\n",
      "|    iterations      | 166      |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 339968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.448      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014233538 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0226      |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.417      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016012046 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.254       |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 0.601       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | -0.205    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1349      |\n",
      "|    iterations           | 169       |\n",
      "|    time_elapsed         | 256       |\n",
      "|    total_timesteps      | 346112    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0127403 |\n",
      "|    clip_fraction        | 0.128     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.75     |\n",
      "|    explained_variance   | 0.961     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.322     |\n",
      "|    n_updates            | 6570      |\n",
      "|    policy_gradient_loss | -0.0141   |\n",
      "|    std                  | 0.981     |\n",
      "|    value_loss           | 0.66      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.5         |\n",
      "|    ep_rew_mean          | 0.2          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1353         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102428645 |\n",
      "|    clip_fraction        | 0.08         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.145        |\n",
      "|    n_updates            | 6580         |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 0.465        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=348528, episode_reward=-0.54 +/- 4.99\n",
      "Episode length: 30.40 +/- 6.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.4        |\n",
      "|    mean_reward          | -0.544      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 348528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012723194 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -0.371   |\n",
      "| time/              |          |\n",
      "|    fps             | 1353     |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 258      |\n",
      "|    total_timesteps | 350208   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.000936    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1353        |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014090892 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 0.329       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.328      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1352        |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013912545 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 0.507       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.269      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1352        |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013929898 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.319       |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 0.809       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.78        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1352         |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148481745 |\n",
      "|    clip_fraction        | 0.09         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0321       |\n",
      "|    n_updates            | 6630         |\n",
      "|    policy_gradient_loss | -0.00816     |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 0.194        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=358528, episode_reward=0.67 +/- 3.70\n",
      "Episode length: 29.90 +/- 6.41\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.9       |\n",
      "|    mean_reward          | 0.67       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 358528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01412499 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.77      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.316      |\n",
      "|    n_updates            | 6640       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 0.985      |\n",
      "|    value_loss           | 0.711      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.716   |\n",
      "| time/              |          |\n",
      "|    fps             | 1351     |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 266      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.308      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1351        |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010261631 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 0.745       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.309       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1350         |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 364544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132213645 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.184        |\n",
      "|    n_updates            | 6660         |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 0.452        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.411      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1350        |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011500736 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.387       |\n",
      "|    n_updates            | 6670        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.879       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=368528, episode_reward=-2.99 +/- 4.55\n",
      "Episode length: 34.10 +/- 6.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 34.1         |\n",
      "|    mean_reward          | -2.99        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 368528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135815265 |\n",
      "|    clip_fraction        | 0.0986       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0325       |\n",
      "|    n_updates            | 6680         |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 0.232        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.118    |\n",
      "| time/              |          |\n",
      "|    fps             | 1350     |\n",
      "|    iterations      | 180      |\n",
      "|    time_elapsed    | 273      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.0129      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1349         |\n",
      "|    iterations           | 181          |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 370688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136011485 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.124        |\n",
      "|    n_updates            | 6690         |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 0.458        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.921      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010315305 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 0.447       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.541      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016622132 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0325     |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 0.0635      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.169      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017091844 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 0.438       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=378528, episode_reward=1.77 +/- 2.79\n",
      "Episode length: 27.20 +/- 4.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.2        |\n",
      "|    mean_reward          | 1.77        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 378528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014196417 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0978      |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.4     |\n",
      "|    ep_rew_mean     | 0.845    |\n",
      "| time/              |          |\n",
      "|    fps             | 1349     |\n",
      "|    iterations      | 185      |\n",
      "|    time_elapsed    | 280      |\n",
      "|    total_timesteps | 378880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.5        |\n",
      "|    ep_rew_mean          | 0.939       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015482383 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00493    |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 0.0945      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.258       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009291326 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 0.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.562       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013931415 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0938      |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.393       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.755      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012760671 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0979      |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 0.313       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=388528, episode_reward=-1.33 +/- 4.54\n",
      "Episode length: 30.90 +/- 6.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.9        |\n",
      "|    mean_reward          | -1.33       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 388528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018981447 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.288       |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 0.739       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.912   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 190      |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 389120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013487679 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 0.547       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011836549 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0223     |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.546      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014718552 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 0.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014457485 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00902     |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=398528, episode_reward=-0.86 +/- 4.36\n",
      "Episode length: 31.70 +/- 6.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.7        |\n",
      "|    mean_reward          | -0.857      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 398528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013185197 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.617       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.581   |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 195      |\n",
      "|    time_elapsed    | 296      |\n",
      "|    total_timesteps | 399360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.435      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008727334 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.746       |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 1.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.26        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013231551 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 0.602       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.228      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011244034 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.299       |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 0.526       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.765      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011387388 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.594       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=408528, episode_reward=-0.06 +/- 3.43\n",
      "Episode length: 30.60 +/- 6.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.6        |\n",
      "|    mean_reward          | -0.0644     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 408528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014406139 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.388       |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.982       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -0.9     |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 200      |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 409600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.994      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010736439 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.235       |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 0.598       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.809      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010479998 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0229      |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.584      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011039445 |\n",
      "|    clip_fraction        | 0.0719      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0882      |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.872      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012792946 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00598    |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=418528, episode_reward=0.64 +/- 3.76\n",
      "Episode length: 29.10 +/- 4.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.1        |\n",
      "|    mean_reward          | 0.636       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 418528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015823107 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 0.455       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.512   |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 205      |\n",
      "|    time_elapsed    | 311      |\n",
      "|    total_timesteps | 419840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.406      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 313         |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013647797 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 0.429       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.451      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012067086 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.0447      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011232664 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 0.767       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.5       |\n",
      "|    ep_rew_mean          | 0.187      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1346       |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01376525 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.74      |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00977    |\n",
      "|    n_updates            | 6970       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 0.963      |\n",
      "|    value_loss           | 0.14       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=428528, episode_reward=1.86 +/- 4.91\n",
      "Episode length: 27.20 +/- 8.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.2        |\n",
      "|    mean_reward          | 1.86        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 428528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011795092 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0886      |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 0.426       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.52     |\n",
      "| time/              |          |\n",
      "|    fps             | 1345     |\n",
      "|    iterations      | 210      |\n",
      "|    time_elapsed    | 319      |\n",
      "|    total_timesteps | 430080   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.189       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013342369 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 0.523       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.109      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1344        |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011737622 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0939      |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 0.434       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.289       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011800788 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 0.631       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.0167     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017965918 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.73       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 0.639       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=438528, episode_reward=0.02 +/- 4.44\n",
      "Episode length: 31.10 +/- 7.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.1        |\n",
      "|    mean_reward          | 0.0157      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 438528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012574602 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.956       |\n",
      "|    value_loss           | 0.435       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.526   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 326      |\n",
      "|    total_timesteps | 440320   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.9       |\n",
      "|    ep_rew_mean          | 0.402      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1348       |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00869593 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.72      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.172      |\n",
      "|    n_updates            | 7040       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 0.961      |\n",
      "|    value_loss           | 0.813      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.177      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010962367 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 0.0578      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.6       |\n",
      "|    ep_rew_mean          | -0.33      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1348       |\n",
      "|    iterations           | 218        |\n",
      "|    time_elapsed         | 331        |\n",
      "|    total_timesteps      | 446464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01537512 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.72      |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0866     |\n",
      "|    n_updates            | 7060       |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 0.964      |\n",
      "|    value_loss           | 0.258      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.494      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426835 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0798      |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.26        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=448528, episode_reward=-0.29 +/- 3.45\n",
      "Episode length: 30.00 +/- 5.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.288      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 448528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014468865 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 0.671       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | -0.0812  |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 334      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.198      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013215221 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00975     |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.9      |\n",
      "|    ep_rew_mean          | 0.0161    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1348      |\n",
      "|    iterations           | 222       |\n",
      "|    time_elapsed         | 337       |\n",
      "|    total_timesteps      | 454656    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0138231 |\n",
      "|    clip_fraction        | 0.113     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.77     |\n",
      "|    explained_variance   | 0.982     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.00488   |\n",
      "|    n_updates            | 7100      |\n",
      "|    policy_gradient_loss | -0.0113   |\n",
      "|    std                  | 0.979     |\n",
      "|    value_loss           | 0.257     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.0684      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1348         |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 456704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073786476 |\n",
      "|    clip_fraction        | 0.0743       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.218        |\n",
      "|    n_updates            | 7110         |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 0.651        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=458528, episode_reward=0.59 +/- 4.06\n",
      "Episode length: 29.40 +/- 5.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.587       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 458528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016420452 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.761   |\n",
      "| time/              |          |\n",
      "|    fps             | 1347     |\n",
      "|    iterations      | 224      |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 458752   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.375      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014832245 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0937      |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011296129 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 0.0578      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.218       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014480145 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.574       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.733       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013490275 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00308     |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=468528, episode_reward=2.08 +/- 3.19\n",
      "Episode length: 25.60 +/- 5.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.6        |\n",
      "|    mean_reward          | 2.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 468528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014176599 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00615    |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.385   |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 229      |\n",
      "|    time_elapsed    | 348      |\n",
      "|    total_timesteps | 468992   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.531      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014367353 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.526       |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 0.831       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | 0.745       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010338051 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 0.927       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.0185     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009344108 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 0.378       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013960767 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.248       |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 0.607       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=478528, episode_reward=1.59 +/- 5.03\n",
      "Episode length: 27.30 +/- 7.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.3        |\n",
      "|    mean_reward          | 1.59        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 478528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014219751 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.981       |\n",
      "|    value_loss           | 0.621       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -1.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 234      |\n",
      "|    time_elapsed    | 355      |\n",
      "|    total_timesteps | 479232   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.887      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 357         |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013071943 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 0.595       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.452       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012971859 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.502       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.642       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013357884 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0283      |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011448897 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 0.7         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=488528, episode_reward=-3.27 +/- 3.44\n",
      "Episode length: 33.40 +/- 4.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.4        |\n",
      "|    mean_reward          | -3.27       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 488528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010146558 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 0.355       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.879   |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 239      |\n",
      "|    time_elapsed    | 363      |\n",
      "|    total_timesteps | 489472   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.0248     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012144747 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.349       |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.457      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008987742 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.88       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -0.99       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008633294 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.624       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.593      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011759085 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.446       |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=498528, episode_reward=0.20 +/- 4.15\n",
      "Episode length: 31.20 +/- 6.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.2        |\n",
      "|    mean_reward          | 0.205       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 498528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010076506 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.414       |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.873       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.48    |\n",
      "| time/              |          |\n",
      "|    fps             | 1345     |\n",
      "|    iterations      | 244      |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 499712   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012610415 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0926      |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.7        |\n",
      "|    ep_rew_mean          | -1.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011986446 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.569       |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.958       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -0.458      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013111103 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.91       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.5         |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007996253 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.91       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.41        |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.912       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=508528, episode_reward=-0.79 +/- 3.41\n",
      "Episode length: 30.20 +/- 5.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.2        |\n",
      "|    mean_reward          | -0.786      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 508528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012193741 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.441       |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.174   |\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 249      |\n",
      "|    time_elapsed    | 378      |\n",
      "|    total_timesteps | 509952   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.465      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016144002 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.291       |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.842       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.487      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015215878 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 7390        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.1       |\n",
      "|    ep_rew_mean          | -0.741     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1348       |\n",
      "|    iterations           | 252        |\n",
      "|    time_elapsed         | 382        |\n",
      "|    total_timesteps      | 516096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01170939 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.93      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.269      |\n",
      "|    n_updates            | 7400       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    std                  | 1.07       |\n",
      "|    value_loss           | 0.689      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | 0.0752     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1348       |\n",
      "|    iterations           | 253        |\n",
      "|    time_elapsed         | 384        |\n",
      "|    total_timesteps      | 518144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00817859 |\n",
      "|    clip_fraction        | 0.0688     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.94      |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.377      |\n",
      "|    n_updates            | 7410       |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 1.03       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=518528, episode_reward=1.06 +/- 4.51\n",
      "Episode length: 28.70 +/- 7.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.7        |\n",
      "|    mean_reward          | 1.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 518528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011023485 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.587       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.632   |\n",
      "| time/              |          |\n",
      "|    fps             | 1347     |\n",
      "|    iterations      | 254      |\n",
      "|    time_elapsed    | 386      |\n",
      "|    total_timesteps | 520192   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.394      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 387         |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011849738 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.685       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015793202 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.391       |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.893       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 0.276        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1347         |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 390          |\n",
      "|    total_timesteps      | 526336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105076395 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.98        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 7450         |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.64         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.0889     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010607379 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.402       |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=528528, episode_reward=0.93 +/- 5.70\n",
      "Episode length: 28.40 +/- 7.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.4        |\n",
      "|    mean_reward          | 0.927       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 528528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010796914 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.472       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.48    |\n",
      "| time/              |          |\n",
      "|    fps             | 1347     |\n",
      "|    iterations      | 259      |\n",
      "|    time_elapsed    | 393      |\n",
      "|    total_timesteps | 530432   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015616706 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.538       |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.932       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.582       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013545696 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.2       |\n",
      "|    ep_rew_mean          | 0.356      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1348       |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 397        |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01630254 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.97      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.161      |\n",
      "|    n_updates            | 7500       |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 0.452      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=538528, episode_reward=-1.46 +/- 5.11\n",
      "Episode length: 35.40 +/- 14.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.4        |\n",
      "|    mean_reward          | -1.46       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 538528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010283212 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0898      |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.614    |\n",
      "| time/              |          |\n",
      "|    fps             | 1347     |\n",
      "|    iterations      | 263      |\n",
      "|    time_elapsed    | 399      |\n",
      "|    total_timesteps | 538624   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.561      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015274322 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0691      |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.202      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009326943 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.411       |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1348        |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013050036 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0563      |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.67       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014888207 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.671       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=548528, episode_reward=0.45 +/- 4.26\n",
      "Episode length: 29.90 +/- 6.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.9         |\n",
      "|    mean_reward          | 0.446        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 548528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075919526 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.03        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.186        |\n",
      "|    n_updates            | 7560         |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.417        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.94    |\n",
      "| time/              |          |\n",
      "|    fps             | 1347     |\n",
      "|    iterations      | 268      |\n",
      "|    time_elapsed    | 407      |\n",
      "|    total_timesteps | 548864   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.192      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1348       |\n",
      "|    iterations           | 269        |\n",
      "|    time_elapsed         | 408        |\n",
      "|    total_timesteps      | 550912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01560867 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.05      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 7570       |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 0.355      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.204       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011057618 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0441      |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.297       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.402       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016931087 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.03       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0338      |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.00972    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1347        |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014346155 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.04       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00499     |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=558528, episode_reward=-0.44 +/- 7.28\n",
      "Episode length: 32.10 +/- 15.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.1        |\n",
      "|    mean_reward          | -0.437      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 558528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016998556 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.285   |\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 273      |\n",
      "|    time_elapsed    | 415      |\n",
      "|    total_timesteps | 559104   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.0686      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 561152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012279087 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.479       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010650475 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0858      |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.416       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.371       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018798444 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.375       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.192      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015263712 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0962      |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=568528, episode_reward=2.00 +/- 5.04\n",
      "Episode length: 26.80 +/- 8.06\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 26.8       |\n",
      "|    mean_reward          | 2          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 568528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01229904 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.98      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.000802  |\n",
      "|    n_updates            | 7660       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 0.136      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.9     |\n",
      "|    ep_rew_mean     | 0.519    |\n",
      "| time/              |          |\n",
      "|    fps             | 1345     |\n",
      "|    iterations      | 278      |\n",
      "|    time_elapsed    | 423      |\n",
      "|    total_timesteps | 569344   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.2      |\n",
      "|    ep_rew_mean          | 0.511     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1345      |\n",
      "|    iterations           | 279       |\n",
      "|    time_elapsed         | 424       |\n",
      "|    total_timesteps      | 571392    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0121627 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.96     |\n",
      "|    explained_variance   | 0.974     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0909    |\n",
      "|    n_updates            | 7670      |\n",
      "|    policy_gradient_loss | -0.0137   |\n",
      "|    std                  | 1.07      |\n",
      "|    value_loss           | 0.362     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.2       |\n",
      "|    ep_rew_mean          | -0.227     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1344       |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 426        |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185295 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.94      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.18       |\n",
      "|    n_updates            | 7680       |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 0.63       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.382       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012154754 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00109    |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.452       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014230438 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.94       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 7700        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=578528, episode_reward=0.42 +/- 3.82\n",
      "Episode length: 29.90 +/- 4.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.423       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 578528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016722897 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.95       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.471   |\n",
      "| time/              |          |\n",
      "|    fps             | 1345     |\n",
      "|    iterations      | 283      |\n",
      "|    time_elapsed    | 430      |\n",
      "|    total_timesteps | 579584   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.412      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015707865 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.96       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 0.698       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010562999 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.97       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.45        |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.154       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012579733 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.468       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.155      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1346        |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021277806 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=588528, episode_reward=0.11 +/- 3.02\n",
      "Episode length: 31.70 +/- 6.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.7        |\n",
      "|    mean_reward          | 0.113       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 588528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011419367 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.654       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.109   |\n",
      "| time/              |          |\n",
      "|    fps             | 1345     |\n",
      "|    iterations      | 288      |\n",
      "|    time_elapsed    | 438      |\n",
      "|    total_timesteps | 589824   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.00238    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010626752 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.569       |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.31        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1345         |\n",
      "|    iterations           | 290          |\n",
      "|    time_elapsed         | 441          |\n",
      "|    total_timesteps      | 593920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131200785 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.99        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.116        |\n",
      "|    n_updates            | 7780         |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 1.08         |\n",
      "|    value_loss           | 0.434        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1345        |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 442         |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012498259 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.317       |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.864       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.64       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1344        |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010604783 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3          |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.28        |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.575       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=598528, episode_reward=0.68 +/- 5.06\n",
      "Episode length: 28.10 +/- 6.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.1        |\n",
      "|    mean_reward          | 0.678       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 598528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010419989 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.01       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.371       |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.865       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.826   |\n",
      "| time/              |          |\n",
      "|    fps             | 1343     |\n",
      "|    iterations      | 293      |\n",
      "|    time_elapsed    | 446      |\n",
      "|    total_timesteps | 600064   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.586      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1342        |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014663383 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 0.288       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.283      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1340        |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012762444 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.02       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0699      |\n",
      "|    n_updates            | 7830        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.395       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31         |\n",
      "|    ep_rew_mean          | -0.0663    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1340       |\n",
      "|    iterations           | 296        |\n",
      "|    time_elapsed         | 452        |\n",
      "|    total_timesteps      | 606208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01133456 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.04      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.163      |\n",
      "|    n_updates            | 7840       |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 0.39       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.211      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1339        |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015117148 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.08       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.743       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=608528, episode_reward=-0.58 +/- 4.48\n",
      "Episode length: 30.60 +/- 6.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.6        |\n",
      "|    mean_reward          | -0.578      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 608528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011763761 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.437       |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 0.99        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.803   |\n",
      "| time/              |          |\n",
      "|    fps             | 1338     |\n",
      "|    iterations      | 298      |\n",
      "|    time_elapsed    | 455      |\n",
      "|    total_timesteps | 610304   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1336        |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 458         |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012109921 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.897       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32         |\n",
      "|    ep_rew_mean          | -0.53      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1335       |\n",
      "|    iterations           | 300        |\n",
      "|    time_elapsed         | 460        |\n",
      "|    total_timesteps      | 614400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01396806 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.11      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.338      |\n",
      "|    n_updates            | 7880       |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 1.16       |\n",
      "|    value_loss           | 0.719      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.0954     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1333        |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 462         |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014798877 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.11       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 0.676       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.166       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1332        |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012790054 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0593      |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.362       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=618528, episode_reward=2.93 +/- 4.36\n",
      "Episode length: 24.30 +/- 6.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.3        |\n",
      "|    mean_reward          | 2.93        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 618528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014187957 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0617      |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.342       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 1330     |\n",
      "|    iterations      | 303      |\n",
      "|    time_elapsed    | 466      |\n",
      "|    total_timesteps | 620544   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.89       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1329        |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017325673 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.347       |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 0.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.353      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1328        |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011733499 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.29        |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.736       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.0926      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1326        |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011513079 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.199       |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.574       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=628528, episode_reward=0.86 +/- 4.91\n",
      "Episode length: 28.90 +/- 9.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.9        |\n",
      "|    mean_reward          | 0.863       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 628528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010330056 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.22       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 0.469       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.438   |\n",
      "| time/              |          |\n",
      "|    fps             | 1324     |\n",
      "|    iterations      | 307      |\n",
      "|    time_elapsed    | 474      |\n",
      "|    total_timesteps | 628736   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.166       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1322        |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013893221 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.866      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1320        |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009954737 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.424       |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.276      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1319        |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011787393 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.248       |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.639       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.746      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1318        |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011288007 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.376       |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=638528, episode_reward=-2.13 +/- 5.66\n",
      "Episode length: 32.80 +/- 8.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.8         |\n",
      "|    mean_reward          | -2.13        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 638528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076824534 |\n",
      "|    clip_fraction        | 0.069        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.165        |\n",
      "|    n_updates            | 8000         |\n",
      "|    policy_gradient_loss | -0.00848     |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 0.518        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -0.122   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 312      |\n",
      "|    time_elapsed    | 485      |\n",
      "|    total_timesteps | 638976   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.614      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014923142 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0801      |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.411      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010791666 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.218       |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.617       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.249      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014893822 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.26       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.0702      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007884944 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.25       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 0.304       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=648528, episode_reward=0.54 +/- 4.50\n",
      "Episode length: 28.40 +/- 7.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 28.4       |\n",
      "|    mean_reward          | 0.537      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 648528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01585886 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.25      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0446     |\n",
      "|    n_updates            | 8050       |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 0.257      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.63    |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 317      |\n",
      "|    time_elapsed    | 497      |\n",
      "|    total_timesteps | 649216   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.524       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 318          |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 651264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134793725 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.24        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.119        |\n",
      "|    n_updates            | 8060         |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    std                  | 1.23         |\n",
      "|    value_loss           | 0.431        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.0832      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010581593 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.597       |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.243       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014097864 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.21       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0816      |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.3       |\n",
      "|    ep_rew_mean          | -0.127     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1298       |\n",
      "|    iterations           | 321        |\n",
      "|    time_elapsed         | 506        |\n",
      "|    total_timesteps      | 657408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01193213 |\n",
      "|    clip_fraction        | 0.0976     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.17      |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.103      |\n",
      "|    n_updates            | 8090       |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 1.18       |\n",
      "|    value_loss           | 0.31       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=658528, episode_reward=-3.09 +/- 3.63\n",
      "Episode length: 33.00 +/- 5.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33          |\n",
      "|    mean_reward          | -3.09       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 658528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015146135 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.303       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | 0.315    |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 322      |\n",
      "|    time_elapsed    | 508      |\n",
      "|    total_timesteps | 659456   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.0771     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008567169 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.653       |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.326      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 513         |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013972757 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.373       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.425      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013935744 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0811      |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.815      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012685033 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.16       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=668528, episode_reward=0.75 +/- 4.26\n",
      "Episode length: 30.00 +/- 6.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.755       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 668528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011934537 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.266       |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.873       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -1.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 1288     |\n",
      "|    iterations      | 327      |\n",
      "|    time_elapsed    | 519      |\n",
      "|    total_timesteps | 669696   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.322      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1287        |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014262492 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.667       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 524         |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010255737 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.17       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.0872      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | -0.0615     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1284        |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011856532 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.15       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0396      |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.6       |\n",
      "|    ep_rew_mean          | 0.175      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1283       |\n",
      "|    iterations           | 331        |\n",
      "|    time_elapsed         | 528        |\n",
      "|    total_timesteps      | 677888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01495297 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.18      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.168      |\n",
      "|    n_updates            | 8190       |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 0.378      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=678528, episode_reward=-1.00 +/- 4.61\n",
      "Episode length: 30.80 +/- 5.55\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.8       |\n",
      "|    mean_reward          | -1         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 678528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01733626 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.21      |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0105    |\n",
      "|    n_updates            | 8200       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.21       |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -0.243   |\n",
      "| time/              |          |\n",
      "|    fps             | 1281     |\n",
      "|    iterations      | 332      |\n",
      "|    time_elapsed    | 530      |\n",
      "|    total_timesteps | 679936   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.921      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1280        |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 532         |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017859012 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 1.94        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | -0.545     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1278       |\n",
      "|    iterations           | 334        |\n",
      "|    time_elapsed         | 535        |\n",
      "|    total_timesteps      | 684032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01167821 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.26      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.209      |\n",
      "|    n_updates            | 8220       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 0.642      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.194      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1277        |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 537         |\n",
      "|    total_timesteps      | 686080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018267388 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.27       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.383       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.0585      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1275        |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 539         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012715213 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0737      |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=688528, episode_reward=1.24 +/- 4.75\n",
      "Episode length: 29.00 +/- 6.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 1.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 688528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014422607 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.865   |\n",
      "| time/              |          |\n",
      "|    fps             | 1274     |\n",
      "|    iterations      | 337      |\n",
      "|    time_elapsed    | 541      |\n",
      "|    total_timesteps | 690176   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.522      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1272        |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 543         |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017408349 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.29       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.466       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.387      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1271        |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 546         |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010263579 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.494       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.0151      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1269        |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015136226 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.193       |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.636       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.509       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1268        |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014587259 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.32       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=698528, episode_reward=-1.05 +/- 5.09\n",
      "Episode length: 30.60 +/- 5.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.6        |\n",
      "|    mean_reward          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 698528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012003944 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.31       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0427     |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | 0.489    |\n",
      "| time/              |          |\n",
      "|    fps             | 1267     |\n",
      "|    iterations      | 342      |\n",
      "|    time_elapsed    | 552      |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.743       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013838665 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.322      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011373676 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0212      |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.4        |\n",
      "|    ep_rew_mean          | -0.528      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011978777 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=708528, episode_reward=-1.35 +/- 4.69\n",
      "Episode length: 34.90 +/- 9.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.9        |\n",
      "|    mean_reward          | -1.35       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 708528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010987106 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.426       |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.8     |\n",
      "|    ep_rew_mean     | -0.853   |\n",
      "| time/              |          |\n",
      "|    fps             | 1264     |\n",
      "|    iterations      | 346      |\n",
      "|    time_elapsed    | 560      |\n",
      "|    total_timesteps | 708608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.5       |\n",
      "|    ep_rew_mean          | -0.45      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1264       |\n",
      "|    iterations           | 347        |\n",
      "|    time_elapsed         | 562        |\n",
      "|    total_timesteps      | 710656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00976625 |\n",
      "|    clip_fraction        | 0.0747     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.34      |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.192      |\n",
      "|    n_updates            | 8350       |\n",
      "|    policy_gradient_loss | -0.00882   |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 0.518      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.579      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011929015 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.399       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.708      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010414498 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.506       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33.3       |\n",
      "|    ep_rew_mean          | -1.49      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1264       |\n",
      "|    iterations           | 350        |\n",
      "|    time_elapsed         | 566        |\n",
      "|    total_timesteps      | 716800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01530006 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.34      |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.208      |\n",
      "|    n_updates            | 8380       |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.29       |\n",
      "|    value_loss           | 0.832      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=718528, episode_reward=0.48 +/- 4.69\n",
      "Episode length: 29.30 +/- 6.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.3        |\n",
      "|    mean_reward          | 0.481       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 718528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012415138 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.35       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.278       |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.669       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -1.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 1264     |\n",
      "|    iterations      | 351      |\n",
      "|    time_elapsed    | 568      |\n",
      "|    total_timesteps | 718848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.618      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 569         |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012438981 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.26        |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.691       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.394      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015817085 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.597       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011319939 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 8420        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.2         |\n",
      "|    ep_rew_mean          | 0.387        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1266         |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 574          |\n",
      "|    total_timesteps      | 727040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136069385 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.39        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.153        |\n",
      "|    n_updates            | 8430         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    std                  | 1.34         |\n",
      "|    value_loss           | 0.45         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=728528, episode_reward=-2.40 +/- 6.59\n",
      "Episode length: 36.90 +/- 14.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 36.9        |\n",
      "|    mean_reward          | -2.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 728528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015577205 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.278       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -1.03    |\n",
      "| time/              |          |\n",
      "|    fps             | 1266     |\n",
      "|    iterations      | 356      |\n",
      "|    time_elapsed    | 575      |\n",
      "|    total_timesteps | 729088   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.439      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017301802 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.221       |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.873       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.448      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010607872 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.319       |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.166       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1263        |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010841424 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 0.575       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | 0.0693      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1262        |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009732132 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 8480        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.867       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=738528, episode_reward=-1.76 +/- 7.28\n",
      "Episode length: 32.20 +/- 8.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.2        |\n",
      "|    mean_reward          | -1.76       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 738528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010043815 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.234       |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.658       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.495   |\n",
      "| time/              |          |\n",
      "|    fps             | 1261     |\n",
      "|    iterations      | 361      |\n",
      "|    time_elapsed    | 586      |\n",
      "|    total_timesteps | 739328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.972      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1259        |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013700151 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 0.485       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.155      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1259        |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 590         |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015359353 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.844       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.322      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1259        |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017814051 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.624       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.595      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1259        |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007326958 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 8530        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.473       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=748528, episode_reward=-2.36 +/- 5.43\n",
      "Episode length: 34.80 +/- 11.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.8        |\n",
      "|    mean_reward          | -2.36       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 748528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014864298 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00932     |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.206   |\n",
      "| time/              |          |\n",
      "|    fps             | 1257     |\n",
      "|    iterations      | 366      |\n",
      "|    time_elapsed    | 595      |\n",
      "|    total_timesteps | 749568   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.468      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1256        |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 751616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013024263 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.36       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.934       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.0239     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1255        |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 600         |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013279544 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.191      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1254        |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012920272 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0367      |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.235      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1254        |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123027 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00509    |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=758528, episode_reward=1.66 +/- 2.55\n",
      "Episode length: 26.70 +/- 5.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.7        |\n",
      "|    mean_reward          | 1.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 758528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013491176 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0527      |\n",
      "|    n_updates            | 8590        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 1254     |\n",
      "|    iterations      | 371      |\n",
      "|    time_elapsed    | 605      |\n",
      "|    total_timesteps | 759808   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.172       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1254        |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011249787 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.347       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.165      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1254        |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015826799 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0831      |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.229      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1254        |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 610         |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015832478 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.287       |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 0.895       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.903       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1254        |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011441803 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.37       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 8630        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.633       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=768528, episode_reward=-2.28 +/- 3.68\n",
      "Episode length: 33.90 +/- 6.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.9        |\n",
      "|    mean_reward          | -2.28       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 768528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010235681 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.39       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.476       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.0163   |\n",
      "| time/              |          |\n",
      "|    fps             | 1254     |\n",
      "|    iterations      | 376      |\n",
      "|    time_elapsed    | 613      |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.472       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1254        |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012997236 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.4        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0297      |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.71       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1255        |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010036398 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.42       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.435       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.876      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1255        |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 618         |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010492913 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.856       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.2       |\n",
      "|    ep_rew_mean          | -1.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1255       |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 619        |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01289501 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.44      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0944     |\n",
      "|    n_updates            | 8680       |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 1.36       |\n",
      "|    value_loss           | 0.283      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=778528, episode_reward=0.29 +/- 4.90\n",
      "Episode length: 29.20 +/- 7.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.2        |\n",
      "|    mean_reward          | 0.295       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 778528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015979672 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.44       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 8690        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.824       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.352   |\n",
      "| time/              |          |\n",
      "|    fps             | 1255     |\n",
      "|    iterations      | 381      |\n",
      "|    time_elapsed    | 621      |\n",
      "|    total_timesteps | 780288   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.7         |\n",
      "|    ep_rew_mean          | 0.00779      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1255         |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 622          |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103339255 |\n",
      "|    clip_fraction        | 0.099        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.711        |\n",
      "|    n_updates            | 8700         |\n",
      "|    policy_gradient_loss | -0.00844     |\n",
      "|    std                  | 1.37         |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.574       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1255        |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013935562 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 0.544       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.4       |\n",
      "|    ep_rew_mean          | -0.462     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1256       |\n",
      "|    iterations           | 384        |\n",
      "|    time_elapsed         | 626        |\n",
      "|    total_timesteps      | 786432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01004809 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.46      |\n",
      "|    explained_variance   | 0.948      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.252      |\n",
      "|    n_updates            | 8720       |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 0.788      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -1.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1256        |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 627         |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011916453 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.545       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=788528, episode_reward=0.51 +/- 3.64\n",
      "Episode length: 29.70 +/- 5.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | 0.514       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 788528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009283225 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.47       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.38        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.874       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.2     |\n",
      "|    ep_rew_mean     | 0.323    |\n",
      "| time/              |          |\n",
      "|    fps             | 1256     |\n",
      "|    iterations      | 386      |\n",
      "|    time_elapsed    | 629      |\n",
      "|    total_timesteps | 790528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.607      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1256        |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011577387 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.302       |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.68       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1256        |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012289668 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.326       |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.849       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.3       |\n",
      "|    ep_rew_mean          | -0.402     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1256       |\n",
      "|    iterations           | 389        |\n",
      "|    time_elapsed         | 634        |\n",
      "|    total_timesteps      | 796672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01143332 |\n",
      "|    clip_fraction        | 0.0917     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.47      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.216      |\n",
      "|    n_updates            | 8770       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 0.696      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=798528, episode_reward=-3.07 +/- 4.44\n",
      "Episode length: 34.60 +/- 5.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 34.6       |\n",
      "|    mean_reward          | -3.07      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 798528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01403288 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.47      |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.164      |\n",
      "|    n_updates            | 8780       |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 0.427      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.239   |\n",
      "| time/              |          |\n",
      "|    fps             | 1257     |\n",
      "|    iterations      | 390      |\n",
      "|    time_elapsed    | 635      |\n",
      "|    total_timesteps | 798720   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.8       |\n",
      "|    ep_rew_mean          | -0.422     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1257       |\n",
      "|    iterations           | 391        |\n",
      "|    time_elapsed         | 636        |\n",
      "|    total_timesteps      | 800768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01847383 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.47      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.347      |\n",
      "|    n_updates            | 8790       |\n",
      "|    policy_gradient_loss | -0.00842   |\n",
      "|    std                  | 1.38       |\n",
      "|    value_loss           | 0.879      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.472       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1257        |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013373527 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.48       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 0.639       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.144      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1257        |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 639         |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011847454 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 0.493       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.0535      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1257        |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013347304 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0374     |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 0.0697      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=808528, episode_reward=-2.48 +/- 5.72\n",
      "Episode length: 32.60 +/- 7.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.6        |\n",
      "|    mean_reward          | -2.48       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 808528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011941658 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0715      |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.257       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -0.581   |\n",
      "| time/              |          |\n",
      "|    fps             | 1257     |\n",
      "|    iterations      | 395      |\n",
      "|    time_elapsed    | 643      |\n",
      "|    total_timesteps | 808960   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.437      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1257        |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009257388 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.775       |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.294      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 646         |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011941073 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.45        |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.855       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.664      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016168153 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.169       |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.503       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.0879      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 649         |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011278374 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.291       |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 0.78        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=818528, episode_reward=-0.59 +/- 5.61\n",
      "Episode length: 31.00 +/- 10.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31          |\n",
      "|    mean_reward          | -0.587      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 818528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011941085 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.5        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.476       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.187    |\n",
      "| time/              |          |\n",
      "|    fps             | 1258     |\n",
      "|    iterations      | 400      |\n",
      "|    time_elapsed    | 651      |\n",
      "|    total_timesteps | 819200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.361       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011526914 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 654         |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013620369 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 8900        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.587       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.19        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1258         |\n",
      "|    iterations           | 403          |\n",
      "|    time_elapsed         | 655          |\n",
      "|    total_timesteps      | 825344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149114225 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.5         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0164      |\n",
      "|    n_updates            | 8910         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    std                  | 1.39         |\n",
      "|    value_loss           | 0.107        |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 31.2     |\n",
      "|    ep_rew_mean          | -0.42    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 1258     |\n",
      "|    iterations           | 404      |\n",
      "|    time_elapsed         | 657      |\n",
      "|    total_timesteps      | 827392   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.011553 |\n",
      "|    clip_fraction        | 0.124    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -3.49    |\n",
      "|    explained_variance   | 0.974    |\n",
      "|    learning_rate        | 0.001    |\n",
      "|    loss                 | 0.112    |\n",
      "|    n_updates            | 8920     |\n",
      "|    policy_gradient_loss | -0.0137  |\n",
      "|    std                  | 1.4      |\n",
      "|    value_loss           | 0.45     |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=828528, episode_reward=-1.38 +/- 3.80\n",
      "Episode length: 32.00 +/- 6.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32          |\n",
      "|    mean_reward          | -1.38       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 828528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015735263 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.095    |\n",
      "| time/              |          |\n",
      "|    fps             | 1258     |\n",
      "|    iterations      | 405      |\n",
      "|    time_elapsed    | 659      |\n",
      "|    total_timesteps | 829440   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.9       |\n",
      "|    ep_rew_mean          | 0.0816     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1258       |\n",
      "|    iterations           | 406        |\n",
      "|    time_elapsed         | 660        |\n",
      "|    total_timesteps      | 831488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01026912 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.52      |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.313      |\n",
      "|    n_updates            | 8940       |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 0.715      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30         |\n",
      "|    ep_rew_mean          | -0.0451    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1258       |\n",
      "|    iterations           | 407        |\n",
      "|    time_elapsed         | 662        |\n",
      "|    total_timesteps      | 833536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01283239 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.5       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.11       |\n",
      "|    n_updates            | 8950       |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 1.39       |\n",
      "|    value_loss           | 0.394      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | -0.0748     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 664         |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010944916 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.49       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 0.468       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012002517 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=838528, episode_reward=-3.79 +/- 4.02\n",
      "Episode length: 36.60 +/- 4.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 36.6        |\n",
      "|    mean_reward          | -3.79       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 838528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016781056 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.75        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.868   |\n",
      "| time/              |          |\n",
      "|    fps             | 1258     |\n",
      "|    iterations      | 410      |\n",
      "|    time_elapsed    | 666      |\n",
      "|    total_timesteps | 839680   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.842       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012449738 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.513       |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012343627 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 0.565       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.211      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1258        |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 671         |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015093951 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.526       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.283      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1259        |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010913706 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.44        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=848528, episode_reward=-1.92 +/- 6.03\n",
      "Episode length: 32.20 +/- 9.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.2        |\n",
      "|    mean_reward          | -1.92       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 848528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011056199 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0683      |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.506   |\n",
      "| time/              |          |\n",
      "|    fps             | 1259     |\n",
      "|    iterations      | 415      |\n",
      "|    time_elapsed    | 674      |\n",
      "|    total_timesteps | 849920   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.466      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1259        |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 676         |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011541637 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 0.473       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.0676     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1259        |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 677         |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012449458 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.992       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.229      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1260        |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 679         |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013247519 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.52       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0581      |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 0.285       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.271      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1260        |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013142982 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.693       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=858528, episode_reward=1.93 +/- 3.87\n",
      "Episode length: 27.00 +/- 6.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 27         |\n",
      "|    mean_reward          | 1.93       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 858528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961022 |\n",
      "|    clip_fraction        | 0.0914     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.53      |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.199      |\n",
      "|    n_updates            | 9080       |\n",
      "|    policy_gradient_loss | -0.0087    |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 0.573      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -0.964   |\n",
      "| time/              |          |\n",
      "|    fps             | 1260     |\n",
      "|    iterations      | 420      |\n",
      "|    time_elapsed    | 682      |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | 0.000256    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1260        |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 684         |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009063177 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 0.715       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.441      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1260        |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011033205 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.743       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.461      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1260        |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013363091 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.435       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.729      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1261        |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 688         |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009182075 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.38        |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 0.951       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=868528, episode_reward=0.58 +/- 3.76\n",
      "Episode length: 29.80 +/- 5.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.8        |\n",
      "|    mean_reward          | 0.576       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 868528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013021725 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.56       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.386       |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.845       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | -0.0231  |\n",
      "| time/              |          |\n",
      "|    fps             | 1261     |\n",
      "|    iterations      | 425      |\n",
      "|    time_elapsed    | 690      |\n",
      "|    total_timesteps | 870400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1261        |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011706124 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.834       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.531      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1261        |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 693         |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010771351 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 0.527       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.225      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1262        |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 694         |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012296479 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 9160        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=878528, episode_reward=-1.24 +/- 3.00\n",
      "Episode length: 31.10 +/- 3.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.1        |\n",
      "|    mean_reward          | -1.24       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 878528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015998315 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0733      |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.252       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29       |\n",
      "|    ep_rew_mean     | 0.358    |\n",
      "| time/              |          |\n",
      "|    fps             | 1262     |\n",
      "|    iterations      | 429      |\n",
      "|    time_elapsed    | 696      |\n",
      "|    total_timesteps | 878592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0082      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1262        |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011005997 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 9180        |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.0751     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1262        |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010110481 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 0.563       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.9       |\n",
      "|    ep_rew_mean          | -0.685     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1262       |\n",
      "|    iterations           | 432        |\n",
      "|    time_elapsed         | 700        |\n",
      "|    total_timesteps      | 884736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00991212 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.61      |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.442      |\n",
      "|    n_updates            | 9200       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 0.901      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1262        |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015873179 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.373       |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=888528, episode_reward=0.52 +/- 4.80\n",
      "Episode length: 29.90 +/- 7.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.522       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 888528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014874805 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 0.719       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | 0.294    |\n",
      "| time/              |          |\n",
      "|    fps             | 1262     |\n",
      "|    iterations      | 434      |\n",
      "|    time_elapsed    | 703      |\n",
      "|    total_timesteps | 888832   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.9         |\n",
      "|    ep_rew_mean          | -0.351       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1263         |\n",
      "|    iterations           | 435          |\n",
      "|    time_elapsed         | 705          |\n",
      "|    total_timesteps      | 890880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080304565 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.291        |\n",
      "|    n_updates            | 9230         |\n",
      "|    policy_gradient_loss | -0.00999     |\n",
      "|    std                  | 1.5          |\n",
      "|    value_loss           | 0.905        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1263        |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010809504 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.898       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.318       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1263        |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 708         |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010818484 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 0.539       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.00724     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1263        |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 709         |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010298005 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.626       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=898528, episode_reward=1.15 +/- 5.16\n",
      "Episode length: 28.00 +/- 7.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 1.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 898528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010018105 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.379       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.449   |\n",
      "| time/              |          |\n",
      "|    fps             | 1263     |\n",
      "|    iterations      | 439      |\n",
      "|    time_elapsed    | 711      |\n",
      "|    total_timesteps | 899072   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.118      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1263        |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 712         |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010925671 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.928       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.427      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010482688 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.137      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016781393 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.159      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 717         |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008698804 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.377       |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.847       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=908528, episode_reward=-1.31 +/- 5.32\n",
      "Episode length: 32.20 +/- 5.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.2         |\n",
      "|    mean_reward          | -1.31        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 908528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110808285 |\n",
      "|    clip_fraction        | 0.0979       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.68        |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.452        |\n",
      "|    n_updates            | 9320         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    std                  | 1.52         |\n",
      "|    value_loss           | 1.1          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.123   |\n",
      "| time/              |          |\n",
      "|    fps             | 1264     |\n",
      "|    iterations      | 444      |\n",
      "|    time_elapsed    | 718      |\n",
      "|    total_timesteps | 909312   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.577      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1264        |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 720         |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008505778 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.503       |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.6       |\n",
      "|    ep_rew_mean          | -0.966     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1265       |\n",
      "|    iterations           | 446        |\n",
      "|    time_elapsed         | 722        |\n",
      "|    total_timesteps      | 913408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00888255 |\n",
      "|    clip_fraction        | 0.0909     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.68      |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.249      |\n",
      "|    n_updates            | 9340       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 0.66       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.8       |\n",
      "|    ep_rew_mean          | -0.925     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1265       |\n",
      "|    iterations           | 447        |\n",
      "|    time_elapsed         | 723        |\n",
      "|    total_timesteps      | 915456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01093214 |\n",
      "|    clip_fraction        | 0.0966     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.68      |\n",
      "|    explained_variance   | 0.944      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.219      |\n",
      "|    n_updates            | 9350       |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 1.53       |\n",
      "|    value_loss           | 1.01       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -1.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 725         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011752794 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.414       |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=918528, episode_reward=-1.16 +/- 6.03\n",
      "Episode length: 31.20 +/- 8.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.2        |\n",
      "|    mean_reward          | -1.16       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 918528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009906487 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.432       |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.71    |\n",
      "| time/              |          |\n",
      "|    fps             | 1265     |\n",
      "|    iterations      | 449      |\n",
      "|    time_elapsed    | 726      |\n",
      "|    total_timesteps | 919552   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.314      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 728         |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011612175 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.317       |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 0.984       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | 0.0621      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386114 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.396       |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.993       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012265598 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.326      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009210473 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.552       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=928528, episode_reward=-2.28 +/- 7.66\n",
      "Episode length: 33.70 +/- 14.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 33.7         |\n",
      "|    mean_reward          | -2.28        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 928528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122805815 |\n",
      "|    clip_fraction        | 0.0983       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.69        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0951       |\n",
      "|    n_updates            | 9420         |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    std                  | 1.54         |\n",
      "|    value_loss           | 0.465        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.00995 |\n",
      "| time/              |          |\n",
      "|    fps             | 1265     |\n",
      "|    iterations      | 454      |\n",
      "|    time_elapsed    | 734      |\n",
      "|    total_timesteps | 929792   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.287       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 736         |\n",
      "|    total_timesteps      | 931840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010296568 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.559       |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 737         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009913163 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.333       |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.931       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.4       |\n",
      "|    ep_rew_mean          | -0.442     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1265       |\n",
      "|    iterations           | 457        |\n",
      "|    time_elapsed         | 739        |\n",
      "|    total_timesteps      | 935936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00923931 |\n",
      "|    clip_fraction        | 0.0574     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.69      |\n",
      "|    explained_variance   | 0.942      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.358      |\n",
      "|    n_updates            | 9450       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 0.923      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.2       |\n",
      "|    ep_rew_mean          | -0.995     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1265       |\n",
      "|    iterations           | 458        |\n",
      "|    time_elapsed         | 741        |\n",
      "|    total_timesteps      | 937984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01110251 |\n",
      "|    clip_fraction        | 0.0841     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.67      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.446      |\n",
      "|    n_updates            | 9460       |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 1.08       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=938528, episode_reward=-3.07 +/- 6.33\n",
      "Episode length: 33.00 +/- 7.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33          |\n",
      "|    mean_reward          | -3.07       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 938528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011898292 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -1.47    |\n",
      "| time/              |          |\n",
      "|    fps             | 1265     |\n",
      "|    iterations      | 459      |\n",
      "|    time_elapsed    | 742      |\n",
      "|    total_timesteps | 940032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 744         |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013641031 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.43        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 1.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.946      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021918979 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0825      |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 0.329       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.456      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010806151 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.63       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.542       |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | 0.23         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1266         |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 748          |\n",
      "|    total_timesteps      | 948224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101934755 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.63        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.18         |\n",
      "|    n_updates            | 9510         |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 1.48         |\n",
      "|    value_loss           | 0.526        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=948528, episode_reward=-2.38 +/- 3.26\n",
      "Episode length: 34.50 +/- 3.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.5        |\n",
      "|    mean_reward          | -2.38       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 948528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014249964 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0408      |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.14     |\n",
      "| time/              |          |\n",
      "|    fps             | 1266     |\n",
      "|    iterations      | 464      |\n",
      "|    time_elapsed    | 750      |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.862      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 751         |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014250928 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.193       |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.486       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.275      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1266       |\n",
      "|    iterations           | 466        |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 954368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01582241 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.61      |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.471      |\n",
      "|    n_updates            | 9540       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 1.01       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.0309     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 754         |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011940384 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.711       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.0368      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1267        |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 755         |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012971389 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.63       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0034      |\n",
      "|    n_updates            | 9560        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=958528, episode_reward=-1.09 +/- 6.12\n",
      "Episode length: 31.40 +/- 7.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.4        |\n",
      "|    mean_reward          | -1.09       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 958528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016469177 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.5     |\n",
      "|    ep_rew_mean     | 0.0449   |\n",
      "| time/              |          |\n",
      "|    fps             | 1267     |\n",
      "|    iterations      | 469      |\n",
      "|    time_elapsed    | 757      |\n",
      "|    total_timesteps | 960512   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.332      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1267        |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 759         |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014636874 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0563      |\n",
      "|    n_updates            | 9580        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.53       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1268        |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 760         |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015633563 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.465       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.9         |\n",
      "|    ep_rew_mean          | -1.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1268         |\n",
      "|    iterations           | 472          |\n",
      "|    time_elapsed         | 762          |\n",
      "|    total_timesteps      | 966656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099048475 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.62        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.385        |\n",
      "|    n_updates            | 9600         |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    std                  | 1.48         |\n",
      "|    value_loss           | 1.08         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=968528, episode_reward=1.26 +/- 3.77\n",
      "Episode length: 26.30 +/- 5.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.3        |\n",
      "|    mean_reward          | 1.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 968528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011787218 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0649      |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.345       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.218   |\n",
      "| time/              |          |\n",
      "|    fps             | 1268     |\n",
      "|    iterations      | 473      |\n",
      "|    time_elapsed    | 763      |\n",
      "|    total_timesteps | 968704   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.455      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1268        |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 765         |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008033155 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.63       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 0.332       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.987      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1268        |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013626283 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.64       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0453     |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.0421      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.745      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1268        |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 768         |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012818411 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0338     |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.0437      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.3       |\n",
      "|    ep_rew_mean          | -0.269     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1268       |\n",
      "|    iterations           | 477        |\n",
      "|    time_elapsed         | 769        |\n",
      "|    total_timesteps      | 976896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01191519 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.58      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.109      |\n",
      "|    n_updates            | 9650       |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 0.573      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=978528, episode_reward=1.04 +/- 1.96\n",
      "Episode length: 29.30 +/- 4.29\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.3       |\n",
      "|    mean_reward          | 1.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 978528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01747392 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.56      |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.071      |\n",
      "|    n_updates            | 9660       |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 0.54       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.238   |\n",
      "| time/              |          |\n",
      "|    fps             | 1268     |\n",
      "|    iterations      | 478      |\n",
      "|    time_elapsed    | 771      |\n",
      "|    total_timesteps | 978944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.706      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1269        |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 772         |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009956313 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0953      |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.165      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1269        |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014259674 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.072       |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.1       |\n",
      "|    ep_rew_mean          | 0.981      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1269       |\n",
      "|    iterations           | 481        |\n",
      "|    time_elapsed         | 776        |\n",
      "|    total_timesteps      | 985088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01291011 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.52      |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.175      |\n",
      "|    n_updates            | 9690       |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 1.4        |\n",
      "|    value_loss           | 0.547      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.238      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1269        |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814067 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.53       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 0.676       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=988528, episode_reward=1.44 +/- 3.77\n",
      "Episode length: 27.30 +/- 5.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.3        |\n",
      "|    mean_reward          | 1.44        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 988528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010929501 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.57       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.5         |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.765   |\n",
      "| time/              |          |\n",
      "|    fps             | 1270     |\n",
      "|    iterations      | 483      |\n",
      "|    time_elapsed    | 778      |\n",
      "|    total_timesteps | 989184   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.29       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1270        |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 780         |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007970767 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.59       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.732       |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 1.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.685      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1270        |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 781         |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011245834 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.607      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1271        |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011256689 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0427      |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.251       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.686      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1271        |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013469417 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.58       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0847      |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=998528, episode_reward=-1.33 +/- 4.58\n",
      "Episode length: 30.90 +/- 6.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.9         |\n",
      "|    mean_reward          | -1.33        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 998528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095492955 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.58        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.205        |\n",
      "|    n_updates            | 9760         |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    std                  | 1.46         |\n",
      "|    value_loss           | 0.833        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | 0.607    |\n",
      "| time/              |          |\n",
      "|    fps             | 1271     |\n",
      "|    iterations      | 488      |\n",
      "|    time_elapsed    | 785      |\n",
      "|    total_timesteps | 999424   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.416       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1271        |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 787         |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016654786 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.61       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0771      |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 0.258       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.6       |\n",
      "|    ep_rew_mean          | -1.01      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1271       |\n",
      "|    iterations           | 490        |\n",
      "|    time_elapsed         | 788        |\n",
      "|    total_timesteps      | 1003520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01985096 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.62      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.103      |\n",
      "|    n_updates            | 9780       |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 0.302      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.989      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1272        |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 790         |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011785915 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.63       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.519       |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.4       |\n",
      "|    ep_rew_mean          | -0.0845    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1272       |\n",
      "|    iterations           | 492        |\n",
      "|    time_elapsed         | 792        |\n",
      "|    total_timesteps      | 1007616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00984351 |\n",
      "|    clip_fraction        | 0.0918     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.65      |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 9800       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 0.376      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1008528, episode_reward=-2.55 +/- 4.20\n",
      "Episode length: 34.70 +/- 5.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.7        |\n",
      "|    mean_reward          | -2.55       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1008528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011648729 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | 0.287    |\n",
      "| time/              |          |\n",
      "|    fps             | 1272     |\n",
      "|    iterations      | 493      |\n",
      "|    time_elapsed    | 793      |\n",
      "|    total_timesteps | 1009664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.0623      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1272        |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012802314 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00298     |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.443       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1273        |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 796         |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013206035 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.68       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0408      |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.223       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1273        |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018492363 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.583       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.882      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1274        |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 798         |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011492583 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.69       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.726       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1018528, episode_reward=0.17 +/- 4.58\n",
      "Episode length: 30.30 +/- 7.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | 0.172       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1018528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012151831 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.263       |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.798       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.991   |\n",
      "| time/              |          |\n",
      "|    fps             | 1274     |\n",
      "|    iterations      | 498      |\n",
      "|    time_elapsed    | 800      |\n",
      "|    total_timesteps | 1019904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1274        |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 801         |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008405473 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.335       |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1274        |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010536261 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0385     |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.0913      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.496       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1274        |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 804         |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010040904 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.976       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | 0.123       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1275        |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 806         |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010259845 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.918       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1028528, episode_reward=3.28 +/- 5.00\n",
      "Episode length: 24.80 +/- 8.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.8        |\n",
      "|    mean_reward          | 3.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1028528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011732436 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0652      |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.28        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -0.0431  |\n",
      "| time/              |          |\n",
      "|    fps             | 1275     |\n",
      "|    iterations      | 503      |\n",
      "|    time_elapsed    | 807      |\n",
      "|    total_timesteps | 1030144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.292      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1275        |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008776352 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.596      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1275        |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014596766 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0431      |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.635       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1275         |\n",
      "|    iterations           | 506          |\n",
      "|    time_elapsed         | 812          |\n",
      "|    total_timesteps      | 1036288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131709585 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0371      |\n",
      "|    n_updates            | 9940         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    std                  | 1.54         |\n",
      "|    value_loss           | 0.0672       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.8        |\n",
      "|    ep_rew_mean          | -1.46       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1276        |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 813         |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014337452 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.36        |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 0.84        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1038528, episode_reward=2.55 +/- 3.64\n",
      "Episode length: 26.20 +/- 5.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.2         |\n",
      "|    mean_reward          | 2.55         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1038528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078427475 |\n",
      "|    clip_fraction        | 0.0724       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.654        |\n",
      "|    n_updates            | 9960         |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 1.56         |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.3     |\n",
      "|    ep_rew_mean     | -0.593   |\n",
      "| time/              |          |\n",
      "|    fps             | 1276     |\n",
      "|    iterations      | 508      |\n",
      "|    time_elapsed    | 815      |\n",
      "|    total_timesteps | 1040384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.358       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1276        |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 816         |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010725662 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0816      |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.448       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.339       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1276         |\n",
      "|    iterations           | 510          |\n",
      "|    time_elapsed         | 818          |\n",
      "|    total_timesteps      | 1044480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112302955 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.115        |\n",
      "|    n_updates            | 9980         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 1.55         |\n",
      "|    value_loss           | 0.271        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.00781     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1276        |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 819         |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011783241 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0602      |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1048528, episode_reward=-1.45 +/- 4.22\n",
      "Episode length: 32.50 +/- 6.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.5        |\n",
      "|    mean_reward          | -1.45       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1048528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010362057 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 0.816       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.519   |\n",
      "| time/              |          |\n",
      "|    fps             | 1276     |\n",
      "|    iterations      | 512      |\n",
      "|    time_elapsed    | 821      |\n",
      "|    total_timesteps | 1048576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1276        |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 823         |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011257836 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.188      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1276        |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 824         |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010537831 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 0.466       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.955      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1277        |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 825         |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012414856 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.731       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.771      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1278        |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 826         |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014218414 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.439       |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1058528, episode_reward=0.64 +/- 3.95\n",
      "Episode length: 28.00 +/- 7.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 0.64        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1058528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011518627 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0861      |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 0.497       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.426   |\n",
      "| time/              |          |\n",
      "|    fps             | 1278     |\n",
      "|    iterations      | 517      |\n",
      "|    time_elapsed    | 828      |\n",
      "|    total_timesteps | 1058816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.303      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1279        |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010683706 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.92        |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.5       |\n",
      "|    ep_rew_mean          | -0.454     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1279       |\n",
      "|    iterations           | 519        |\n",
      "|    time_elapsed         | 830        |\n",
      "|    total_timesteps      | 1062912    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01022333 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.75      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.319      |\n",
      "|    n_updates            | 10070      |\n",
      "|    policy_gradient_loss | -0.00868   |\n",
      "|    std                  | 1.57       |\n",
      "|    value_loss           | 0.653      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.49       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1280        |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011606745 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0798      |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.494       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1281        |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 832         |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015371073 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.658       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1068528, episode_reward=-1.61 +/- 2.47\n",
      "Episode length: 33.00 +/- 3.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33          |\n",
      "|    mean_reward          | -1.61       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1068528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009669039 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.339       |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.717       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.37    |\n",
      "| time/              |          |\n",
      "|    fps             | 1281     |\n",
      "|    iterations      | 522      |\n",
      "|    time_elapsed    | 834      |\n",
      "|    total_timesteps | 1069056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.00697    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1281        |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011640134 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.73       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.374       |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.0635     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1281        |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 837         |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013084728 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.72       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 0.416       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.752      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1282        |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 838         |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014183383 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.204       |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.647       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.522      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1282        |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 840         |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011814119 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.835       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1078528, episode_reward=-0.81 +/- 2.71\n",
      "Episode length: 31.50 +/- 4.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.5        |\n",
      "|    mean_reward          | -0.813      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1078528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010658458 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0924      |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 0.27        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.368    |\n",
      "| time/              |          |\n",
      "|    fps             | 1282     |\n",
      "|    iterations      | 527      |\n",
      "|    time_elapsed    | 841      |\n",
      "|    total_timesteps | 1079296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.114       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1282        |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 843         |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009177109 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 0.538       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.205       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1283        |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 844         |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018301116 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 10170       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.514       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.5      |\n",
      "|    ep_rew_mean          | -0.359    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1283      |\n",
      "|    iterations           | 530       |\n",
      "|    time_elapsed         | 845       |\n",
      "|    total_timesteps      | 1085440   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0094456 |\n",
      "|    clip_fraction        | 0.0802    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.75     |\n",
      "|    explained_variance   | 0.993     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0355   |\n",
      "|    n_updates            | 10180     |\n",
      "|    policy_gradient_loss | -0.012    |\n",
      "|    std                  | 1.58      |\n",
      "|    value_loss           | 0.0817    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.39       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1283        |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012959254 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.466       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1088528, episode_reward=-0.25 +/- 4.91\n",
      "Episode length: 29.70 +/- 8.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | -0.246      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1088528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013748227 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.401       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.207   |\n",
      "| time/              |          |\n",
      "|    fps             | 1283     |\n",
      "|    iterations      | 532      |\n",
      "|    time_elapsed    | 848      |\n",
      "|    total_timesteps | 1089536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.107      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1283        |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 850         |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008513025 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.74       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.565       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1283        |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 851         |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010124784 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.253       |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 0.976       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1284        |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012497751 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 10230       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 0.333       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.265      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1284        |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 854         |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009875043 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.76       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 0.586       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1098528, episode_reward=-1.41 +/- 4.14\n",
      "Episode length: 33.20 +/- 6.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.2        |\n",
      "|    mean_reward          | -1.41       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1098528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010173219 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.77       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.287       |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 0.67        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33       |\n",
      "|    ep_rew_mean     | -1.18    |\n",
      "| time/              |          |\n",
      "|    fps             | 1284     |\n",
      "|    iterations      | 537      |\n",
      "|    time_elapsed    | 856      |\n",
      "|    total_timesteps | 1099776  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.2       |\n",
      "|    ep_rew_mean          | -0.423     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1284       |\n",
      "|    iterations           | 538        |\n",
      "|    time_elapsed         | 857        |\n",
      "|    total_timesteps      | 1101824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01004983 |\n",
      "|    clip_fraction        | 0.0808     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.77      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.284      |\n",
      "|    n_updates            | 10260      |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 0.794      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.606       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1285         |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 858          |\n",
      "|    total_timesteps      | 1103872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070144306 |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.78        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.344        |\n",
      "|    n_updates            | 10270        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 1.6          |\n",
      "|    value_loss           | 0.864        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | 0.222        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1285         |\n",
      "|    iterations           | 540          |\n",
      "|    time_elapsed         | 860          |\n",
      "|    total_timesteps      | 1105920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113927955 |\n",
      "|    clip_fraction        | 0.0855       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.79        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0821       |\n",
      "|    n_updates            | 10280        |\n",
      "|    policy_gradient_loss | -0.00914     |\n",
      "|    std                  | 1.61         |\n",
      "|    value_loss           | 0.368        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.506      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 862         |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011091636 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1108528, episode_reward=2.25 +/- 4.57\n",
      "Episode length: 26.50 +/- 7.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.5        |\n",
      "|    mean_reward          | 2.25        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1108528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011772249 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.217    |\n",
      "| time/              |          |\n",
      "|    fps             | 1285     |\n",
      "|    iterations      | 542      |\n",
      "|    time_elapsed    | 863      |\n",
      "|    total_timesteps | 1110016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -1.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015086073 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.571       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.2        |\n",
      "|    ep_rew_mean          | -1.74       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 866         |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010638054 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.314       |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 0.872       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.5       |\n",
      "|    ep_rew_mean          | -0.272     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1285       |\n",
      "|    iterations           | 545        |\n",
      "|    time_elapsed         | 868        |\n",
      "|    total_timesteps      | 1116160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185197 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.8       |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.501      |\n",
      "|    n_updates            | 10330      |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 1.28       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.284       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 869         |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010258503 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0492      |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.308       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1118528, episode_reward=-2.26 +/- 3.15\n",
      "Episode length: 32.50 +/- 5.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.5        |\n",
      "|    mean_reward          | -2.26       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1118528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009925332 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0443      |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.3     |\n",
      "|    ep_rew_mean     | -0.921   |\n",
      "| time/              |          |\n",
      "|    fps             | 1285     |\n",
      "|    iterations      | 547      |\n",
      "|    time_elapsed    | 871      |\n",
      "|    total_timesteps | 1120256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -1.34       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 872         |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010464342 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.563       |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.384      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 874         |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009818929 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.345       |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.528      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 875         |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008446854 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 10380       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 0.616       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.516       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 877         |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010760365 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0437     |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1128528, episode_reward=-0.18 +/- 4.08\n",
      "Episode length: 29.40 +/- 5.85\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.4       |\n",
      "|    mean_reward          | -0.184     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1128528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01268689 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.8       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00589    |\n",
      "|    n_updates            | 10400      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.218    |\n",
      "| time/              |          |\n",
      "|    fps             | 1286     |\n",
      "|    iterations      | 552      |\n",
      "|    time_elapsed    | 878      |\n",
      "|    total_timesteps | 1130496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.725      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 880         |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009093229 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.746       |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 881         |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014522049 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0891      |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.296       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 883         |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013812614 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.81       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.512       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1138528, episode_reward=-1.00 +/- 4.65\n",
      "Episode length: 32.00 +/- 6.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32          |\n",
      "|    mean_reward          | -1          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1138528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009548986 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.961   |\n",
      "| time/              |          |\n",
      "|    fps             | 1286     |\n",
      "|    iterations      | 556      |\n",
      "|    time_elapsed    | 884      |\n",
      "|    total_timesteps | 1138688  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.101      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 886         |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012420674 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.82       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 0.447       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.483      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1287       |\n",
      "|    iterations           | 558        |\n",
      "|    time_elapsed         | 887        |\n",
      "|    total_timesteps      | 1142784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00941574 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.84      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.211      |\n",
      "|    n_updates            | 10460      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 1.66       |\n",
      "|    value_loss           | 0.5        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.00591     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1286        |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 889         |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007831594 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 0.551       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.5        |\n",
      "|    ep_rew_mean          | -1.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1287        |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 891         |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011746958 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.364       |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 0.902       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1148528, episode_reward=1.05 +/- 4.23\n",
      "Episode length: 27.10 +/- 7.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27.1         |\n",
      "|    mean_reward          | 1.05         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1148528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091464985 |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.86        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 10490        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    std                  | 1.67         |\n",
      "|    value_loss           | 0.38         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -1.32    |\n",
      "| time/              |          |\n",
      "|    fps             | 1286     |\n",
      "|    iterations      | 561      |\n",
      "|    time_elapsed    | 892      |\n",
      "|    total_timesteps | 1148928  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.7       |\n",
      "|    ep_rew_mean          | 0.363      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1287       |\n",
      "|    iterations           | 562        |\n",
      "|    time_elapsed         | 894        |\n",
      "|    total_timesteps      | 1150976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01178037 |\n",
      "|    clip_fraction        | 0.0987     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.87      |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.345      |\n",
      "|    n_updates            | 10500      |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 0.987      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.0817      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1287         |\n",
      "|    iterations           | 563          |\n",
      "|    time_elapsed         | 895          |\n",
      "|    total_timesteps      | 1153024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075194216 |\n",
      "|    clip_fraction        | 0.0761       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.328        |\n",
      "|    n_updates            | 10510        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 1.71         |\n",
      "|    value_loss           | 0.999        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.022      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1287        |\n",
      "|    iterations           | 564         |\n",
      "|    time_elapsed         | 897         |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011596291 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 0.467       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.156      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1287        |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 898         |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010248146 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 0.743       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1158528, episode_reward=1.78 +/- 4.18\n",
      "Episode length: 27.80 +/- 7.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.8        |\n",
      "|    mean_reward          | 1.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1158528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010933329 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.9        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 0.576       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | 0.0185   |\n",
      "| time/              |          |\n",
      "|    fps             | 1287     |\n",
      "|    iterations      | 566      |\n",
      "|    time_elapsed    | 900      |\n",
      "|    total_timesteps | 1159168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.802       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1287        |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 901         |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010905229 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.4       |\n",
      "|    ep_rew_mean          | -0.157     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1287       |\n",
      "|    iterations           | 568        |\n",
      "|    time_elapsed         | 903        |\n",
      "|    total_timesteps      | 1163264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01476749 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.89      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0728     |\n",
      "|    n_updates            | 10560      |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.71       |\n",
      "|    value_loss           | 0.323      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.226      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 904         |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012726314 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0891      |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 0.546       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.8       |\n",
      "|    ep_rew_mean          | 0.115      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1288       |\n",
      "|    iterations           | 570        |\n",
      "|    time_elapsed         | 906        |\n",
      "|    total_timesteps      | 1167360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01503293 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.91      |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00954    |\n",
      "|    n_updates            | 10580      |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 1.72       |\n",
      "|    value_loss           | 0.327      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1168528, episode_reward=-0.30 +/- 4.70\n",
      "Episode length: 29.50 +/- 7.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.5        |\n",
      "|    mean_reward          | -0.301      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1168528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010552291 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 0.369       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.506   |\n",
      "| time/              |          |\n",
      "|    fps             | 1288     |\n",
      "|    iterations      | 571      |\n",
      "|    time_elapsed    | 907      |\n",
      "|    total_timesteps | 1169408  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.497      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 572         |\n",
      "|    time_elapsed         | 909         |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013798099 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.679       |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.864       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 910         |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010424403 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.436       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.3      |\n",
      "|    ep_rew_mean          | -0.438    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1288      |\n",
      "|    iterations           | 574       |\n",
      "|    time_elapsed         | 912       |\n",
      "|    total_timesteps      | 1175552   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0115221 |\n",
      "|    clip_fraction        | 0.0752    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.94     |\n",
      "|    explained_variance   | 0.97      |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0115    |\n",
      "|    n_updates            | 10620     |\n",
      "|    policy_gradient_loss | -0.00962  |\n",
      "|    std                  | 1.72      |\n",
      "|    value_loss           | 0.282     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.6       |\n",
      "|    ep_rew_mean          | -0.486     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1288       |\n",
      "|    iterations           | 575        |\n",
      "|    time_elapsed         | 913        |\n",
      "|    total_timesteps      | 1177600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01337466 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.92      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.23       |\n",
      "|    n_updates            | 10630      |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 0.718      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1178528, episode_reward=1.79 +/- 4.75\n",
      "Episode length: 27.80 +/- 7.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.8        |\n",
      "|    mean_reward          | 1.79        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1178528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013599711 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.592       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.00662  |\n",
      "| time/              |          |\n",
      "|    fps             | 1288     |\n",
      "|    iterations      | 576      |\n",
      "|    time_elapsed    | 915      |\n",
      "|    total_timesteps | 1179648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.117       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013398731 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.199       |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 0.546       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.739      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 918         |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012131531 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.364       |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.809       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 919         |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011848701 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.25        |\n",
      "|    n_updates            | 10670       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.631       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.958      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 920         |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009268304 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.334       |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.894       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1188528, episode_reward=-2.63 +/- 5.64\n",
      "Episode length: 33.30 +/- 7.16\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 33.3         |\n",
      "|    mean_reward          | -2.63        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1188528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115789175 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.99        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.299        |\n",
      "|    n_updates            | 10690        |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 1.77         |\n",
      "|    value_loss           | 0.77         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -1.14    |\n",
      "| time/              |          |\n",
      "|    fps             | 1289     |\n",
      "|    iterations      | 581      |\n",
      "|    time_elapsed    | 922      |\n",
      "|    total_timesteps | 1189888  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.221       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 923         |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011220911 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.343       |\n",
      "|    n_updates            | 10700       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.994       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.273       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 925         |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010049416 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 10710       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.414       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 926         |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014386474 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.98       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 0.412       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.852      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 928         |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007837668 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.401       |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 0.964       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1198528, episode_reward=-0.31 +/- 3.87\n",
      "Episode length: 30.20 +/- 6.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.2        |\n",
      "|    mean_reward          | -0.31       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1198528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008754759 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.383       |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.891       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.533   |\n",
      "| time/              |          |\n",
      "|    fps             | 1291     |\n",
      "|    iterations      | 586      |\n",
      "|    time_elapsed    | 929      |\n",
      "|    total_timesteps | 1200128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.499      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1291        |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 930         |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012298774 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 0.836       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.8       |\n",
      "|    ep_rew_mean          | 0.0787     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1292       |\n",
      "|    iterations           | 588        |\n",
      "|    time_elapsed         | 931        |\n",
      "|    total_timesteps      | 1204224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01135795 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.95      |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.278      |\n",
      "|    n_updates            | 10760      |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 0.876      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.364      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013728144 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.817       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.164      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 934         |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014052597 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 10780       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 0.469       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1208528, episode_reward=-0.29 +/- 4.60\n",
      "Episode length: 30.20 +/- 5.86\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.2       |\n",
      "|    mean_reward          | -0.288     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1208528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00844926 |\n",
      "|    clip_fraction        | 0.0819     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.93      |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.359      |\n",
      "|    n_updates            | 10790      |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 0.911      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.903   |\n",
      "| time/              |          |\n",
      "|    fps             | 1292     |\n",
      "|    iterations      | 591      |\n",
      "|    time_elapsed    | 936      |\n",
      "|    total_timesteps | 1210368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 938         |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017902426 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.191       |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 0.775       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.8        |\n",
      "|    ep_rew_mean          | -2.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 939         |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011172332 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1292        |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 941         |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010718985 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.338       |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.929       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1218528, episode_reward=1.86 +/- 5.58\n",
      "Episode length: 26.80 +/- 9.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.8        |\n",
      "|    mean_reward          | 1.86        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1218528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013404163 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.181       |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.916       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.104    |\n",
      "| time/              |          |\n",
      "|    fps             | 1292     |\n",
      "|    iterations      | 595      |\n",
      "|    time_elapsed    | 942      |\n",
      "|    total_timesteps | 1218560  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.392       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 596          |\n",
      "|    time_elapsed         | 943          |\n",
      "|    total_timesteps      | 1220608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112529015 |\n",
      "|    clip_fraction        | 0.0817       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0892       |\n",
      "|    n_updates            | 10840        |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 1.74         |\n",
      "|    value_loss           | 0.381        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.0406      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 597          |\n",
      "|    time_elapsed         | 945          |\n",
      "|    total_timesteps      | 1222656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137848295 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.93        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 10850        |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    std                  | 1.72         |\n",
      "|    value_loss           | 0.329        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 946         |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009915134 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.466       |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 0.964       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.638      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 948         |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013162616 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.625       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1228528, episode_reward=0.03 +/- 6.84\n",
      "Episode length: 27.90 +/- 11.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.9        |\n",
      "|    mean_reward          | 0.027       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1228528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010532689 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.297       |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 0.842       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.4     |\n",
      "|    ep_rew_mean     | -1.21    |\n",
      "| time/              |          |\n",
      "|    fps             | 1294     |\n",
      "|    iterations      | 600      |\n",
      "|    time_elapsed    | 949      |\n",
      "|    total_timesteps | 1228800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.33       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 951         |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009845827 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.518       |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.257       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 952         |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014937056 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00112    |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.5       |\n",
      "|    ep_rew_mean          | 0.442      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1293       |\n",
      "|    iterations           | 603        |\n",
      "|    time_elapsed         | 954        |\n",
      "|    total_timesteps      | 1234944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01645967 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.93      |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0244     |\n",
      "|    n_updates            | 10910      |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 0.258      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.166       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 604          |\n",
      "|    time_elapsed         | 956          |\n",
      "|    total_timesteps      | 1236992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119190775 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.25         |\n",
      "|    n_updates            | 10920        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 1.74         |\n",
      "|    value_loss           | 0.764        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1238528, episode_reward=-0.21 +/- 4.17\n",
      "Episode length: 29.30 +/- 6.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.3        |\n",
      "|    mean_reward          | -0.212      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1238528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012140239 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.199       |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.489       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -0.696   |\n",
      "| time/              |          |\n",
      "|    fps             | 1293     |\n",
      "|    iterations      | 605      |\n",
      "|    time_elapsed    | 957      |\n",
      "|    total_timesteps | 1239040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.47       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012053214 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.325       |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 1           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 961         |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008008389 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 0.64        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | -0.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1293         |\n",
      "|    iterations           | 608          |\n",
      "|    time_elapsed         | 962          |\n",
      "|    total_timesteps      | 1245184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107771065 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.98        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.397        |\n",
      "|    n_updates            | 10960        |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    std                  | 1.77         |\n",
      "|    value_loss           | 0.84         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.311      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013087088 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 0.62        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1248528, episode_reward=2.04 +/- 3.87\n",
      "Episode length: 28.50 +/- 6.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.5        |\n",
      "|    mean_reward          | 2.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1248528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013493716 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.356       |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.528   |\n",
      "| time/              |          |\n",
      "|    fps             | 1293     |\n",
      "|    iterations      | 610      |\n",
      "|    time_elapsed    | 965      |\n",
      "|    total_timesteps | 1249280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.798      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1293        |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 967         |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011750096 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.936       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.256      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 968         |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015340844 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0359     |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 0.0984      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.894      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 969         |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013366785 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0425      |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.107      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 970         |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007201829 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 0.806       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1258528, episode_reward=-1.89 +/- 3.57\n",
      "Episode length: 33.30 +/- 4.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.3        |\n",
      "|    mean_reward          | -1.89       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1258528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009460603 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.552       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.104   |\n",
      "| time/              |          |\n",
      "|    fps             | 1294     |\n",
      "|    iterations      | 615      |\n",
      "|    time_elapsed    | 972      |\n",
      "|    total_timesteps | 1259520  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -0.0397     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 974         |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011948636 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.283       |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.593       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 975         |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010955169 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.33        |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 0.833       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 976         |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009301599 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.95       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.028      |\n",
      "|    n_updates            | 11060       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.367      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 978         |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010743875 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.545       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1268528, episode_reward=-0.64 +/- 5.86\n",
      "Episode length: 33.10 +/- 16.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.1        |\n",
      "|    mean_reward          | -0.64       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1268528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014695006 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.191       |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.588       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.378   |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 620      |\n",
      "|    time_elapsed    | 979      |\n",
      "|    total_timesteps | 1269760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.0371      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 981         |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011927149 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.96       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.314       |\n",
      "|    n_updates            | 11090       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 0.747       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.364      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 982         |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011527177 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.659       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.687      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 984         |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009845266 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.358       |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.189      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 985         |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014412837 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 0.885       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1278528, episode_reward=0.37 +/- 4.75\n",
      "Episode length: 33.90 +/- 13.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.9        |\n",
      "|    mean_reward          | 0.374       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1278528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010618458 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00903     |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.204   |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 625      |\n",
      "|    time_elapsed    | 987      |\n",
      "|    total_timesteps | 1280000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.414      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013563351 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.455       |\n",
      "|    n_updates            | 11140       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.652      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 990         |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012414711 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 0.511       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.3        |\n",
      "|    ep_rew_mean          | -1.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 991         |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008462183 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 0.935       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.2        |\n",
      "|    ep_rew_mean          | -1.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 993         |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009958652 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.169       |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 0.653       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1288528, episode_reward=-2.44 +/- 6.61\n",
      "Episode length: 35.30 +/- 13.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.3        |\n",
      "|    mean_reward          | -2.44       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1288528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007092433 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 0.73        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.831   |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 630      |\n",
      "|    time_elapsed    | 995      |\n",
      "|    total_timesteps | 1290240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.594       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 996         |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009019925 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 0.667       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.577       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 997         |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012696054 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 0.424       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.144       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 999         |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018416835 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.03       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00297     |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29         |\n",
      "|    ep_rew_mean          | 0.276      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1297       |\n",
      "|    iterations           | 634        |\n",
      "|    time_elapsed         | 1001       |\n",
      "|    total_timesteps      | 1298432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01331515 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4         |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0256     |\n",
      "|    n_updates            | 11220      |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 1.79       |\n",
      "|    value_loss           | 0.263      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1298528, episode_reward=-0.76 +/- 4.72\n",
      "Episode length: 30.40 +/- 7.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.4        |\n",
      "|    mean_reward          | -0.763      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1298528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013555637 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0489     |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 0.0521      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.369    |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 635      |\n",
      "|    time_elapsed    | 1002     |\n",
      "|    total_timesteps | 1300480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.644      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 1004        |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013419809 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 11240       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.103       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 1005        |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016139694 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.533       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.239      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 1007        |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011824729 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0415     |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 0.054       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1308528, episode_reward=-0.09 +/- 4.00\n",
      "Episode length: 31.50 +/- 5.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.5        |\n",
      "|    mean_reward          | -0.0909     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1308528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011630852 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 0.516       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.916   |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 639      |\n",
      "|    time_elapsed    | 1009     |\n",
      "|    total_timesteps | 1308672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.625      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 1010        |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013494849 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0554      |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.261      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 1012        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010204279 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.39        |\n",
      "|    n_updates            | 11290       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.771       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.897      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 1013        |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011940543 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.395      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 1015        |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009027744 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.507       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1318528, episode_reward=-0.30 +/- 4.88\n",
      "Episode length: 31.20 +/- 6.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.2        |\n",
      "|    mean_reward          | -0.297      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1318528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011003042 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4          |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0665      |\n",
      "|    n_updates            | 11320       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.524    |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 644      |\n",
      "|    time_elapsed    | 1017     |\n",
      "|    total_timesteps | 1318912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.234      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 1018        |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011519357 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00948    |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | -0.367     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1296       |\n",
      "|    iterations           | 646        |\n",
      "|    time_elapsed         | 1020       |\n",
      "|    total_timesteps      | 1323008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00980941 |\n",
      "|    clip_fraction        | 0.0862     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4         |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.23       |\n",
      "|    n_updates            | 11340      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 1.79       |\n",
      "|    value_loss           | 0.771      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | -0.0296     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 1021        |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017928738 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0478     |\n",
      "|    n_updates            | 11350       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 0.0691      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 1023        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015525046 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00978     |\n",
      "|    n_updates            | 11360       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1328528, episode_reward=1.69 +/- 5.52\n",
      "Episode length: 26.90 +/- 8.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 26.9       |\n",
      "|    mean_reward          | 1.69       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1328528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01050918 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.09      |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.699      |\n",
      "|    n_updates            | 11370      |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    std                  | 1.89       |\n",
      "|    value_loss           | 1.25       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.2     |\n",
      "|    ep_rew_mean     | -1.18    |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 649      |\n",
      "|    time_elapsed    | 1025     |\n",
      "|    total_timesteps | 1329152  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.397      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 1026        |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009428559 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.351       |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 0.875       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 0.202        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 1028         |\n",
      "|    total_timesteps      | 1333248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0123057645 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0886       |\n",
      "|    n_updates            | 11390        |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    std                  | 1.88         |\n",
      "|    value_loss           | 0.384        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.355        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1296         |\n",
      "|    iterations           | 652          |\n",
      "|    time_elapsed         | 1029         |\n",
      "|    total_timesteps      | 1335296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127899945 |\n",
      "|    clip_fraction        | 0.0984       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.09        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0329      |\n",
      "|    n_updates            | 11400        |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    std                  | 1.86         |\n",
      "|    value_loss           | 0.107        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.975      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 1031        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010136636 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00366     |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1338528, episode_reward=3.82 +/- 2.91\n",
      "Episode length: 24.10 +/- 5.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 24.1         |\n",
      "|    mean_reward          | 3.82         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1338528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106533095 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.05        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0856       |\n",
      "|    n_updates            | 11420        |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    std                  | 1.83         |\n",
      "|    value_loss           | 0.381        |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -1.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 1295     |\n",
      "|    iterations      | 654      |\n",
      "|    time_elapsed    | 1033     |\n",
      "|    total_timesteps | 1339392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.133      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1295        |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 1035        |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013515009 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.331       |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 0.811       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.629       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 1036        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010807486 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.273       |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 0.727       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.266       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013632709 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.06       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0483     |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 0.0656      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.227      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 1039        |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012248512 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.07       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0939      |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 0.354       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1348528, episode_reward=-0.71 +/- 4.04\n",
      "Episode length: 31.60 +/- 6.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.6        |\n",
      "|    mean_reward          | -0.712      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1348528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010282781 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.082       |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 0.353       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.526   |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 659      |\n",
      "|    time_elapsed    | 1040     |\n",
      "|    total_timesteps | 1349632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.511      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 1042        |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011139098 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.326       |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 0.737       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.00801    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 1043        |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009945057 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.31        |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 0.629       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.556      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 1045        |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009984058 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0257      |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.314      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 1046        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015266454 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.518       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1358528, episode_reward=-3.77 +/- 5.21\n",
      "Episode length: 34.90 +/- 6.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.9        |\n",
      "|    mean_reward          | -3.77       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1358528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009936973 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.4     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 1296     |\n",
      "|    iterations      | 664      |\n",
      "|    time_elapsed    | 1048     |\n",
      "|    total_timesteps | 1359872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1296        |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 1050        |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011120362 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0343      |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.0629     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 1051        |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009987185 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.874       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.294       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 1053        |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008720765 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0217      |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.0685     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 1054        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008792263 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.324       |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1368528, episode_reward=1.95 +/- 3.89\n",
      "Episode length: 26.80 +/- 5.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.8        |\n",
      "|    mean_reward          | 1.95        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1368528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010688729 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 0.656       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -1.23    |\n",
      "| time/              |          |\n",
      "|    fps             | 1297     |\n",
      "|    iterations      | 669      |\n",
      "|    time_elapsed    | 1056     |\n",
      "|    total_timesteps | 1370112  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33         |\n",
      "|    ep_rew_mean          | -1.24      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1297       |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 1057       |\n",
      "|    total_timesteps      | 1372160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00646465 |\n",
      "|    clip_fraction        | 0.0389     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.22      |\n",
      "|    explained_variance   | 0.912      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.596      |\n",
      "|    n_updates            | 11580      |\n",
      "|    policy_gradient_loss | -0.00767   |\n",
      "|    std                  | 2          |\n",
      "|    value_loss           | 1.78       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.9       |\n",
      "|    ep_rew_mean          | -0.777     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1297       |\n",
      "|    iterations           | 671        |\n",
      "|    time_elapsed         | 1059       |\n",
      "|    total_timesteps      | 1374208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01449508 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.22      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.262      |\n",
      "|    n_updates            | 11590      |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 0.688      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.7       |\n",
      "|    ep_rew_mean          | 0.0739     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1297       |\n",
      "|    iterations           | 672        |\n",
      "|    time_elapsed         | 1060       |\n",
      "|    total_timesteps      | 1376256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00980426 |\n",
      "|    clip_fraction        | 0.054      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.21      |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.215      |\n",
      "|    n_updates            | 11600      |\n",
      "|    policy_gradient_loss | -0.00835   |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 0.685      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.00934     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008666595 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0463      |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 0.335       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1378528, episode_reward=-0.93 +/- 5.10\n",
      "Episode length: 29.70 +/- 9.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | -0.929      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1378528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011071369 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.341       |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 0.93        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | 0.243    |\n",
      "| time/              |          |\n",
      "|    fps             | 1297     |\n",
      "|    iterations      | 674      |\n",
      "|    time_elapsed    | 1063     |\n",
      "|    total_timesteps | 1380352  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.1         |\n",
      "|    ep_rew_mean          | 0.813        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1297         |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 1065         |\n",
      "|    total_timesteps      | 1382400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074879727 |\n",
      "|    clip_fraction        | 0.0776       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.23        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.265        |\n",
      "|    n_updates            | 11630        |\n",
      "|    policy_gradient_loss | -0.00888     |\n",
      "|    std                  | 2.01         |\n",
      "|    value_loss           | 0.74         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.299       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 1066        |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009077644 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.339       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.404      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 1068        |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013276948 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0636      |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.346       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1388528, episode_reward=0.59 +/- 4.50\n",
      "Episode length: 28.70 +/- 7.21\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 28.7       |\n",
      "|    mean_reward          | 0.586      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1388528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00913344 |\n",
      "|    clip_fraction        | 0.0849     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.18      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.357      |\n",
      "|    n_updates            | 11660      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 1.97       |\n",
      "|    value_loss           | 0.778      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.869   |\n",
      "| time/              |          |\n",
      "|    fps             | 1297     |\n",
      "|    iterations      | 678      |\n",
      "|    time_elapsed    | 1069     |\n",
      "|    total_timesteps | 1388544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.915      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 1071        |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007291054 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.415       |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.987      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 1072        |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011388058 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.612       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.794      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 1074        |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008555691 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.223       |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.364      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 1075        |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013865388 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0365      |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.592       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1398528, episode_reward=0.22 +/- 4.72\n",
      "Episode length: 28.40 +/- 8.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.4        |\n",
      "|    mean_reward          | 0.219       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1398528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013291682 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.555       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | 0.0822   |\n",
      "| time/              |          |\n",
      "|    fps             | 1298     |\n",
      "|    iterations      | 683      |\n",
      "|    time_elapsed    | 1077     |\n",
      "|    total_timesteps | 1398784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.282       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 1078        |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008332854 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.255       |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.818       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.6       |\n",
      "|    ep_rew_mean          | 0.268      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1298       |\n",
      "|    iterations           | 685        |\n",
      "|    time_elapsed         | 1080       |\n",
      "|    total_timesteps      | 1402880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01404447 |\n",
      "|    clip_fraction        | 0.0886     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.17      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.247      |\n",
      "|    n_updates            | 11730      |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 0.744      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.0926     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 1081        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009277919 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.482       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.461       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 1083        |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011223331 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.453       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1408528, episode_reward=-1.92 +/- 5.87\n",
      "Episode length: 32.90 +/- 6.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.9        |\n",
      "|    mean_reward          | -1.92       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1408528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012974402 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.0397  |\n",
      "| time/              |          |\n",
      "|    fps             | 1298     |\n",
      "|    iterations      | 688      |\n",
      "|    time_elapsed    | 1085     |\n",
      "|    total_timesteps | 1409024  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.7       |\n",
      "|    ep_rew_mean          | -1.07      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1298       |\n",
      "|    iterations           | 689        |\n",
      "|    time_elapsed         | 1086       |\n",
      "|    total_timesteps      | 1411072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01197644 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.17      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.058      |\n",
      "|    n_updates            | 11770      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 0.299      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.4        |\n",
      "|    ep_rew_mean          | -1.78       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 1088        |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010631949 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.774       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.971      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 1090        |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015476147 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.399       |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.988       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | -0.34      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1298       |\n",
      "|    iterations           | 692        |\n",
      "|    time_elapsed         | 1091       |\n",
      "|    total_timesteps      | 1417216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00901816 |\n",
      "|    clip_fraction        | 0.0801     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.16      |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.182      |\n",
      "|    n_updates            | 11800      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 0.481      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1418528, episode_reward=0.21 +/- 5.07\n",
      "Episode length: 29.00 +/- 8.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29         |\n",
      "|    mean_reward          | 0.207      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1418528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01308882 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.18      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.284      |\n",
      "|    n_updates            | 11810      |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 1.97       |\n",
      "|    value_loss           | 0.652      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.289   |\n",
      "| time/              |          |\n",
      "|    fps             | 1297     |\n",
      "|    iterations      | 693      |\n",
      "|    time_elapsed    | 1093     |\n",
      "|    total_timesteps | 1419264  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.408      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 1095        |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011669684 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.309       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.144      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 1096        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009490592 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 0.446       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.176      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 1097        |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009509446 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.347       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 1099        |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012927452 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.227       |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 0.83        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1428528, episode_reward=-0.77 +/- 7.97\n",
      "Episode length: 27.50 +/- 11.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.5        |\n",
      "|    mean_reward          | -0.773      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1428528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012865804 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 0.486       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.143    |\n",
      "| time/              |          |\n",
      "|    fps             | 1297     |\n",
      "|    iterations      | 698      |\n",
      "|    time_elapsed    | 1101     |\n",
      "|    total_timesteps | 1429504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.648      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 699         |\n",
      "|    time_elapsed         | 1103        |\n",
      "|    total_timesteps      | 1431552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012472354 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33.1       |\n",
      "|    ep_rew_mean          | -0.754     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1297       |\n",
      "|    iterations           | 700        |\n",
      "|    time_elapsed         | 1104       |\n",
      "|    total_timesteps      | 1433600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01001813 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.12      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.28       |\n",
      "|    n_updates            | 11880      |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 0.818      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | 0.167       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 1106        |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006884343 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.504       |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -0.677      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 1107        |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012133972 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 0.555       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1438528, episode_reward=0.49 +/- 6.08\n",
      "Episode length: 28.20 +/- 8.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.2        |\n",
      "|    mean_reward          | 0.485       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1438528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008945076 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.409       |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.3     |\n",
      "|    ep_rew_mean     | -0.934   |\n",
      "| time/              |          |\n",
      "|    fps             | 1298     |\n",
      "|    iterations      | 703      |\n",
      "|    time_elapsed    | 1109     |\n",
      "|    total_timesteps | 1439744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 1110        |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010827049 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 11920       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 0.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.678      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 1112        |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009345082 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.443       |\n",
      "|    n_updates            | 11930       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.847      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 1113        |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010940757 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.572       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.709      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 1114        |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008723523 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0931      |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1448528, episode_reward=-1.79 +/- 5.40\n",
      "Episode length: 34.70 +/- 13.59\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 34.7       |\n",
      "|    mean_reward          | -1.79      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1448528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01628423 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.13      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.234      |\n",
      "|    n_updates            | 11960      |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 1.91       |\n",
      "|    value_loss           | 0.609      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | 0.0124   |\n",
      "| time/              |          |\n",
      "|    fps             | 1298     |\n",
      "|    iterations      | 708      |\n",
      "|    time_elapsed    | 1116     |\n",
      "|    total_timesteps | 1449984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.231       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 1118        |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011740973 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.605       |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 1.92        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.413      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 1119        |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014049551 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.15       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.494      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 1121        |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011988357 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.401       |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 1123        |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009714036 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.83        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1458528, episode_reward=2.37 +/- 4.51\n",
      "Episode length: 26.60 +/- 7.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.6        |\n",
      "|    mean_reward          | 2.37        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1458528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009317109 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.799       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.664   |\n",
      "| time/              |          |\n",
      "|    fps             | 1298     |\n",
      "|    iterations      | 713      |\n",
      "|    time_elapsed    | 1124     |\n",
      "|    total_timesteps | 1460224  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.631      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 1126        |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327916 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.921       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.519      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 1127        |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011049177 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0573      |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 0.424       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.152       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 1129        |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012047769 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0379      |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.424      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 1131        |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012469953 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.196       |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.743       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1468528, episode_reward=0.57 +/- 5.04\n",
      "Episode length: 29.40 +/- 6.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.568       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1468528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012273865 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0543      |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.851   |\n",
      "| time/              |          |\n",
      "|    fps             | 1297     |\n",
      "|    iterations      | 718      |\n",
      "|    time_elapsed    | 1133     |\n",
      "|    total_timesteps | 1470464  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.368       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1297         |\n",
      "|    iterations           | 719          |\n",
      "|    time_elapsed         | 1134         |\n",
      "|    total_timesteps      | 1472512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099671045 |\n",
      "|    clip_fraction        | 0.0982       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.16        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.234        |\n",
      "|    n_updates            | 12070        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    std                  | 1.95         |\n",
      "|    value_loss           | 0.596        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 29.6      |\n",
      "|    ep_rew_mean          | 0.588     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1297      |\n",
      "|    iterations           | 720       |\n",
      "|    time_elapsed         | 1136      |\n",
      "|    total_timesteps      | 1474560   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0164161 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.17     |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0586   |\n",
      "|    n_updates            | 12080     |\n",
      "|    policy_gradient_loss | -0.0168   |\n",
      "|    std                  | 1.94      |\n",
      "|    value_loss           | 0.0402    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.293       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 1137        |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010558323 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.469       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1478528, episode_reward=2.20 +/- 6.66\n",
      "Episode length: 25.20 +/- 10.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.2        |\n",
      "|    mean_reward          | 2.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1478528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011270431 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.563       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.628   |\n",
      "| time/              |          |\n",
      "|    fps             | 1297     |\n",
      "|    iterations      | 722      |\n",
      "|    time_elapsed    | 1139     |\n",
      "|    total_timesteps | 1478656  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 0.154        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1297         |\n",
      "|    iterations           | 723          |\n",
      "|    time_elapsed         | 1141         |\n",
      "|    total_timesteps      | 1480704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116603235 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.15        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.378        |\n",
      "|    n_updates            | 12110        |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 1.93         |\n",
      "|    value_loss           | 0.942        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.132      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 1142        |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010245299 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.372       |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.894       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.252      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 1144        |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012093786 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0085      |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.44       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1297        |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 1145        |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011293093 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.493       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1488528, episode_reward=1.16 +/- 5.20\n",
      "Episode length: 28.10 +/- 9.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28.1         |\n",
      "|    mean_reward          | 1.16         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1488528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128493495 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0766       |\n",
      "|    n_updates            | 12150        |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    std                  | 1.94         |\n",
      "|    value_loss           | 0.366        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.81    |\n",
      "| time/              |          |\n",
      "|    fps             | 1298     |\n",
      "|    iterations      | 727      |\n",
      "|    time_elapsed    | 1146     |\n",
      "|    total_timesteps | 1488896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | -1.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 1148        |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009349505 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.498       |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.409      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 1149        |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011450647 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0689      |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.414       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.193       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 1151        |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013085182 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.344       |\n",
      "|    n_updates            | 12180       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.709       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.3         |\n",
      "|    ep_rew_mean          | 0.257        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1298         |\n",
      "|    iterations           | 731          |\n",
      "|    time_elapsed         | 1152         |\n",
      "|    total_timesteps      | 1497088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078049325 |\n",
      "|    clip_fraction        | 0.0523       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.17        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0163      |\n",
      "|    n_updates            | 12190        |\n",
      "|    policy_gradient_loss | -0.00845     |\n",
      "|    std                  | 1.94         |\n",
      "|    value_loss           | 0.17         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1498528, episode_reward=3.28 +/- 4.33\n",
      "Episode length: 25.60 +/- 7.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.6        |\n",
      "|    mean_reward          | 3.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1498528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010536705 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.5     |\n",
      "|    ep_rew_mean     | 0.162    |\n",
      "| time/              |          |\n",
      "|    fps             | 1298     |\n",
      "|    iterations      | 732      |\n",
      "|    time_elapsed    | 1154     |\n",
      "|    total_timesteps | 1499136  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.76       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1298        |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 1155        |\n",
      "|    total_timesteps      | 1501184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015034024 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.345       |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.662       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -0.245       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1299         |\n",
      "|    iterations           | 734          |\n",
      "|    time_elapsed         | 1157         |\n",
      "|    total_timesteps      | 1503232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116541535 |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.17        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.254        |\n",
      "|    n_updates            | 12220        |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 1.94         |\n",
      "|    value_loss           | 0.714        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.483      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 1158        |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013108436 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.46       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 1160        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012977638 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1508528, episode_reward=-1.14 +/- 4.86\n",
      "Episode length: 30.60 +/- 8.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.6        |\n",
      "|    mean_reward          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1508528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012265024 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 12250       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 0.54        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.32    |\n",
      "| time/              |          |\n",
      "|    fps             | 1299     |\n",
      "|    iterations      | 737      |\n",
      "|    time_elapsed    | 1161     |\n",
      "|    total_timesteps | 1509376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.297       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 1163        |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013007294 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.705       |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.765       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 1164        |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010023599 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.227       |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 0.654       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -0.769      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 740         |\n",
      "|    time_elapsed         | 1166        |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014114268 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 12280       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.0247      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 1167        |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008429678 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.554       |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1518528, episode_reward=1.28 +/- 3.40\n",
      "Episode length: 28.60 +/- 6.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.6        |\n",
      "|    mean_reward          | 1.28        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1518528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011857398 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0395     |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 0.09        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.42    |\n",
      "| time/              |          |\n",
      "|    fps             | 1299     |\n",
      "|    iterations      | 742      |\n",
      "|    time_elapsed    | 1169     |\n",
      "|    total_timesteps | 1519616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1299        |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 1170        |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024287572 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.588       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.825       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1300         |\n",
      "|    iterations           | 744          |\n",
      "|    time_elapsed         | 1171         |\n",
      "|    total_timesteps      | 1523712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101392055 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.21        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.44         |\n",
      "|    n_updates            | 12320        |\n",
      "|    policy_gradient_loss | -0.00982     |\n",
      "|    std                  | 1.99         |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.504      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1300        |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 1173        |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010683512 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 0.633       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.54       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 1174        |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009513469 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.265       |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 0.671       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1528528, episode_reward=2.43 +/- 3.97\n",
      "Episode length: 26.10 +/- 6.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.1         |\n",
      "|    mean_reward          | 2.43         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1528528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124407895 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0628       |\n",
      "|    n_updates            | 12350        |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    std                  | 1.97         |\n",
      "|    value_loss           | 0.356        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | 0.0117   |\n",
      "| time/              |          |\n",
      "|    fps             | 1301     |\n",
      "|    iterations      | 747      |\n",
      "|    time_elapsed    | 1175     |\n",
      "|    total_timesteps | 1529856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.801      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 1176        |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010247892 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 12360       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.76        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1301         |\n",
      "|    iterations           | 749          |\n",
      "|    time_elapsed         | 1178         |\n",
      "|    total_timesteps      | 1533952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093427645 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 12370        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 1.98         |\n",
      "|    value_loss           | 0.456        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 1180        |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010546237 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.376       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.83       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 1181        |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012659688 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 0.406       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1538528, episode_reward=0.91 +/- 3.67\n",
      "Episode length: 29.00 +/- 5.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 0.906       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1538528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012841997 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 0.479       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.3     |\n",
      "|    ep_rew_mean     | -0.989   |\n",
      "| time/              |          |\n",
      "|    fps             | 1301     |\n",
      "|    iterations      | 752      |\n",
      "|    time_elapsed    | 1183     |\n",
      "|    total_timesteps | 1540096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.224       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 1184        |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013683441 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.26       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 12410       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 0.875       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.379       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 1186        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014587355 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0866      |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.892       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 755         |\n",
      "|    time_elapsed         | 1187        |\n",
      "|    total_timesteps      | 1546240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010981286 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.3        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.192       |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 2.09        |\n",
      "|    value_loss           | 0.559       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.2       |\n",
      "|    ep_rew_mean          | -0.0326    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1301       |\n",
      "|    iterations           | 756        |\n",
      "|    time_elapsed         | 1189       |\n",
      "|    total_timesteps      | 1548288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01192208 |\n",
      "|    clip_fraction        | 0.0964     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.32      |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 12440      |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 2.11       |\n",
      "|    value_loss           | 0.479      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1548528, episode_reward=-1.66 +/- 6.03\n",
      "Episode length: 32.30 +/- 9.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.3        |\n",
      "|    mean_reward          | -1.66       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1548528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013262669 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.33       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 0.814       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.411   |\n",
      "| time/              |          |\n",
      "|    fps             | 1301     |\n",
      "|    iterations      | 757      |\n",
      "|    time_elapsed    | 1190     |\n",
      "|    total_timesteps | 1550336  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.201       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 1192        |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010200381 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 12460       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 0.677       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.701       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 759          |\n",
      "|    time_elapsed         | 1193         |\n",
      "|    total_timesteps      | 1554432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071035046 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.32        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0249      |\n",
      "|    n_updates            | 12470        |\n",
      "|    policy_gradient_loss | -0.00979     |\n",
      "|    std                  | 2.08         |\n",
      "|    value_loss           | 0.131        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31         |\n",
      "|    ep_rew_mean          | -0.503     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1301       |\n",
      "|    iterations           | 760        |\n",
      "|    time_elapsed         | 1195       |\n",
      "|    total_timesteps      | 1556480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01280799 |\n",
      "|    clip_fraction        | 0.0933     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.3       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.2        |\n",
      "|    n_updates            | 12480      |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 2.08       |\n",
      "|    value_loss           | 0.619      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1558528, episode_reward=2.35 +/- 4.25\n",
      "Episode length: 27.00 +/- 8.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 2.35        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016191076 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0273      |\n",
      "|    n_updates            | 12490       |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.689   |\n",
      "| time/              |          |\n",
      "|    fps             | 1301     |\n",
      "|    iterations      | 761      |\n",
      "|    time_elapsed    | 1197     |\n",
      "|    total_timesteps | 1558528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.492      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 1198        |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008264508 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 0.759       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31         |\n",
      "|    ep_rew_mean          | -0.137     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1302       |\n",
      "|    iterations           | 763        |\n",
      "|    time_elapsed         | 1199       |\n",
      "|    total_timesteps      | 1562624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01080808 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.32      |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.242      |\n",
      "|    n_updates            | 12510      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 2.1        |\n",
      "|    value_loss           | 0.394      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.371      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 1201        |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010277374 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.32       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 12520       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 0.634       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | -0.662       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 765          |\n",
      "|    time_elapsed         | 1203         |\n",
      "|    total_timesteps      | 1566720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071444204 |\n",
      "|    clip_fraction        | 0.0929       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.33        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.182        |\n",
      "|    n_updates            | 12530        |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 2.12         |\n",
      "|    value_loss           | 0.508        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1568528, episode_reward=1.07 +/- 4.87\n",
      "Episode length: 27.90 +/- 8.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.9        |\n",
      "|    mean_reward          | 1.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1568528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008101488 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.34       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.398       |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.12        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.813   |\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 766      |\n",
      "|    time_elapsed    | 1204     |\n",
      "|    total_timesteps | 1568768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.371       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 767         |\n",
      "|    time_elapsed         | 1206        |\n",
      "|    total_timesteps      | 1570816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009826288 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.34       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 12550       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 0.795       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.198      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 1207        |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008703718 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.36       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0614      |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 0.357       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | -0.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 769          |\n",
      "|    time_elapsed         | 1208         |\n",
      "|    total_timesteps      | 1574912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117980465 |\n",
      "|    clip_fraction        | 0.0808       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.358        |\n",
      "|    n_updates            | 12570        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 2.19         |\n",
      "|    value_loss           | 0.949        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 1210        |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012212286 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 0.591       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1578528, episode_reward=-0.99 +/- 5.89\n",
      "Episode length: 37.10 +/- 14.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 37.1        |\n",
      "|    mean_reward          | -0.987      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1578528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011525257 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.205       |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 0.648       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.0911  |\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 771      |\n",
      "|    time_elapsed    | 1212     |\n",
      "|    total_timesteps | 1579008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.314      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 1213        |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009282917 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.428       |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 1214        |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008546389 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.43       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 2.21        |\n",
      "|    value_loss           | 0.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.578      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 1216        |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012923101 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.42       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.733      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016273487 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.44       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0971      |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 0.339       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1588528, episode_reward=0.57 +/- 4.54\n",
      "Episode length: 28.20 +/- 7.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.2        |\n",
      "|    mean_reward          | 0.566       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1588528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011099877 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.46       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 0.509       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.7     |\n",
      "|    ep_rew_mean     | -1.48    |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 776      |\n",
      "|    time_elapsed    | 1219     |\n",
      "|    total_timesteps | 1589248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | -1.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 777         |\n",
      "|    time_elapsed         | 1221        |\n",
      "|    total_timesteps      | 1591296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009780502 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.47       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.588       |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.86       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 1222        |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006890619 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.48       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.564       |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 2.26        |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.621      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 1223        |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010712951 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.47       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.09        |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 0.419       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.589      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 1225        |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013102912 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.48       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0979      |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1598528, episode_reward=-4.29 +/- 4.83\n",
      "Episode length: 35.00 +/- 6.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 35         |\n",
      "|    mean_reward          | -4.29      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1598528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01254611 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.5       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.161      |\n",
      "|    n_updates            | 12690      |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 2.31       |\n",
      "|    value_loss           | 0.389      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.21    |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 781      |\n",
      "|    time_elapsed    | 1226     |\n",
      "|    total_timesteps | 1599488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.724      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 782         |\n",
      "|    time_elapsed         | 1228        |\n",
      "|    total_timesteps      | 1601536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010111967 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 12700       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 0.355       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.658       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 783          |\n",
      "|    time_elapsed         | 1230         |\n",
      "|    total_timesteps      | 1603584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096350275 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.54        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.378        |\n",
      "|    n_updates            | 12710        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    std                  | 2.35         |\n",
      "|    value_loss           | 0.725        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.757      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 1231        |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012333707 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 0.397       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 1233        |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009191011 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.187       |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 0.925       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1608528, episode_reward=4.86 +/- 2.76\n",
      "Episode length: 23.60 +/- 5.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 23.6        |\n",
      "|    mean_reward          | 4.86        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1608528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011099826 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.49       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 0.649       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -1.66    |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 786      |\n",
      "|    time_elapsed    | 1234     |\n",
      "|    total_timesteps | 1609728  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.9         |\n",
      "|    ep_rew_mean          | -1.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 787          |\n",
      "|    time_elapsed         | 1235         |\n",
      "|    total_timesteps      | 1611776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075325766 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.5         |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.41         |\n",
      "|    n_updates            | 12750        |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    std                  | 2.31         |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.83       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 1237        |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013644397 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.196       |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 0.722       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34          |\n",
      "|    ep_rew_mean          | -1.54       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 1238        |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007008148 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 12770       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 0.472       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.162      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 1240        |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008006851 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.403       |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1618528, episode_reward=2.10 +/- 4.38\n",
      "Episode length: 27.50 +/- 9.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.5        |\n",
      "|    mean_reward          | 2.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1618528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008433817 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 0.746       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.254   |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 791      |\n",
      "|    time_elapsed    | 1242     |\n",
      "|    total_timesteps | 1619968  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.5       |\n",
      "|    ep_rew_mean          | -0.928     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1304       |\n",
      "|    iterations           | 792        |\n",
      "|    time_elapsed         | 1243       |\n",
      "|    total_timesteps      | 1622016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00989821 |\n",
      "|    clip_fraction        | 0.0866     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.5       |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.51       |\n",
      "|    n_updates            | 12800      |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 1.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.746      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 1245        |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013616735 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 0.626       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | -1.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 1246        |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011463524 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.5        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.266       |\n",
      "|    n_updates            | 12820       |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 0.685       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.5         |\n",
      "|    ep_rew_mean          | -0.72        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 1248         |\n",
      "|    total_timesteps      | 1628160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079480745 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.51        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.372        |\n",
      "|    n_updates            | 12830        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 2.32         |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1628528, episode_reward=-1.57 +/- 3.87\n",
      "Episode length: 32.70 +/- 5.25\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 32.7       |\n",
      "|    mean_reward          | -1.57      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1628528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00790628 |\n",
      "|    clip_fraction        | 0.0743     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.52      |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.401      |\n",
      "|    n_updates            | 12840      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 0.999      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.3     |\n",
      "|    ep_rew_mean     | -1.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 796      |\n",
      "|    time_elapsed    | 1249     |\n",
      "|    total_timesteps | 1630208  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.358      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 1251        |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009636586 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 0.614       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.1       |\n",
      "|    ep_rew_mean          | -0.592     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1304       |\n",
      "|    iterations           | 798        |\n",
      "|    time_elapsed         | 1253       |\n",
      "|    total_timesteps      | 1634304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01184378 |\n",
      "|    clip_fraction        | 0.0858     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.51      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0347     |\n",
      "|    n_updates            | 12860      |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 0.231      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.4       |\n",
      "|    ep_rew_mean          | -0.181     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1304       |\n",
      "|    iterations           | 799        |\n",
      "|    time_elapsed         | 1254       |\n",
      "|    total_timesteps      | 1636352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01174363 |\n",
      "|    clip_fraction        | 0.0929     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.51      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0891     |\n",
      "|    n_updates            | 12870      |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    std                  | 2.29       |\n",
      "|    value_loss           | 0.372      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.598      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 1255        |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012324939 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.51       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0448      |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1638528, episode_reward=0.88 +/- 3.77\n",
      "Episode length: 29.40 +/- 5.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.877       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1638528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009778135 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 12890       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 0.52        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | 0.307    |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 801      |\n",
      "|    time_elapsed    | 1257     |\n",
      "|    total_timesteps | 1640448  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.0287     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 1259        |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013027057 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 12900       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 0.761       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.754      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 1260        |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012172929 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0999      |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 0.391       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.432      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 1261        |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008908074 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.56       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 12920       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 0.689       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1648528, episode_reward=-0.11 +/- 5.25\n",
      "Episode length: 29.90 +/- 8.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.9         |\n",
      "|    mean_reward          | -0.108       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1648528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103121465 |\n",
      "|    clip_fraction        | 0.0846       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.55        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0736       |\n",
      "|    n_updates            | 12930        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 2.34         |\n",
      "|    value_loss           | 0.367        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.449    |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 805      |\n",
      "|    time_elapsed    | 1263     |\n",
      "|    total_timesteps | 1648640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.337       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 1264        |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011807824 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 12940       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 0.431       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 1265        |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008301982 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 0.581       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.3         |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 808          |\n",
      "|    time_elapsed         | 1267         |\n",
      "|    total_timesteps      | 1654784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133023085 |\n",
      "|    clip_fraction        | 0.0939       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.55        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.34         |\n",
      "|    n_updates            | 12960        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 2.33         |\n",
      "|    value_loss           | 0.942        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.552      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 1268        |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010368488 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.255       |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 0.629       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1658528, episode_reward=-1.06 +/- 5.90\n",
      "Episode length: 32.20 +/- 8.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.2         |\n",
      "|    mean_reward          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1658528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149654765 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.53        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.053        |\n",
      "|    n_updates            | 12980        |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    std                  | 2.33         |\n",
      "|    value_loss           | 0.325        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.6     |\n",
      "|    ep_rew_mean     | -0.853   |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 810      |\n",
      "|    time_elapsed    | 1270     |\n",
      "|    total_timesteps | 1658880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.428      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 1271        |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008737143 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.352       |\n",
      "|    n_updates            | 12990       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 1273        |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011310893 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 1274        |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013184493 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.169       |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 0.561       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.687      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 1276        |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012913649 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 2.34        |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1668528, episode_reward=-1.15 +/- 4.67\n",
      "Episode length: 30.40 +/- 7.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.4        |\n",
      "|    mean_reward          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1668528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010530935 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.54       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 0.328       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | -1.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 815      |\n",
      "|    time_elapsed    | 1278     |\n",
      "|    total_timesteps | 1669120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -0.995      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 816         |\n",
      "|    time_elapsed         | 1279        |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010802221 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.52       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.0649     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 1280        |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013217232 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 0.604       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.804       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 1282        |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009237498 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.57       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0524      |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 0.338       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.278      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 1283        |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013134885 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0345      |\n",
      "|    n_updates            | 13070       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 2.35        |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1678528, episode_reward=0.68 +/- 4.84\n",
      "Episode length: 29.00 +/- 7.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 0.682       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1678528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009807192 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 0.514       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.851   |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 820      |\n",
      "|    time_elapsed    | 1285     |\n",
      "|    total_timesteps | 1679360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -0.851      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 821         |\n",
      "|    time_elapsed         | 1287        |\n",
      "|    total_timesteps      | 1681408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010340003 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.55       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.239       |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2.36        |\n",
      "|    value_loss           | 0.485       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.9       |\n",
      "|    ep_rew_mean          | 0.162      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1306       |\n",
      "|    iterations           | 822        |\n",
      "|    time_elapsed         | 1288       |\n",
      "|    total_timesteps      | 1683456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00957466 |\n",
      "|    clip_fraction        | 0.0825     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.56      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.275      |\n",
      "|    n_updates            | 13100      |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 2.38       |\n",
      "|    value_loss           | 0.752      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.0113      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 1289        |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011161393 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.58       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.926      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 1291        |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011313083 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0839      |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 0.43        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1688528, episode_reward=1.46 +/- 6.01\n",
      "Episode length: 29.20 +/- 8.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.2        |\n",
      "|    mean_reward          | 1.46        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1688528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010575562 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | 0.0347   |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 825      |\n",
      "|    time_elapsed    | 1292     |\n",
      "|    total_timesteps | 1689600  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.739      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 826         |\n",
      "|    time_elapsed         | 1294        |\n",
      "|    total_timesteps      | 1691648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012422584 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.58       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 13140       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 0.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 1295        |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009409992 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0484      |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.601      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 1297        |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011705774 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 0.541       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.348      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007826529 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0146     |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1698528, episode_reward=0.73 +/- 5.43\n",
      "Episode length: 28.00 +/- 7.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 0.728       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1698528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009773015 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 13180       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 0.405       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.638    |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 830      |\n",
      "|    time_elapsed    | 1300     |\n",
      "|    total_timesteps | 1699840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.366       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 831         |\n",
      "|    time_elapsed         | 1302        |\n",
      "|    total_timesteps      | 1701888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018710403 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 0.619       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 1303        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012004849 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 13200       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 2.41        |\n",
      "|    value_loss           | 0.279       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.119       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 1305        |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009510648 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 0.595       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.716       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 1306        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009951404 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0889      |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 0.386       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1708528, episode_reward=-0.10 +/- 4.40\n",
      "Episode length: 32.50 +/- 11.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.5        |\n",
      "|    mean_reward          | -0.0955     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1708528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011547053 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.64       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.454       |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -0.843   |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 835      |\n",
      "|    time_elapsed    | 1308     |\n",
      "|    total_timesteps | 1710080  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.6       |\n",
      "|    ep_rew_mean          | -0.527     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1307       |\n",
      "|    iterations           | 836        |\n",
      "|    time_elapsed         | 1309       |\n",
      "|    total_timesteps      | 1712128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00932125 |\n",
      "|    clip_fraction        | 0.0631     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.63      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.377      |\n",
      "|    n_updates            | 13240      |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    std                  | 2.45       |\n",
      "|    value_loss           | 1.26       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | 0.228       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 1311        |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005329581 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.239       |\n",
      "|    n_updates            | 13250       |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 0.826       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | -1.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 1313        |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007679833 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 0.645       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33.9       |\n",
      "|    ep_rew_mean          | -2.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1307       |\n",
      "|    iterations           | 839        |\n",
      "|    time_elapsed         | 1314       |\n",
      "|    total_timesteps      | 1718272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00768499 |\n",
      "|    clip_fraction        | 0.0727     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.65      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.239      |\n",
      "|    n_updates            | 13270      |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 2.48       |\n",
      "|    value_loss           | 0.708      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1718528, episode_reward=-0.15 +/- 5.28\n",
      "Episode length: 33.50 +/- 12.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.5        |\n",
      "|    mean_reward          | -0.148      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1718528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009963704 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 13280       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 0.621       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33       |\n",
      "|    ep_rew_mean     | -0.971   |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 840      |\n",
      "|    time_elapsed    | 1316     |\n",
      "|    total_timesteps | 1720320  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.6       |\n",
      "|    ep_rew_mean          | -0.0866    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1306       |\n",
      "|    iterations           | 841        |\n",
      "|    time_elapsed         | 1317       |\n",
      "|    total_timesteps      | 1722368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01012903 |\n",
      "|    clip_fraction        | 0.0686     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.65      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.17       |\n",
      "|    n_updates            | 13290      |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 2.47       |\n",
      "|    value_loss           | 0.597      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.62       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 1319        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010506968 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 0.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.453       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 1321        |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011765205 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 0.692       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.328      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 1322        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010976418 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0583      |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 0.282       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1728528, episode_reward=-1.24 +/- 6.04\n",
      "Episode length: 32.00 +/- 10.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32          |\n",
      "|    mean_reward          | -1.24       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1728528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013286555 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.64       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.242       |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 0.651       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -0.896   |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 845      |\n",
      "|    time_elapsed    | 1324     |\n",
      "|    total_timesteps | 1730560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.789      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010923244 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.365       |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 0.899       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.299      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 1326        |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011664271 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.036      |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 0.0993      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 1328        |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010369699 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0785      |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 0.473       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1738528, episode_reward=0.03 +/- 5.93\n",
      "Episode length: 31.60 +/- 12.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 31.6       |\n",
      "|    mean_reward          | 0.0284     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1738528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01128105 |\n",
      "|    clip_fraction        | 0.0878     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.63      |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.126      |\n",
      "|    n_updates            | 13370      |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 2.47       |\n",
      "|    value_loss           | 0.511      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.327   |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 849      |\n",
      "|    time_elapsed    | 1330     |\n",
      "|    total_timesteps | 1738752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.266       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 850         |\n",
      "|    time_elapsed         | 1331        |\n",
      "|    total_timesteps      | 1740800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009301772 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.405       |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 2.5         |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.5       |\n",
      "|    ep_rew_mean          | -0.014     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1307       |\n",
      "|    iterations           | 851        |\n",
      "|    time_elapsed         | 1332       |\n",
      "|    total_timesteps      | 1742848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00948693 |\n",
      "|    clip_fraction        | 0.0677     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.66      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.025     |\n",
      "|    n_updates            | 13390      |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 2.51       |\n",
      "|    value_loss           | 0.138      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.7       |\n",
      "|    ep_rew_mean          | -0.227     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1307       |\n",
      "|    iterations           | 852        |\n",
      "|    time_elapsed         | 1334       |\n",
      "|    total_timesteps      | 1744896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01399856 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.67      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0881     |\n",
      "|    n_updates            | 13400      |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    std                  | 2.51       |\n",
      "|    value_loss           | 0.334      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 1336        |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012461405 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0831      |\n",
      "|    n_updates            | 13410       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.3         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1748528, episode_reward=3.23 +/- 4.20\n",
      "Episode length: 26.00 +/- 6.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26          |\n",
      "|    mean_reward          | 3.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1748528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011283571 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.27        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | 0.0013   |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 854      |\n",
      "|    time_elapsed    | 1337     |\n",
      "|    total_timesteps | 1748992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.135       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 1339        |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008017456 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.451       |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.945       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.8       |\n",
      "|    ep_rew_mean          | -0.697     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1307       |\n",
      "|    iterations           | 856        |\n",
      "|    time_elapsed         | 1340       |\n",
      "|    total_timesteps      | 1753088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00932499 |\n",
      "|    clip_fraction        | 0.0692     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.68      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.139      |\n",
      "|    n_updates            | 13440      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 2.53       |\n",
      "|    value_loss           | 0.498      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.844      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 1342        |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012336897 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00538     |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.253      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 1343        |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011913077 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0413      |\n",
      "|    n_updates            | 13460       |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1758528, episode_reward=-3.62 +/- 4.00\n",
      "Episode length: 34.70 +/- 4.52\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 34.7      |\n",
      "|    mean_reward          | -3.62     |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1758528   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0125932 |\n",
      "|    clip_fraction        | 0.105     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.68     |\n",
      "|    explained_variance   | 0.976     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0616    |\n",
      "|    n_updates            | 13470     |\n",
      "|    policy_gradient_loss | -0.0145   |\n",
      "|    std                  | 2.53      |\n",
      "|    value_loss           | 0.391     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.227   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 859      |\n",
      "|    time_elapsed    | 1344     |\n",
      "|    total_timesteps | 1759232  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.647      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 860         |\n",
      "|    time_elapsed         | 1346        |\n",
      "|    total_timesteps      | 1761280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011407485 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.636       |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.116      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 1347        |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007605193 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.221       |\n",
      "|    n_updates            | 13490       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.727       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.443      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 1349        |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010684082 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 13500       |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.939      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 1349        |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010680646 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0707      |\n",
      "|    n_updates            | 13510       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1768528, episode_reward=-0.46 +/- 3.15\n",
      "Episode length: 31.40 +/- 4.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.4        |\n",
      "|    mean_reward          | -0.463      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1768528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005198626 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.74       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.312       |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 0.896       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.204   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 864      |\n",
      "|    time_elapsed    | 1351     |\n",
      "|    total_timesteps | 1769472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.166       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 1353        |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009430528 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.353       |\n",
      "|    n_updates            | 13530       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 0.941       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.152       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 1354        |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008765339 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.77       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 13540       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 0.506       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.9       |\n",
      "|    ep_rew_mean          | -0.146     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 867        |\n",
      "|    time_elapsed         | 1355       |\n",
      "|    total_timesteps      | 1775616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01083057 |\n",
      "|    clip_fraction        | 0.0895     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.75      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0224     |\n",
      "|    n_updates            | 13550      |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 2.6        |\n",
      "|    value_loss           | 0.244      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.0923      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 1357         |\n",
      "|    total_timesteps      | 1777664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111750085 |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.73        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0234      |\n",
      "|    n_updates            | 13560        |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    std                  | 2.58         |\n",
      "|    value_loss           | 0.149        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1778528, episode_reward=1.60 +/- 7.05\n",
      "Episode length: 24.90 +/- 11.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.9        |\n",
      "|    mean_reward          | 1.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1778528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012343099 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.332       |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.142   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 869      |\n",
      "|    time_elapsed    | 1358     |\n",
      "|    total_timesteps | 1779712  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.138       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 870          |\n",
      "|    time_elapsed         | 1360         |\n",
      "|    total_timesteps      | 1781760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052957926 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.72        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.319        |\n",
      "|    n_updates            | 13580        |\n",
      "|    policy_gradient_loss | -0.00895     |\n",
      "|    std                  | 2.57         |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.681       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 871          |\n",
      "|    time_elapsed         | 1361         |\n",
      "|    total_timesteps      | 1783808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105136465 |\n",
      "|    clip_fraction        | 0.0761       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0476       |\n",
      "|    n_updates            | 13590        |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 2.54         |\n",
      "|    value_loss           | 0.32         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.7       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 872        |\n",
      "|    time_elapsed         | 1363       |\n",
      "|    total_timesteps      | 1785856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01046262 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.69      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.00311   |\n",
      "|    n_updates            | 13600      |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    std                  | 2.55       |\n",
      "|    value_loss           | 0.242      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 1364        |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010524368 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1788528, episode_reward=0.12 +/- 5.39\n",
      "Episode length: 30.70 +/- 7.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.7        |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1788528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010999126 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00844     |\n",
      "|    n_updates            | 13620       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.459   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 874      |\n",
      "|    time_elapsed    | 1366     |\n",
      "|    total_timesteps | 1789952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.516       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 1367        |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008250509 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 0.689       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.6       |\n",
      "|    ep_rew_mean          | -0.146     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 876        |\n",
      "|    time_elapsed         | 1369       |\n",
      "|    total_timesteps      | 1794048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00913366 |\n",
      "|    clip_fraction        | 0.0608     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.71      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0169    |\n",
      "|    n_updates            | 13640      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.878      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 1370        |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015189277 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.94       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 1372        |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011735331 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 13660       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 0.614       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1798528, episode_reward=0.62 +/- 3.65\n",
      "Episode length: 30.50 +/- 7.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.5        |\n",
      "|    mean_reward          | 0.621       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1798528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010361986 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.407       |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.907       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.149   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 879      |\n",
      "|    time_elapsed    | 1374     |\n",
      "|    total_timesteps | 1800192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.183      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 1375        |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007876078 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 0.844       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.586      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 1377        |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008692298 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 13690       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 0.605       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.811      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 1379        |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008733022 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | 0.107       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 1380        |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011670997 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.653       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1808528, episode_reward=0.36 +/- 5.58\n",
      "Episode length: 29.30 +/- 7.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.3        |\n",
      "|    mean_reward          | 0.357       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1808528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012166904 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.349       |\n",
      "|    n_updates            | 13720       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 0.818       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.662   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 884      |\n",
      "|    time_elapsed    | 1382     |\n",
      "|    total_timesteps | 1810432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.0663      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 1383        |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018233042 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 13730       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.528       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.46        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 1385        |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009238102 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | 0.157       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 1386        |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008170595 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.371       |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 0.881       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1818528, episode_reward=-0.16 +/- 5.90\n",
      "Episode length: 29.70 +/- 8.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | -0.156      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1818528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008378675 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.405       |\n",
      "|    n_updates            | 13760       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.32    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 888      |\n",
      "|    time_elapsed    | 1388     |\n",
      "|    total_timesteps | 1818624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | -1.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 889         |\n",
      "|    time_elapsed         | 1390        |\n",
      "|    total_timesteps      | 1820672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009118118 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 0.65        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.8       |\n",
      "|    ep_rew_mean          | -0.227     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 890        |\n",
      "|    time_elapsed         | 1391       |\n",
      "|    total_timesteps      | 1822720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01070855 |\n",
      "|    clip_fraction        | 0.096      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.67      |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.248      |\n",
      "|    n_updates            | 13780      |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 0.664      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.0544     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 1392        |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009970353 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -1.29       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 1393        |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012478263 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.283       |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.784       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1828528, episode_reward=-1.73 +/- 5.71\n",
      "Episode length: 34.10 +/- 10.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.1        |\n",
      "|    mean_reward          | -1.73       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1828528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007748256 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.293       |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.879       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -1.04    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 893      |\n",
      "|    time_elapsed    | 1395     |\n",
      "|    total_timesteps | 1828864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.386      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 894         |\n",
      "|    time_elapsed         | 1397        |\n",
      "|    total_timesteps      | 1830912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011624802 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.6         |\n",
      "|    n_updates            | 13820       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -1.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 1398        |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009859072 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 13830       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.8         |\n",
      "|    ep_rew_mean          | -0.903       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 896          |\n",
      "|    time_elapsed         | 1400         |\n",
      "|    total_timesteps      | 1835008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071122376 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.465        |\n",
      "|    n_updates            | 13840        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 2.56         |\n",
      "|    value_loss           | 1.29         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | 0.0164      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 1401        |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010666616 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 13850       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 0.794       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1838528, episode_reward=-0.05 +/- 4.55\n",
      "Episode length: 29.80 +/- 6.98\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.8       |\n",
      "|    mean_reward          | -0.053     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1838528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01064021 |\n",
      "|    clip_fraction        | 0.0794     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.67      |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.145      |\n",
      "|    n_updates            | 13860      |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 2.53       |\n",
      "|    value_loss           | 0.54       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.000249 |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 898      |\n",
      "|    time_elapsed    | 1403     |\n",
      "|    total_timesteps | 1839104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -0.546      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 1404        |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011778786 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.751       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | 0.0673      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 1406        |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011643863 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.35        |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.819       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | 0.254      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 901        |\n",
      "|    time_elapsed         | 1407       |\n",
      "|    total_timesteps      | 1845248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00803295 |\n",
      "|    clip_fraction        | 0.0828     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.68      |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.384      |\n",
      "|    n_updates            | 13890      |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 2.53       |\n",
      "|    value_loss           | 1.11       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | 0.0619       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 1409         |\n",
      "|    total_timesteps      | 1847296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097128805 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.277        |\n",
      "|    n_updates            | 13900        |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    std                  | 2.49         |\n",
      "|    value_loss           | 0.781        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1848528, episode_reward=2.69 +/- 3.21\n",
      "Episode length: 26.40 +/- 6.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 26.4       |\n",
      "|    mean_reward          | 2.69       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1848528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00841048 |\n",
      "|    clip_fraction        | 0.0539     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.64      |\n",
      "|    explained_variance   | 0.935      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.372      |\n",
      "|    n_updates            | 13910      |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 2.48       |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | 0.0793   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 903      |\n",
      "|    time_elapsed    | 1410     |\n",
      "|    total_timesteps | 1849344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.792      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 904         |\n",
      "|    time_elapsed         | 1412        |\n",
      "|    total_timesteps      | 1851392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011371274 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.322       |\n",
      "|    n_updates            | 13920       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 0.658       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.168      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 1413        |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014735055 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 13930       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 0.421       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.769      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 1415        |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013450882 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.61       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.000531    |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -1.39       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 1416        |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017024688 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.6        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0289      |\n",
      "|    n_updates            | 13950       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1858528, episode_reward=-0.10 +/- 3.62\n",
      "Episode length: 30.00 +/- 4.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | -0.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1858528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01267995 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.6       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.221      |\n",
      "|    n_updates            | 13960      |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 0.759      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -1.45    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 908      |\n",
      "|    time_elapsed    | 1418     |\n",
      "|    total_timesteps | 1859584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.754      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 1419        |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009736052 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.62       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.471       |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 0.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.364      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 1421        |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012715665 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 13980       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.266      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 1423        |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011556546 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.315       |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 0.724       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -0.609      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 1424        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012603146 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 14000       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 0.534       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1868528, episode_reward=-0.15 +/- 5.13\n",
      "Episode length: 29.40 +/- 7.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | -0.155      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1868528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008674309 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.373       |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.3     |\n",
      "|    ep_rew_mean     | -0.363   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 913      |\n",
      "|    time_elapsed    | 1426     |\n",
      "|    total_timesteps | 1869824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.267       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 914         |\n",
      "|    time_elapsed         | 1427        |\n",
      "|    total_timesteps      | 1871872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008716404 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.629       |\n",
      "|    n_updates            | 14020       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 1429        |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008367994 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 14030       |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.656      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 1430        |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011289934 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.335       |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | 0.0299       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 917          |\n",
      "|    time_elapsed         | 1431         |\n",
      "|    total_timesteps      | 1878016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093394425 |\n",
      "|    clip_fraction        | 0.0797       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.39         |\n",
      "|    n_updates            | 14050        |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    std                  | 2.6          |\n",
      "|    value_loss           | 0.92         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1878528, episode_reward=2.49 +/- 4.16\n",
      "Episode length: 26.70 +/- 8.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.7        |\n",
      "|    mean_reward          | 2.49        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1878528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009379737 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 14060       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 0.247       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.0613  |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 918      |\n",
      "|    time_elapsed    | 1433     |\n",
      "|    total_timesteps | 1880064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 1434        |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009899903 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.538       |\n",
      "|    n_updates            | 14070       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 0.947       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.816      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 1436        |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011583546 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.3         |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.359      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 921         |\n",
      "|    time_elapsed         | 1437        |\n",
      "|    total_timesteps      | 1886208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011529305 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 0.569       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.295      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 1439        |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011389397 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.74       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.234       |\n",
      "|    n_updates            | 14100       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 0.882       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1888528, episode_reward=-0.29 +/- 4.95\n",
      "Episode length: 31.00 +/- 7.04\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 31         |\n",
      "|    mean_reward          | -0.29      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1888528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01568652 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.72      |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.118      |\n",
      "|    n_updates            | 14110      |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 2.58       |\n",
      "|    value_loss           | 0.662      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 923      |\n",
      "|    time_elapsed    | 1441     |\n",
      "|    total_timesteps | 1890304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.409      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 1442        |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015230492 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 0.376       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.171      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 1444        |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012649469 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0612      |\n",
      "|    n_updates            | 14130       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.322       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.701      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 1445        |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009992491 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 14140       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.774       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -1.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 1446         |\n",
      "|    total_timesteps      | 1898496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121288905 |\n",
      "|    clip_fraction        | 0.0743       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.00703     |\n",
      "|    n_updates            | 14150        |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    std                  | 2.53         |\n",
      "|    value_loss           | 0.212        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1898528, episode_reward=-0.01 +/- 5.50\n",
      "Episode length: 29.20 +/- 9.51\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.2       |\n",
      "|    mean_reward          | -0.0068    |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1898528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01098481 |\n",
      "|    clip_fraction        | 0.0877     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.67      |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.22       |\n",
      "|    n_updates            | 14160      |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 0.681      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.1     |\n",
      "|    ep_rew_mean     | -1.45    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 928      |\n",
      "|    time_elapsed    | 1448     |\n",
      "|    total_timesteps | 1900544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -0.539      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 1450        |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008780054 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.817       |\n",
      "|    n_updates            | 14170       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -0.833      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 1451        |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010910694 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0993      |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 0.457       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.9       |\n",
      "|    ep_rew_mean          | -0.684     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 931        |\n",
      "|    time_elapsed         | 1454       |\n",
      "|    total_timesteps      | 1906688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01124634 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.65      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.142      |\n",
      "|    n_updates            | 14190      |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 0.644      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1908528, episode_reward=2.53 +/- 5.81\n",
      "Episode length: 26.50 +/- 8.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.5        |\n",
      "|    mean_reward          | 2.53        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1908528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010674546 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0705      |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.319       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.323   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 932      |\n",
      "|    time_elapsed    | 1456     |\n",
      "|    total_timesteps | 1908736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.37        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 933         |\n",
      "|    time_elapsed         | 1458        |\n",
      "|    total_timesteps      | 1910784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013155277 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.234       |\n",
      "|    n_updates            | 14210       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.758       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 0.239        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 934          |\n",
      "|    time_elapsed         | 1460         |\n",
      "|    total_timesteps      | 1912832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122874295 |\n",
      "|    clip_fraction        | 0.0986       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0433      |\n",
      "|    n_updates            | 14220        |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    std                  | 2.52         |\n",
      "|    value_loss           | 0.125        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.36       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 1462        |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017086271 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00361     |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.719      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 1464        |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015032527 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00684    |\n",
      "|    n_updates            | 14240       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1918528, episode_reward=-0.76 +/- 5.70\n",
      "Episode length: 30.80 +/- 8.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.8        |\n",
      "|    mean_reward          | -0.762      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1918528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011508103 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 0.537       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -1.02    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 937      |\n",
      "|    time_elapsed    | 1466     |\n",
      "|    total_timesteps | 1918976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.522      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 938         |\n",
      "|    time_elapsed         | 1468        |\n",
      "|    total_timesteps      | 1921024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009180633 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 0.844       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.0477      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 1469        |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013353862 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 14270       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.0876      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 1471        |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010177006 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0831      |\n",
      "|    n_updates            | 14280       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 0.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 1473        |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010778073 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.322       |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 0.587       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1928528, episode_reward=0.94 +/- 3.57\n",
      "Episode length: 30.00 +/- 5.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.938       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1928528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007561865 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 0.944       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.283   |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 942      |\n",
      "|    time_elapsed    | 1475     |\n",
      "|    total_timesteps | 1929216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.611      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 1477        |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008317181 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 14310       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 0.509       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -1.32        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 944          |\n",
      "|    time_elapsed         | 1478         |\n",
      "|    total_timesteps      | 1933312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075756554 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.74        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.595        |\n",
      "|    n_updates            | 14320        |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    std                  | 2.61         |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.0584      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 1480        |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009046005 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 0.399       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.261      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 1482        |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013208096 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00786    |\n",
      "|    n_updates            | 14340       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1938528, episode_reward=0.76 +/- 5.83\n",
      "Episode length: 29.90 +/- 8.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.9         |\n",
      "|    mean_reward          | 0.76         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1938528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0130741615 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0773       |\n",
      "|    n_updates            | 14350        |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    std                  | 2.51         |\n",
      "|    value_loss           | 0.32         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.5     |\n",
      "|    ep_rew_mean     | 0.32     |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 947      |\n",
      "|    time_elapsed    | 1484     |\n",
      "|    total_timesteps | 1939456  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | -0.0574    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1306       |\n",
      "|    iterations           | 948        |\n",
      "|    time_elapsed         | 1486       |\n",
      "|    total_timesteps      | 1941504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01077484 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.66      |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 14360      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 0.49       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.664       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 949          |\n",
      "|    time_elapsed         | 1488         |\n",
      "|    total_timesteps      | 1943552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119709205 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.68        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0307       |\n",
      "|    n_updates            | 14370        |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    std                  | 2.54         |\n",
      "|    value_loss           | 0.242        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.331       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 950          |\n",
      "|    time_elapsed         | 1490         |\n",
      "|    total_timesteps      | 1945600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137002645 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0756       |\n",
      "|    n_updates            | 14380        |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    std                  | 2.51         |\n",
      "|    value_loss           | 0.245        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 1491        |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017876796 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.65       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0678     |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 0.0398      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1948528, episode_reward=0.25 +/- 6.12\n",
      "Episode length: 30.60 +/- 9.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.6        |\n",
      "|    mean_reward          | 0.252       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1948528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016275674 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.63       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 0.728       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | 0.192    |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 952      |\n",
      "|    time_elapsed    | 1493     |\n",
      "|    total_timesteps | 1949696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.00512    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 1495        |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012859181 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0557     |\n",
      "|    n_updates            | 14410       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.561      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 1497        |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018439533 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 0.415       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.689      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 1499        |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010701841 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.67       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.655       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 1501        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009336001 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.66       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.217       |\n",
      "|    n_updates            | 14440       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 0.629       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1958528, episode_reward=0.49 +/- 3.84\n",
      "Episode length: 29.10 +/- 7.19\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.1       |\n",
      "|    mean_reward          | 0.487      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1958528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00962581 |\n",
      "|    clip_fraction        | 0.0714     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.67      |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0492     |\n",
      "|    n_updates            | 14450      |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 2.54       |\n",
      "|    value_loss           | 0.279      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -1.42    |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 957      |\n",
      "|    time_elapsed    | 1503     |\n",
      "|    total_timesteps | 1959936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.356      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 1504        |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011255849 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.263       |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 0.958       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.0395      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 1506        |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012322952 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.69       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 0.388       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.619      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 1508        |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012501085 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0587      |\n",
      "|    n_updates            | 14480       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.436      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 1510        |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013346172 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0117      |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 0.338       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1968528, episode_reward=0.85 +/- 5.61\n",
      "Episode length: 27.80 +/- 8.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.8        |\n",
      "|    mean_reward          | 0.851       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1968528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012507728 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.327       |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 0.685       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.6     |\n",
      "|    ep_rew_mean     | -0.958   |\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 962      |\n",
      "|    time_elapsed    | 1512     |\n",
      "|    total_timesteps | 1970176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 1514        |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009505987 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.235       |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 0.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 1516        |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008506885 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 14520       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 0.348       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.261      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 1517        |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013267048 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | -1.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 1519        |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012228126 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.71       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 14540       |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 0.426       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1978528, episode_reward=-3.33 +/- 5.83\n",
      "Episode length: 34.90 +/- 7.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.9        |\n",
      "|    mean_reward          | -3.33       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1978528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009229414 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.73       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.288       |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 0.801       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.587   |\n",
      "| time/              |          |\n",
      "|    fps             | 1301     |\n",
      "|    iterations      | 967      |\n",
      "|    time_elapsed    | 1521     |\n",
      "|    total_timesteps | 1980416  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.0375      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 1522        |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013281519 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.74       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 0.574       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1301        |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 1524        |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012972372 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.76       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0499      |\n",
      "|    n_updates            | 14570       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 2.65        |\n",
      "|    value_loss           | 0.328       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.0351     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 1525        |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015089053 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.77       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0511      |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1988528, episode_reward=-0.25 +/- 7.40\n",
      "Episode length: 30.00 +/- 12.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30           |\n",
      "|    mean_reward          | -0.254       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1988528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077579506 |\n",
      "|    clip_fraction        | 0.0768       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.78        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.248        |\n",
      "|    n_updates            | 14590        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 2.67         |\n",
      "|    value_loss           | 0.633        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -1.15    |\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 971      |\n",
      "|    time_elapsed    | 1527     |\n",
      "|    total_timesteps | 1988608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.441      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 1528        |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010873206 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.381       |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.409      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 1530        |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013618705 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 14610       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 2.69        |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.375      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 1531        |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010290608 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00313    |\n",
      "|    n_updates            | 14620       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.211      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 1533        |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010754291 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0567     |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 0.0608      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1998528, episode_reward=1.34 +/- 3.98\n",
      "Episode length: 27.40 +/- 7.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.4        |\n",
      "|    mean_reward          | 1.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1998528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012038907 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00584     |\n",
      "|    n_updates            | 14640       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.524   |\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 976      |\n",
      "|    time_elapsed    | 1534     |\n",
      "|    total_timesteps | 1998848  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.774       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 977          |\n",
      "|    time_elapsed         | 1536         |\n",
      "|    total_timesteps      | 2000896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066042943 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.79        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.402        |\n",
      "|    n_updates            | 14650        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    std                  | 2.69         |\n",
      "|    value_loss           | 1.23         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.7      |\n",
      "|    ep_rew_mean          | -0.103    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1302      |\n",
      "|    iterations           | 978       |\n",
      "|    time_elapsed         | 1537      |\n",
      "|    total_timesteps      | 2002944   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0106032 |\n",
      "|    clip_fraction        | 0.081     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.79     |\n",
      "|    explained_variance   | 0.986     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0166    |\n",
      "|    n_updates            | 14660     |\n",
      "|    policy_gradient_loss | -0.0134   |\n",
      "|    std                  | 2.68      |\n",
      "|    value_loss           | 0.209     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 1539        |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012241219 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.77       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.157      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 1540        |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012366922 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.77       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 14680       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2008528, episode_reward=-1.63 +/- 5.85\n",
      "Episode length: 32.80 +/- 8.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -1.63       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2008528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008904517 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.79       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 14690       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 0.516       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.472   |\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 981      |\n",
      "|    time_elapsed    | 1542     |\n",
      "|    total_timesteps | 2009088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.28        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 982         |\n",
      "|    time_elapsed         | 1543        |\n",
      "|    total_timesteps      | 2011136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005882154 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.81       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.475       |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 2.72        |\n",
      "|    value_loss           | 1.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.611       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011794221 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.8        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 14710       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 1546        |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013260587 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0872      |\n",
      "|    n_updates            | 14720       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.0311     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1302        |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 1548        |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012083379 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.82       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 14730       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 0.614       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2018528, episode_reward=2.13 +/- 4.18\n",
      "Episode length: 26.70 +/- 8.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.7        |\n",
      "|    mean_reward          | 2.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2018528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009942168 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.85       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0322      |\n",
      "|    n_updates            | 14740       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 0.262       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.108   |\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 986      |\n",
      "|    time_elapsed    | 1549     |\n",
      "|    total_timesteps | 2019328  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 987          |\n",
      "|    time_elapsed         | 1551         |\n",
      "|    total_timesteps      | 2021376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073448727 |\n",
      "|    clip_fraction        | 0.0623       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.84        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0643       |\n",
      "|    n_updates            | 14750        |\n",
      "|    policy_gradient_loss | -0.00987     |\n",
      "|    std                  | 2.75         |\n",
      "|    value_loss           | 0.347        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.459      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 1552        |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008463789 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 14760       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 0.447       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 1554        |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011160114 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.85       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 14770       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 0.526       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.359      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 1555        |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011723768 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 14780       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2028528, episode_reward=1.83 +/- 4.07\n",
      "Episode length: 28.70 +/- 6.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.7        |\n",
      "|    mean_reward          | 1.83        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2028528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007562413 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 14790       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 0.345       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.8     |\n",
      "|    ep_rew_mean     | -1.55    |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 991      |\n",
      "|    time_elapsed    | 1557     |\n",
      "|    total_timesteps | 2029568  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33           |\n",
      "|    ep_rew_mean          | -1.42        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 992          |\n",
      "|    time_elapsed         | 1559         |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077447803 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.93        |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.416        |\n",
      "|    n_updates            | 14800        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    std                  | 2.9          |\n",
      "|    value_loss           | 1.7          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -1.42       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 1560        |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008621229 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 14810       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 0.39        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.1         |\n",
      "|    ep_rew_mean          | -1.59        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 994          |\n",
      "|    time_elapsed         | 1562         |\n",
      "|    total_timesteps      | 2035712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072877496 |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.93        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0881       |\n",
      "|    n_updates            | 14820        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 2.89         |\n",
      "|    value_loss           | 0.364        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | 0.0439      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 1563        |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005124295 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 14830       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 0.898       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2038528, episode_reward=1.79 +/- 6.27\n",
      "Episode length: 26.00 +/- 11.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26          |\n",
      "|    mean_reward          | 1.79        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2038528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008835524 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 14840       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 0.548       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.428   |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 996      |\n",
      "|    time_elapsed    | 1565     |\n",
      "|    total_timesteps | 2039808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.653       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 997         |\n",
      "|    time_elapsed         | 1566        |\n",
      "|    total_timesteps      | 2041856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012735187 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.91       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 14850       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 0.502       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.0317     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 1568        |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012792319 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0438      |\n",
      "|    n_updates            | 14860       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 0.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.615      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 1569        |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008537659 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.91       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0469      |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 0.406       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.351      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 1571        |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010023286 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 0.375       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2048528, episode_reward=0.27 +/- 4.40\n",
      "Episode length: 30.00 +/- 6.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2048528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010070577 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.92       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00968     |\n",
      "|    n_updates            | 14890       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.132   |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 1001     |\n",
      "|    time_elapsed    | 1572     |\n",
      "|    total_timesteps | 2050048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 1574        |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008145131 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.91       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.318       |\n",
      "|    n_updates            | 14900       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.5         |\n",
      "|    ep_rew_mean          | 0.171        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 1575         |\n",
      "|    total_timesteps      | 2054144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107750725 |\n",
      "|    clip_fraction        | 0.0978       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0335      |\n",
      "|    n_updates            | 14910        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 2.82         |\n",
      "|    value_loss           | 0.11         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.376       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 1004        |\n",
      "|    time_elapsed         | 1577        |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014464866 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.000858    |\n",
      "|    n_updates            | 14920       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 1578        |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015064902 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0262     |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2058528, episode_reward=0.11 +/- 3.75\n",
      "Episode length: 29.90 +/- 5.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.113       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2058528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011355367 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 0.574       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.195   |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 1006     |\n",
      "|    time_elapsed    | 1580     |\n",
      "|    total_timesteps | 2060288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.731      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 1007        |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 2062336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012422714 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.095       |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.207       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 1583        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012019316 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.87       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.473       |\n",
      "|    n_updates            | 14960       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.596      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1303        |\n",
      "|    iterations           | 1009        |\n",
      "|    time_elapsed         | 1584        |\n",
      "|    total_timesteps      | 2066432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011064422 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.86       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 14970       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 0.348       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.546       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 1010         |\n",
      "|    time_elapsed         | 1586         |\n",
      "|    total_timesteps      | 2068480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069292053 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.87        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.00521     |\n",
      "|    n_updates            | 14980        |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    std                  | 2.81         |\n",
      "|    value_loss           | 0.261        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2068528, episode_reward=0.03 +/- 3.63\n",
      "Episode length: 30.30 +/- 5.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.3         |\n",
      "|    mean_reward          | 0.0294       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2068528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108749205 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 14990        |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    std                  | 2.82         |\n",
      "|    value_loss           | 0.37         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.965   |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 1011     |\n",
      "|    time_elapsed    | 1587     |\n",
      "|    total_timesteps | 2070528  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.342       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1303         |\n",
      "|    iterations           | 1012         |\n",
      "|    time_elapsed         | 1589         |\n",
      "|    total_timesteps      | 2072576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059572803 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.165        |\n",
      "|    n_updates            | 15000        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 2.81         |\n",
      "|    value_loss           | 0.637        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.171      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 1590        |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011449644 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 0.433       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.258      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 1592        |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010692706 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00728    |\n",
      "|    n_updates            | 15020       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2078528, episode_reward=-0.95 +/- 5.40\n",
      "Episode length: 34.00 +/- 12.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34          |\n",
      "|    mean_reward          | -0.951      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2078528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015506141 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 0.522       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.959   |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 1015     |\n",
      "|    time_elapsed    | 1594     |\n",
      "|    total_timesteps | 2078720  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.7         |\n",
      "|    ep_rew_mean          | -0.588       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 1016         |\n",
      "|    time_elapsed         | 1595         |\n",
      "|    total_timesteps      | 2080768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078443475 |\n",
      "|    clip_fraction        | 0.0832       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.91        |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.653        |\n",
      "|    n_updates            | 15040        |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    std                  | 2.87         |\n",
      "|    value_loss           | 1.84         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.94        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 1597        |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010946913 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0967      |\n",
      "|    n_updates            | 15050       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.019       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1018        |\n",
      "|    time_elapsed         | 1598        |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010016782 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0839      |\n",
      "|    n_updates            | 15060       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 0.316       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.408      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 1600        |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014563872 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0682      |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 0.338       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2088528, episode_reward=2.82 +/- 2.82\n",
      "Episode length: 25.50 +/- 5.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.5        |\n",
      "|    mean_reward          | 2.82        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2088528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010147726 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0799      |\n",
      "|    n_updates            | 15080       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 0.352       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.502   |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 1020     |\n",
      "|    time_elapsed    | 1601     |\n",
      "|    total_timesteps | 2088960  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | -1.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 1021         |\n",
      "|    time_elapsed         | 1603         |\n",
      "|    total_timesteps      | 2091008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059978953 |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.97        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.756        |\n",
      "|    n_updates            | 15090        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    std                  | 2.95         |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.799       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 1022         |\n",
      "|    time_elapsed         | 1604         |\n",
      "|    total_timesteps      | 2093056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094051575 |\n",
      "|    clip_fraction        | 0.0765       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0445       |\n",
      "|    n_updates            | 15100        |\n",
      "|    policy_gradient_loss | -0.00991     |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 0.354        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.279       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 1606        |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011274448 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.319       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 1607        |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008296004 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 15120       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 0.461       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2098528, episode_reward=4.24 +/- 3.51\n",
      "Episode length: 23.50 +/- 8.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 23.5        |\n",
      "|    mean_reward          | 4.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2098528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007993245 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0634      |\n",
      "|    n_updates            | 15130       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.348       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | 0.469    |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 1025     |\n",
      "|    time_elapsed    | 1609     |\n",
      "|    total_timesteps | 2099200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.248      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1026        |\n",
      "|    time_elapsed         | 1610        |\n",
      "|    total_timesteps      | 2101248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007788256 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.253       |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.0194     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 1612        |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013189582 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 15150       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.598       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.0581     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1028        |\n",
      "|    time_elapsed         | 1613        |\n",
      "|    total_timesteps      | 2105344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008152678 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 15160       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.735       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.243       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 1615        |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007676686 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0939      |\n",
      "|    n_updates            | 15170       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.353       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2108528, episode_reward=-1.82 +/- 5.16\n",
      "Episode length: 32.50 +/- 6.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.5        |\n",
      "|    mean_reward          | -1.82       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2108528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013765221 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.628       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.497   |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 1030     |\n",
      "|    time_elapsed    | 1617     |\n",
      "|    total_timesteps | 2109440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.146      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1031        |\n",
      "|    time_elapsed         | 1618        |\n",
      "|    total_timesteps      | 2111488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007523121 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.266       |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.685       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.612      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 1620        |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013394864 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 15200       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -1.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 1621        |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010261682 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.808       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.624      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 1623        |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008958984 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 15220       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2118528, episode_reward=2.40 +/- 5.06\n",
      "Episode length: 26.80 +/- 12.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.8        |\n",
      "|    mean_reward          | 2.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2118528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008121762 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.304       |\n",
      "|    n_updates            | 15230       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.618       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.0256   |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 1035     |\n",
      "|    time_elapsed    | 1624     |\n",
      "|    total_timesteps | 2119680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.689      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1036        |\n",
      "|    time_elapsed         | 1626        |\n",
      "|    total_timesteps      | 2121728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821581 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.354       |\n",
      "|    n_updates            | 15240       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.984       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.5         |\n",
      "|    ep_rew_mean          | -0.684       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 1037         |\n",
      "|    time_elapsed         | 1627         |\n",
      "|    total_timesteps      | 2123776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073491465 |\n",
      "|    clip_fraction        | 0.0734       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.02        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.19         |\n",
      "|    n_updates            | 15250        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 0.739        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.2        |\n",
      "|    ep_rew_mean          | -0.918      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 1629        |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014759204 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.326       |\n",
      "|    n_updates            | 15260       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -0.547       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 1039         |\n",
      "|    time_elapsed         | 1630         |\n",
      "|    total_timesteps      | 2127872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119589865 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.03        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.442        |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    std                  | 3.04         |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2128528, episode_reward=-0.01 +/- 6.60\n",
      "Episode length: 29.00 +/- 10.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | -0.00993    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2128528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008020578 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.851   |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 1040     |\n",
      "|    time_elapsed    | 1632     |\n",
      "|    total_timesteps | 2129920  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.963       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 1041         |\n",
      "|    time_elapsed         | 1633         |\n",
      "|    total_timesteps      | 2131968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058133127 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 15290        |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 0.375        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.285      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 1635        |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015174633 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0575     |\n",
      "|    n_updates            | 15300       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 0.0624      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.324       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1304        |\n",
      "|    iterations           | 1043        |\n",
      "|    time_elapsed         | 1636        |\n",
      "|    total_timesteps      | 2136064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015155146 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0717      |\n",
      "|    n_updates            | 15310       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.479      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 1638        |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010635544 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0803      |\n",
      "|    n_updates            | 15320       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2138528, episode_reward=3.18 +/- 3.26\n",
      "Episode length: 25.60 +/- 7.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.6        |\n",
      "|    mean_reward          | 3.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2138528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010550015 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 15330       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.413       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.517   |\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 1045     |\n",
      "|    time_elapsed    | 1639     |\n",
      "|    total_timesteps | 2140160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0122      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 1641        |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009052064 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0416      |\n",
      "|    n_updates            | 15340       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.624      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 1642        |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010925315 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 15350       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.489      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 1644        |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013167406 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 15360       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 0.621       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.9       |\n",
      "|    ep_rew_mean          | -0.341     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1305       |\n",
      "|    iterations           | 1049       |\n",
      "|    time_elapsed         | 1645       |\n",
      "|    total_timesteps      | 2148352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00942641 |\n",
      "|    clip_fraction        | 0.0729     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.03      |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.233      |\n",
      "|    n_updates            | 15370      |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    std                  | 3.02       |\n",
      "|    value_loss           | 0.792      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2148528, episode_reward=-1.53 +/- 4.58\n",
      "Episode length: 33.80 +/- 5.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.8        |\n",
      "|    mean_reward          | -1.53       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2148528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016956503 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0698      |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.296       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.274   |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 1050     |\n",
      "|    time_elapsed    | 1647     |\n",
      "|    total_timesteps | 2150400  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.8       |\n",
      "|    ep_rew_mean          | -0.518     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1305       |\n",
      "|    iterations           | 1051       |\n",
      "|    time_elapsed         | 1649       |\n",
      "|    total_timesteps      | 2152448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01260973 |\n",
      "|    clip_fraction        | 0.0935     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.01      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.127      |\n",
      "|    n_updates            | 15390      |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 3.02       |\n",
      "|    value_loss           | 0.566      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.238      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 1650        |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011916708 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.196       |\n",
      "|    n_updates            | 15400       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.524       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.156      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 1652        |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009688544 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 15410       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2158528, episode_reward=-1.23 +/- 5.68\n",
      "Episode length: 30.90 +/- 8.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.9         |\n",
      "|    mean_reward          | -1.23        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2158528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075160996 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.26         |\n",
      "|    n_updates            | 15420        |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 0.798        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.826   |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 1054     |\n",
      "|    time_elapsed    | 1653     |\n",
      "|    total_timesteps | 2158592  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.6         |\n",
      "|    ep_rew_mean          | 0.242        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 1055         |\n",
      "|    time_elapsed         | 1655         |\n",
      "|    total_timesteps      | 2160640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072917156 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.306        |\n",
      "|    n_updates            | 15430        |\n",
      "|    policy_gradient_loss | -0.00771     |\n",
      "|    std                  | 2.98         |\n",
      "|    value_loss           | 0.836        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.443       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 1656        |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009007228 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0545     |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 0.0741      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.0514      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 1658        |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012031568 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0481     |\n",
      "|    n_updates            | 15450       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.0222      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 1659        |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009962028 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 15460       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 0.603       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2168528, episode_reward=-1.41 +/- 3.15\n",
      "Episode length: 32.30 +/- 4.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.3        |\n",
      "|    mean_reward          | -1.41       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2168528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008360969 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 15470       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | -0.259   |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 1059     |\n",
      "|    time_elapsed    | 1661     |\n",
      "|    total_timesteps | 2168832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.384      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 1662        |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011538624 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 15480       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.523      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 1664        |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013534723 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.617       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 1665        |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013443384 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0623     |\n",
      "|    n_updates            | 15500       |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 0.0648      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 1667        |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027704436 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0978      |\n",
      "|    n_updates            | 15510       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2178528, episode_reward=-1.30 +/- 4.49\n",
      "Episode length: 32.50 +/- 5.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 32.5       |\n",
      "|    mean_reward          | -1.3       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2178528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00941264 |\n",
      "|    clip_fraction        | 0.0914     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.99      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.085      |\n",
      "|    n_updates            | 15520      |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 2.99       |\n",
      "|    value_loss           | 0.556      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | -1.33    |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 1064     |\n",
      "|    time_elapsed    | 1668     |\n",
      "|    total_timesteps | 2179072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1065        |\n",
      "|    time_elapsed         | 1670        |\n",
      "|    total_timesteps      | 2181120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006965113 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.879       |\n",
      "|    n_updates            | 15530       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.255        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 1671         |\n",
      "|    total_timesteps      | 2183168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077435537 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.298        |\n",
      "|    n_updates            | 15540        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 2.99         |\n",
      "|    value_loss           | 0.842        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.238      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1305       |\n",
      "|    iterations           | 1067       |\n",
      "|    time_elapsed         | 1673       |\n",
      "|    total_timesteps      | 2185216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00939171 |\n",
      "|    clip_fraction        | 0.0684     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.98      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0589     |\n",
      "|    n_updates            | 15550      |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    std                  | 2.95       |\n",
      "|    value_loss           | 0.397      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.7         |\n",
      "|    ep_rew_mean          | 0.491        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 1068         |\n",
      "|    time_elapsed         | 1674         |\n",
      "|    total_timesteps      | 2187264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142993815 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.96        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0827       |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    std                  | 2.92         |\n",
      "|    value_loss           | 0.399        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2188528, episode_reward=-2.76 +/- 3.55\n",
      "Episode length: 32.40 +/- 3.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.4        |\n",
      "|    mean_reward          | -2.76       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2188528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015746245 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0512     |\n",
      "|    n_updates            | 15570       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 0.0779      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | -0.0869  |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 1069     |\n",
      "|    time_elapsed    | 1676     |\n",
      "|    total_timesteps | 2189312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.325      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1070        |\n",
      "|    time_elapsed         | 1678        |\n",
      "|    total_timesteps      | 2191360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011162333 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 15580       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 0.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.149       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 1679        |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007906049 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.563       |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.0519     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1305        |\n",
      "|    iterations           | 1072        |\n",
      "|    time_elapsed         | 1681        |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012492228 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.0703      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 1682        |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013756523 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 15610       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 0.63        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2198528, episode_reward=-1.02 +/- 4.12\n",
      "Episode length: 31.60 +/- 5.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.6        |\n",
      "|    mean_reward          | -1.02       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2198528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013280649 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0507      |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 0.395       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.133   |\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 1074     |\n",
      "|    time_elapsed    | 1684     |\n",
      "|    total_timesteps | 2199552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.0377     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1075        |\n",
      "|    time_elapsed         | 1685        |\n",
      "|    total_timesteps      | 2201600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010181556 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 0.425       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.0189     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 1686        |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015258454 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0773      |\n",
      "|    n_updates            | 15640       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.424      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 1688        |\n",
      "|    total_timesteps      | 2205696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013370457 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.9        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 15650       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 0.585       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.656      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 1689        |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011467655 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0899      |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 2.9         |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2208528, episode_reward=1.00 +/- 3.38\n",
      "Episode length: 29.30 +/- 4.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.3        |\n",
      "|    mean_reward          | 1           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2208528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011257011 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.94       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0505      |\n",
      "|    n_updates            | 15670       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 0.399       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -1.06    |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 1079     |\n",
      "|    time_elapsed    | 1691     |\n",
      "|    total_timesteps | 2209792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.7        |\n",
      "|    ep_rew_mean          | 0.466       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 1693        |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011310682 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 15680       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 0.559       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.601      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 1694        |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010196818 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0764      |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 1696        |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012603084 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0594     |\n",
      "|    n_updates            | 15700       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 0.034       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.629      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 1697        |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013614519 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.95       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 15710       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2218528, episode_reward=2.92 +/- 4.34\n",
      "Episode length: 26.60 +/- 8.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.6        |\n",
      "|    mean_reward          | 2.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2218528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014355099 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.408       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.334   |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 1084     |\n",
      "|    time_elapsed    | 1699     |\n",
      "|    total_timesteps | 2220032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.403      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1306        |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 1700        |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011285137 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.641       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.616       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 1086         |\n",
      "|    time_elapsed         | 1702         |\n",
      "|    total_timesteps      | 2224128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071855327 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.401        |\n",
      "|    n_updates            | 15740        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 3.02         |\n",
      "|    value_loss           | 0.732        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -1.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1306         |\n",
      "|    iterations           | 1087         |\n",
      "|    time_elapsed         | 1703         |\n",
      "|    total_timesteps      | 2226176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061480356 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.455        |\n",
      "|    n_updates            | 15750        |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 0.83         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.792      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 1704        |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011517359 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0945      |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.349       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2228528, episode_reward=1.01 +/- 4.64\n",
      "Episode length: 26.50 +/- 7.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.5        |\n",
      "|    mean_reward          | 1.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2228528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011047244 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 15770       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.62        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.659   |\n",
      "| time/              |          |\n",
      "|    fps             | 1306     |\n",
      "|    iterations      | 1089     |\n",
      "|    time_elapsed    | 1706     |\n",
      "|    total_timesteps | 2230272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.594      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 1707        |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008367112 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.399       |\n",
      "|    n_updates            | 15780       |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.827       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.8       |\n",
      "|    ep_rew_mean          | -0.294     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1307       |\n",
      "|    iterations           | 1091       |\n",
      "|    time_elapsed         | 1709       |\n",
      "|    total_timesteps      | 2234368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01118019 |\n",
      "|    clip_fraction        | 0.0709     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.99      |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.61       |\n",
      "|    n_updates            | 15790      |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 3.02       |\n",
      "|    value_loss           | 1.16       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -1.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 1711        |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009162414 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.289       |\n",
      "|    n_updates            | 15800       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.911       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 1712        |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013489969 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0425      |\n",
      "|    n_updates            | 15810       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2238528, episode_reward=-1.78 +/- 5.04\n",
      "Episode length: 32.20 +/- 7.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.2        |\n",
      "|    mean_reward          | -1.78       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2238528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008845244 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0783      |\n",
      "|    n_updates            | 15820       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.94    |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 1094     |\n",
      "|    time_elapsed    | 1713     |\n",
      "|    total_timesteps | 2240512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.194      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 1715        |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013373461 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 15830       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.516       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 1716        |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009366151 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 0.654       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.409      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 1718        |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009831458 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.608       |\n",
      "|    n_updates            | 15850       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2248528, episode_reward=-0.98 +/- 4.99\n",
      "Episode length: 30.30 +/- 7.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | -0.977      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2248528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008212835 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 15860       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.638   |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 1098     |\n",
      "|    time_elapsed    | 1719     |\n",
      "|    total_timesteps | 2248704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.928      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 1721        |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008447911 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0432      |\n",
      "|    n_updates            | 15870       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 0.304       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | 0.602        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 1100         |\n",
      "|    time_elapsed         | 1722         |\n",
      "|    total_timesteps      | 2252800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094243735 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.03        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.33         |\n",
      "|    n_updates            | 15880        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 3.09         |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.209      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 1724        |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010112442 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0761      |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 0.359       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.197       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 1726        |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006737599 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.246       |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 0.729       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2258528, episode_reward=-0.62 +/- 5.98\n",
      "Episode length: 30.10 +/- 8.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | -0.624      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2258528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008644139 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0164      |\n",
      "|    n_updates            | 15910       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.0709  |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 1103     |\n",
      "|    time_elapsed    | 1727     |\n",
      "|    total_timesteps | 2258944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.494       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 1729        |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011734438 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.543       |\n",
      "|    n_updates            | 15920       |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 1730        |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008022988 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0266      |\n",
      "|    n_updates            | 15930       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.483      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1106        |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012719246 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 15940       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.6         |\n",
      "|    ep_rew_mean          | 0.384        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 1107         |\n",
      "|    time_elapsed         | 1733         |\n",
      "|    total_timesteps      | 2267136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154143125 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.059        |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    std                  | 3.04         |\n",
      "|    value_loss           | 0.208        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2268528, episode_reward=2.94 +/- 5.03\n",
      "Episode length: 24.70 +/- 8.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.7        |\n",
      "|    mean_reward          | 2.94        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2268528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008531315 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 0.748       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.162   |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 1108     |\n",
      "|    time_elapsed    | 1735     |\n",
      "|    total_timesteps | 2269184  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.0775     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1109        |\n",
      "|    time_elapsed         | 1736        |\n",
      "|    total_timesteps      | 2271232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013260564 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.279       |\n",
      "|    n_updates            | 15970       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.371      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1110        |\n",
      "|    time_elapsed         | 1738        |\n",
      "|    total_timesteps      | 2273280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017271942 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 15980       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 0.542       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.9       |\n",
      "|    ep_rew_mean          | -1.02      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1307       |\n",
      "|    iterations           | 1111       |\n",
      "|    time_elapsed         | 1739       |\n",
      "|    total_timesteps      | 2275328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00968496 |\n",
      "|    clip_fraction        | 0.0874     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.05      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.156      |\n",
      "|    n_updates            | 15990      |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    std                  | 3.08       |\n",
      "|    value_loss           | 0.459      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.141      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 1741        |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012683975 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0771      |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 0.324       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2278528, episode_reward=-0.14 +/- 5.86\n",
      "Episode length: 30.50 +/- 7.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.5        |\n",
      "|    mean_reward          | -0.139      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2278528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011511693 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 0.772       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.4     |\n",
      "|    ep_rew_mean     | 0.592    |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 1113     |\n",
      "|    time_elapsed    | 1743     |\n",
      "|    total_timesteps | 2279424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.158      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 1744        |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012129362 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 16020       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 0.532       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.785      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 1746        |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013208421 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 0.446       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.412       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 1116        |\n",
      "|    time_elapsed         | 1747        |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014318133 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.05       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.0245      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 1748        |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017835535 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0654     |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 0.0363      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2288528, episode_reward=-0.73 +/- 7.36\n",
      "Episode length: 30.30 +/- 10.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | -0.729      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2288528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009676693 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 16060       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.623       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.202   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1118     |\n",
      "|    time_elapsed    | 1750     |\n",
      "|    total_timesteps | 2289664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.265      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 1751        |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664628 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 0.469       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.5       |\n",
      "|    ep_rew_mean          | -0.0944    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 1120       |\n",
      "|    time_elapsed         | 1753       |\n",
      "|    total_timesteps      | 2293760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01448833 |\n",
      "|    clip_fraction        | 0.0914     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.02      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.09       |\n",
      "|    n_updates            | 16080      |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    std                  | 3.04       |\n",
      "|    value_loss           | 0.486      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.0441     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 1754        |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008341813 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 16090       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 1756        |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014451372 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0714      |\n",
      "|    n_updates            | 16100       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2298528, episode_reward=0.21 +/- 4.53\n",
      "Episode length: 28.70 +/- 7.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28.7         |\n",
      "|    mean_reward          | 0.205        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2298528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067566466 |\n",
      "|    clip_fraction        | 0.0766       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.148        |\n",
      "|    n_updates            | 16110        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 3            |\n",
      "|    value_loss           | 0.407        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.751   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1123     |\n",
      "|    time_elapsed    | 1757     |\n",
      "|    total_timesteps | 2299904  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.363       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1124         |\n",
      "|    time_elapsed         | 1759         |\n",
      "|    total_timesteps      | 2301952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137702795 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.212        |\n",
      "|    n_updates            | 16120        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 3.02         |\n",
      "|    value_loss           | 0.664        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.1      |\n",
      "|    ep_rew_mean          | -0.582    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1308      |\n",
      "|    iterations           | 1125      |\n",
      "|    time_elapsed         | 1760      |\n",
      "|    total_timesteps      | 2304000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0109597 |\n",
      "|    clip_fraction        | 0.106     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.02     |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.00627   |\n",
      "|    n_updates            | 16130     |\n",
      "|    policy_gradient_loss | -0.0153   |\n",
      "|    std                  | 3.04      |\n",
      "|    value_loss           | 0.202     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.129      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 1762        |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011535453 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.000719   |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.611      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1127        |\n",
      "|    time_elapsed         | 1763        |\n",
      "|    total_timesteps      | 2308096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009992664 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0833      |\n",
      "|    n_updates            | 16150       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 0.485       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2308528, episode_reward=-2.09 +/- 5.57\n",
      "Episode length: 32.80 +/- 9.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -2.09       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2308528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012750454 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.287   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1128     |\n",
      "|    time_elapsed    | 1765     |\n",
      "|    total_timesteps | 2310144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 1767        |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009553069 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.859       |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.795      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1130        |\n",
      "|    time_elapsed         | 1768        |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010043256 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00416     |\n",
      "|    n_updates            | 16180       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.794       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1131         |\n",
      "|    time_elapsed         | 1770         |\n",
      "|    total_timesteps      | 2316288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084158555 |\n",
      "|    clip_fraction        | 0.0978       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5           |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0135       |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 3.02         |\n",
      "|    value_loss           | 0.268        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.7       |\n",
      "|    ep_rew_mean          | 0.11       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 1132       |\n",
      "|    time_elapsed         | 1771       |\n",
      "|    total_timesteps      | 2318336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01621032 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.99      |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.041      |\n",
      "|    n_updates            | 16200      |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    std                  | 2.99       |\n",
      "|    value_loss           | 0.261      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2318528, episode_reward=1.33 +/- 4.48\n",
      "Episode length: 27.90 +/- 8.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.9        |\n",
      "|    mean_reward          | 1.33        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2318528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016001357 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00275     |\n",
      "|    n_updates            | 16210       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -1.09    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1133     |\n",
      "|    time_elapsed    | 1773     |\n",
      "|    total_timesteps | 2320384  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.7         |\n",
      "|    ep_rew_mean          | -1.12        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 1774         |\n",
      "|    total_timesteps      | 2322432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140244765 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.97        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.351        |\n",
      "|    n_updates            | 16220        |\n",
      "|    policy_gradient_loss | -0.00973     |\n",
      "|    std                  | 2.98         |\n",
      "|    value_loss           | 0.952        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.866      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 1776        |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011378562 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.087       |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 0.395       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.496      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1136        |\n",
      "|    time_elapsed         | 1777        |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013959952 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0289      |\n",
      "|    n_updates            | 16240       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2328528, episode_reward=0.36 +/- 3.44\n",
      "Episode length: 29.40 +/- 5.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.361       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2328528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013809441 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 16250       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.657       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.5     |\n",
      "|    ep_rew_mean     | -1.76    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1137     |\n",
      "|    time_elapsed    | 1779     |\n",
      "|    total_timesteps | 2328576  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.576       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1138         |\n",
      "|    time_elapsed         | 1781         |\n",
      "|    total_timesteps      | 2330624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078448355 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.01        |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.72         |\n",
      "|    n_updates            | 16260        |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    std                  | 3.02         |\n",
      "|    value_loss           | 2.54         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.328      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 1782        |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008314086 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.297       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 1784        |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008411745 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.0541      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.379      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1141        |\n",
      "|    time_elapsed         | 1785        |\n",
      "|    total_timesteps      | 2336768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009916075 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.028      |\n",
      "|    n_updates            | 16290       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2338528, episode_reward=0.09 +/- 4.87\n",
      "Episode length: 28.50 +/- 8.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.5        |\n",
      "|    mean_reward          | 0.0948      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2338528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014853247 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0541     |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.0426      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | 0.0235   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1142     |\n",
      "|    time_elapsed    | 1787     |\n",
      "|    total_timesteps | 2338816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.41       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1143        |\n",
      "|    time_elapsed         | 1789        |\n",
      "|    total_timesteps      | 2340864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009126857 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.862       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.411       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 1790        |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009806577 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0616     |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.0541      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.0947     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 1791        |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008174338 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.227       |\n",
      "|    n_updates            | 16330       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 0.637       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.199       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 1793        |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010693392 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.291       |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 0.66        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2348528, episode_reward=1.34 +/- 5.47\n",
      "Episode length: 26.10 +/- 9.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.1        |\n",
      "|    mean_reward          | 1.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2348528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011861747 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 16350       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.194   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1147     |\n",
      "|    time_elapsed    | 1795     |\n",
      "|    total_timesteps | 2349056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.266       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1148        |\n",
      "|    time_elapsed         | 1796        |\n",
      "|    total_timesteps      | 2351104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013536944 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0789      |\n",
      "|    n_updates            | 16360       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.144       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 1798        |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010912044 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00646     |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.251       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.123       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 1799        |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010498779 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.301       |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.816       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.508      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 1801        |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012460414 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 0.529       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2358528, episode_reward=1.63 +/- 5.21\n",
      "Episode length: 27.60 +/- 7.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.6        |\n",
      "|    mean_reward          | 1.63        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2358528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009275266 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 16400       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -1.17    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1152     |\n",
      "|    time_elapsed    | 1802     |\n",
      "|    total_timesteps | 2359296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.851      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1153        |\n",
      "|    time_elapsed         | 1804        |\n",
      "|    total_timesteps      | 2361344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008432155 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.076       |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 0.375       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.314      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 1805        |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009211531 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0705     |\n",
      "|    n_updates            | 16420       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.0598      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.8       |\n",
      "|    ep_rew_mean          | 0.338      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 1155       |\n",
      "|    time_elapsed         | 1807       |\n",
      "|    total_timesteps      | 2365440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01088386 |\n",
      "|    clip_fraction        | 0.0969     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.01      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0582    |\n",
      "|    n_updates            | 16430      |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 2.98       |\n",
      "|    value_loss           | 0.047      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.298       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 1808        |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014490946 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0652     |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.025       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2368528, episode_reward=1.27 +/- 4.44\n",
      "Episode length: 28.60 +/- 6.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.6        |\n",
      "|    mean_reward          | 1.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2368528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010020702 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0436      |\n",
      "|    n_updates            | 16450       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.141   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1157     |\n",
      "|    time_elapsed    | 1810     |\n",
      "|    total_timesteps | 2369536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.436      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 1811        |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011374733 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 16460       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.792       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.45       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 1813        |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007661483 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00957    |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 0.224       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.873      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 1814        |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009068991 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.061       |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.834      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 1816        |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010743432 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0896      |\n",
      "|    n_updates            | 16490       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.423       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2378528, episode_reward=2.57 +/- 3.49\n",
      "Episode length: 24.40 +/- 6.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.4        |\n",
      "|    mean_reward          | 2.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2378528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010509174 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0205      |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.343    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1162     |\n",
      "|    time_elapsed    | 1818     |\n",
      "|    total_timesteps | 2379776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.626      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 1819        |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011816455 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0336      |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.802      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1164        |\n",
      "|    time_elapsed         | 1821        |\n",
      "|    total_timesteps      | 2383872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009106594 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 16520       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.447       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.732      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 1822        |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012281313 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.064       |\n",
      "|    n_updates            | 16530       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.265       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.561      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 1824        |\n",
      "|    total_timesteps      | 2387968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012184037 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0835      |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 0.369       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2388528, episode_reward=-2.91 +/- 4.76\n",
      "Episode length: 34.20 +/- 8.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.2        |\n",
      "|    mean_reward          | -2.91       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2388528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062657 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.02       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0637     |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 0.0403      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.277   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1167     |\n",
      "|    time_elapsed    | 1825     |\n",
      "|    total_timesteps | 2390016  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.7       |\n",
      "|    ep_rew_mean          | 0.619      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 1168       |\n",
      "|    time_elapsed         | 1827       |\n",
      "|    total_timesteps      | 2392064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01109112 |\n",
      "|    clip_fraction        | 0.0891     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.01      |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.14       |\n",
      "|    n_updates            | 16560      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 2.99       |\n",
      "|    value_loss           | 0.509      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.718       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 1828        |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011880402 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0465     |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 0.0643      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.527       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 1830        |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013558171 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.01       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 16580       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 0.458       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0215      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 1831        |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010222409 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 16590       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 0.801       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2398528, episode_reward=-0.16 +/- 5.74\n",
      "Episode length: 30.60 +/- 7.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.6         |\n",
      "|    mean_reward          | -0.164       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2398528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113336705 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0628      |\n",
      "|    n_updates            | 16600        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 2.97         |\n",
      "|    value_loss           | 0.082        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.809   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1172     |\n",
      "|    time_elapsed    | 1833     |\n",
      "|    total_timesteps | 2400256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.57       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 1835        |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013938158 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.000712    |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.745      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 1836        |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011545204 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.96       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 0.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.42       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 1838        |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009635248 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.97       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 16630       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 0.615       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.461        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1176         |\n",
      "|    time_elapsed         | 1839         |\n",
      "|    total_timesteps      | 2408448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121423965 |\n",
      "|    clip_fraction        | 0.0864       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.99        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.151        |\n",
      "|    n_updates            | 16640        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 2.98         |\n",
      "|    value_loss           | 0.438        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2408528, episode_reward=2.65 +/- 5.73\n",
      "Episode length: 26.00 +/- 7.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26          |\n",
      "|    mean_reward          | 2.65        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2408528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013023451 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 0.407       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.335    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1177     |\n",
      "|    time_elapsed    | 1841     |\n",
      "|    total_timesteps | 2410496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.283      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1178        |\n",
      "|    time_elapsed         | 1842        |\n",
      "|    total_timesteps      | 2412544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007963518 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 0.546       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.953      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 1844        |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009967968 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.99       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.213       |\n",
      "|    n_updates            | 16670       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.152      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 1845        |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013021467 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0088      |\n",
      "|    n_updates            | 16680       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 2.96        |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2418528, episode_reward=1.89 +/- 2.60\n",
      "Episode length: 27.50 +/- 4.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.5        |\n",
      "|    mean_reward          | 1.89        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2418528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013598566 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0615     |\n",
      "|    n_updates            | 16690       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 0.0378      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.35    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1181     |\n",
      "|    time_elapsed    | 1847     |\n",
      "|    total_timesteps | 2418688  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.178       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1182        |\n",
      "|    time_elapsed         | 1849        |\n",
      "|    total_timesteps      | 2420736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007597035 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 16700       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 0.381       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 1850        |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013477943 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0673     |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 0.0686      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.3       |\n",
      "|    ep_rew_mean          | -0.569     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 1184       |\n",
      "|    time_elapsed         | 1852       |\n",
      "|    total_timesteps      | 2424832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00888104 |\n",
      "|    clip_fraction        | 0.0882     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5         |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.168      |\n",
      "|    n_updates            | 16720      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 3.02       |\n",
      "|    value_loss           | 0.543      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.565      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 1853        |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008702978 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.36        |\n",
      "|    n_updates            | 16730       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.911       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2428528, episode_reward=-1.76 +/- 4.09\n",
      "Episode length: 32.60 +/- 6.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.6        |\n",
      "|    mean_reward          | -1.76       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2428528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008862469 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 16740       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 3.05        |\n",
      "|    value_loss           | 0.478       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.46    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1186     |\n",
      "|    time_elapsed    | 1855     |\n",
      "|    total_timesteps | 2428928  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.249       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1187         |\n",
      "|    time_elapsed         | 1856         |\n",
      "|    total_timesteps      | 2430976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070615485 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.03        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.217        |\n",
      "|    n_updates            | 16750        |\n",
      "|    policy_gradient_loss | -0.00937     |\n",
      "|    std                  | 3.03         |\n",
      "|    value_loss           | 0.556        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.333      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 1858        |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011021176 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 16760       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.8        |\n",
      "|    ep_rew_mean          | -1.67       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 1859        |\n",
      "|    total_timesteps      | 2435072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008063274 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.03       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.25        |\n",
      "|    n_updates            | 16770       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 3.04        |\n",
      "|    value_loss           | 0.813       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 1861        |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008300456 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.04       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 0.829       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2438528, episode_reward=-0.05 +/- 5.87\n",
      "Episode length: 30.20 +/- 8.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.2        |\n",
      "|    mean_reward          | -0.0535     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2438528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008907663 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.06       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.288       |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 0.772       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | 0.427    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1191     |\n",
      "|    time_elapsed    | 1862     |\n",
      "|    total_timesteps | 2439168  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.9         |\n",
      "|    ep_rew_mean          | 0.863        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1192         |\n",
      "|    time_elapsed         | 1864         |\n",
      "|    total_timesteps      | 2441216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076862173 |\n",
      "|    clip_fraction        | 0.0686       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.09        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 16800        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    std                  | 3.15         |\n",
      "|    value_loss           | 0.618        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.1         |\n",
      "|    ep_rew_mean          | 0.373        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1193         |\n",
      "|    time_elapsed         | 1865         |\n",
      "|    total_timesteps      | 2443264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117728505 |\n",
      "|    clip_fraction        | 0.0689       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.09        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0102       |\n",
      "|    n_updates            | 16810        |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    std                  | 3.14         |\n",
      "|    value_loss           | 0.204        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 1867        |\n",
      "|    total_timesteps      | 2445312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012020098 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.09       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0414      |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 0.364       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.723      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1195        |\n",
      "|    time_elapsed         | 1868        |\n",
      "|    total_timesteps      | 2447360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010528747 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00276     |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2448528, episode_reward=0.41 +/- 4.73\n",
      "Episode length: 29.10 +/- 6.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.1        |\n",
      "|    mean_reward          | 0.411       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2448528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012780329 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 16840       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 0.571       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.492   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1196     |\n",
      "|    time_elapsed    | 1870     |\n",
      "|    total_timesteps | 2449408  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.257       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 1871        |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009169835 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 0.948       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -0.713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 1873        |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008305116 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.079       |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 0.354       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.377      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 1874        |\n",
      "|    total_timesteps      | 2455552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009515932 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.371       |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 0.933       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.243       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 1876        |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011239133 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.317       |\n",
      "|    n_updates            | 16880       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 0.868       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2458528, episode_reward=0.70 +/- 4.59\n",
      "Episode length: 27.70 +/- 6.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.7        |\n",
      "|    mean_reward          | 0.702       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2458528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008906072 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.14       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0814      |\n",
      "|    n_updates            | 16890       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 0.381       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.8     |\n",
      "|    ep_rew_mean     | 0.597    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1201     |\n",
      "|    time_elapsed    | 1878     |\n",
      "|    total_timesteps | 2459648  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32         |\n",
      "|    ep_rew_mean          | -0.933     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 1202       |\n",
      "|    time_elapsed         | 1879       |\n",
      "|    total_timesteps      | 2461696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01100603 |\n",
      "|    clip_fraction        | 0.0767     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.17      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0146     |\n",
      "|    n_updates            | 16900      |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 3.25       |\n",
      "|    value_loss           | 0.281      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.633      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 1881        |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005754384 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.16       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.396       |\n",
      "|    n_updates            | 16910       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.5         |\n",
      "|    ep_rew_mean          | -0.116       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1204         |\n",
      "|    time_elapsed         | 1882         |\n",
      "|    total_timesteps      | 2465792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111853015 |\n",
      "|    clip_fraction        | 0.0733       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.016        |\n",
      "|    n_updates            | 16920        |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    std                  | 3.18         |\n",
      "|    value_loss           | 0.254        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.37        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1205         |\n",
      "|    time_elapsed         | 1883         |\n",
      "|    total_timesteps      | 2467840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107396245 |\n",
      "|    clip_fraction        | 0.0927       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.13        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0958       |\n",
      "|    n_updates            | 16930        |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    std                  | 3.19         |\n",
      "|    value_loss           | 0.364        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2468528, episode_reward=0.38 +/- 4.17\n",
      "Episode length: 28.90 +/- 7.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.9        |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2468528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009549424 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.32        |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 0.806       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.371   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1206     |\n",
      "|    time_elapsed    | 1885     |\n",
      "|    total_timesteps | 2469888  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.4         |\n",
      "|    ep_rew_mean          | 0.603        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1207         |\n",
      "|    time_elapsed         | 1887         |\n",
      "|    total_timesteps      | 2471936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069430796 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.352        |\n",
      "|    n_updates            | 16950        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 3.21         |\n",
      "|    value_loss           | 0.796        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.235       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 1888        |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009910373 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.14       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00339    |\n",
      "|    n_updates            | 16960       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.299      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 1890        |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008804966 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 0.392       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.538      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 1891        |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010344271 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 16980       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 0.837       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2478528, episode_reward=-3.78 +/- 3.61\n",
      "Episode length: 34.30 +/- 5.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 34.3       |\n",
      "|    mean_reward          | -3.78      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2478528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00815303 |\n",
      "|    clip_fraction        | 0.0614     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.14      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.184      |\n",
      "|    n_updates            | 16990      |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 3.2        |\n",
      "|    value_loss           | 0.618      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.735   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1211     |\n",
      "|    time_elapsed    | 1893     |\n",
      "|    total_timesteps | 2480128  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | -0.997     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 1212       |\n",
      "|    time_elapsed         | 1894       |\n",
      "|    total_timesteps      | 2482176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01003531 |\n",
      "|    clip_fraction        | 0.0949     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.15      |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.132      |\n",
      "|    n_updates            | 17000      |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 3.24       |\n",
      "|    value_loss           | 0.496      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.891      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 1896        |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009739686 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.16       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 17010       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.85       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 1897        |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009439172 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.411       |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.368      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 1899        |\n",
      "|    total_timesteps      | 2488320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009509416 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.14       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2488528, episode_reward=0.21 +/- 4.81\n",
      "Episode length: 31.40 +/- 6.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.4        |\n",
      "|    mean_reward          | 0.214       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2488528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010761563 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.11       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0552      |\n",
      "|    n_updates            | 17040       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 0.419       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.64    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1216     |\n",
      "|    time_elapsed    | 1900     |\n",
      "|    total_timesteps | 2490368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.523      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 1902        |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009546797 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 0.522       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.132       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 1903        |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012250171 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 0.368       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.365      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 1905        |\n",
      "|    total_timesteps      | 2496512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012257434 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0624     |\n",
      "|    n_updates            | 17070       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 3.14        |\n",
      "|    value_loss           | 0.0449      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2498528, episode_reward=0.93 +/- 6.18\n",
      "Episode length: 27.60 +/- 8.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.6        |\n",
      "|    mean_reward          | 0.93        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2498528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009246716 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.254       |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 0.596       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.2     |\n",
      "|    ep_rew_mean     | 0.587    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1220     |\n",
      "|    time_elapsed    | 1906     |\n",
      "|    total_timesteps | 2498560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.297      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1221        |\n",
      "|    time_elapsed         | 1908        |\n",
      "|    total_timesteps      | 2500608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009529068 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.12       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0843      |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 0.285       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 1909        |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011364365 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.047       |\n",
      "|    n_updates            | 17100       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 0.308       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.0996     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 1911        |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011744117 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0829      |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 3.2         |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.6       |\n",
      "|    ep_rew_mean          | -0.198     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 1224       |\n",
      "|    time_elapsed         | 1912       |\n",
      "|    total_timesteps      | 2506752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01571553 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.16      |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.217      |\n",
      "|    n_updates            | 17120      |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 3.26       |\n",
      "|    value_loss           | 0.462      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2508528, episode_reward=-1.32 +/- 4.27\n",
      "Episode length: 31.40 +/- 6.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.4        |\n",
      "|    mean_reward          | -1.32       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2508528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006722075 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.19       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 0.548       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.122   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1225     |\n",
      "|    time_elapsed    | 1914     |\n",
      "|    total_timesteps | 2508800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.0462     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1226        |\n",
      "|    time_elapsed         | 1916        |\n",
      "|    total_timesteps      | 2510848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009840853 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.22       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 0.324       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 32.2      |\n",
      "|    ep_rew_mean          | -0.838    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1310      |\n",
      "|    iterations           | 1227      |\n",
      "|    time_elapsed         | 1917      |\n",
      "|    total_timesteps      | 2512896   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0100131 |\n",
      "|    clip_fraction        | 0.0759    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.23     |\n",
      "|    explained_variance   | 0.972     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.237     |\n",
      "|    n_updates            | 17150     |\n",
      "|    policy_gradient_loss | -0.0104   |\n",
      "|    std                  | 3.34      |\n",
      "|    value_loss           | 0.515     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 1919        |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013261807 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.22       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 0.589       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1229        |\n",
      "|    time_elapsed         | 1920        |\n",
      "|    total_timesteps      | 2516992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011508558 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.22       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0967      |\n",
      "|    n_updates            | 17170       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 0.464       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2518528, episode_reward=-0.52 +/- 5.23\n",
      "Episode length: 29.50 +/- 10.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.5        |\n",
      "|    mean_reward          | -0.52       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2518528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008434997 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.527       |\n",
      "|    n_updates            | 17180       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33       |\n",
      "|    ep_rew_mean     | -1.57    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1230     |\n",
      "|    time_elapsed    | 1922     |\n",
      "|    total_timesteps | 2519040  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | -0.556     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 1231       |\n",
      "|    time_elapsed         | 1923       |\n",
      "|    total_timesteps      | 2521088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01179075 |\n",
      "|    clip_fraction        | 0.0797     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.23      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0484     |\n",
      "|    n_updates            | 17190      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 3.33       |\n",
      "|    value_loss           | 0.315      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | -0.112      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 1925        |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010698127 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.21       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.00963    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1233        |\n",
      "|    time_elapsed         | 1926        |\n",
      "|    total_timesteps      | 2525184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007764085 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.2        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0244      |\n",
      "|    n_updates            | 17210       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 3.32        |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 1928        |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010453059 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.23       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0066      |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2528528, episode_reward=-1.84 +/- 5.02\n",
      "Episode length: 35.50 +/- 9.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.5        |\n",
      "|    mean_reward          | -1.84       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2528528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014398535 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.25       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0388     |\n",
      "|    n_updates            | 17230       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.366   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1235     |\n",
      "|    time_elapsed    | 1929     |\n",
      "|    total_timesteps | 2529280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -1.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1236        |\n",
      "|    time_elapsed         | 1931        |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011425575 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.27       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.278       |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 0.533       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.0805     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1237        |\n",
      "|    time_elapsed         | 1932        |\n",
      "|    total_timesteps      | 2533376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009864617 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.31       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0541     |\n",
      "|    n_updates            | 17250       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 0.0713      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.862      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1238        |\n",
      "|    time_elapsed         | 1934        |\n",
      "|    total_timesteps      | 2535424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009317232 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 17260       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 0.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.0367      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 1935        |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010441182 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 0.668       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2538528, episode_reward=1.78 +/- 4.87\n",
      "Episode length: 29.00 +/- 7.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 1.78        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2538528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012466941 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 17280       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 0.26        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.679   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1240     |\n",
      "|    time_elapsed    | 1937     |\n",
      "|    total_timesteps | 2539520  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.3       |\n",
      "|    ep_rew_mean          | -0.606     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 1241       |\n",
      "|    time_elapsed         | 1938       |\n",
      "|    total_timesteps      | 2541568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01044409 |\n",
      "|    clip_fraction        | 0.0687     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.37      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.316      |\n",
      "|    n_updates            | 17290      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 3.6        |\n",
      "|    value_loss           | 0.566      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.0541      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 1940        |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007490343 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.297       |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 0.798       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | -0.288      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1243        |\n",
      "|    time_elapsed         | 1941        |\n",
      "|    total_timesteps      | 2545664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006109612 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.4        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0734      |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 0.342       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.281      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 1943        |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012350681 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00465    |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2548528, episode_reward=0.37 +/- 6.20\n",
      "Episode length: 29.40 +/- 15.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.4         |\n",
      "|    mean_reward          | 0.372        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2548528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058089662 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.37        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.425        |\n",
      "|    n_updates            | 17330        |\n",
      "|    policy_gradient_loss | -0.0083      |\n",
      "|    std                  | 3.61         |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.167   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1245     |\n",
      "|    time_elapsed    | 1944     |\n",
      "|    total_timesteps | 2549760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.000959    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1246        |\n",
      "|    time_elapsed         | 1946        |\n",
      "|    total_timesteps      | 2551808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008828765 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0739      |\n",
      "|    n_updates            | 17340       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 0.279       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.175      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 1947        |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009304478 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 17350       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 0.408       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.9         |\n",
      "|    ep_rew_mean          | 0.825        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1248         |\n",
      "|    time_elapsed         | 1949         |\n",
      "|    total_timesteps      | 2555904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082318075 |\n",
      "|    clip_fraction        | 0.0528       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.35        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.19         |\n",
      "|    n_updates            | 17360        |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 3.55         |\n",
      "|    value_loss           | 0.692        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 0.227        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1249         |\n",
      "|    time_elapsed         | 1950         |\n",
      "|    total_timesteps      | 2557952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126193175 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.33        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 17370        |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    std                  | 3.53         |\n",
      "|    value_loss           | 0.562        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2558528, episode_reward=-2.30 +/- 4.60\n",
      "Episode length: 38.70 +/- 15.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 38.7        |\n",
      "|    mean_reward          | -2.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012132248 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.399       |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.671   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 1250     |\n",
      "|    time_elapsed    | 1952     |\n",
      "|    total_timesteps | 2560000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.512      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 1954        |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008955262 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.242       |\n",
      "|    n_updates            | 17390       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 0.655       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 1955        |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009695969 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 0.682       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.1       |\n",
      "|    ep_rew_mean          | -0.401     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 1253       |\n",
      "|    time_elapsed         | 1957       |\n",
      "|    total_timesteps      | 2566144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01147804 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.36      |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.401      |\n",
      "|    n_updates            | 17410      |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    std                  | 3.59       |\n",
      "|    value_loss           | 1.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.52       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1254        |\n",
      "|    time_elapsed         | 1958        |\n",
      "|    total_timesteps      | 2568192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010689807 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.065       |\n",
      "|    n_updates            | 17420       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 0.422       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2568528, episode_reward=-0.39 +/- 5.43\n",
      "Episode length: 29.10 +/- 8.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.1        |\n",
      "|    mean_reward          | -0.391      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2568528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010168886 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 17430       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 0.376       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -1.29    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 1255     |\n",
      "|    time_elapsed    | 1960     |\n",
      "|    total_timesteps | 2570240  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -0.71        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1256         |\n",
      "|    time_elapsed         | 1961         |\n",
      "|    total_timesteps      | 2572288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073621087 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.32        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.359        |\n",
      "|    n_updates            | 17440        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 3.51         |\n",
      "|    value_loss           | 0.982        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.607       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1257         |\n",
      "|    time_elapsed         | 1963         |\n",
      "|    total_timesteps      | 2574336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077744485 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.32        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.229        |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 3.51         |\n",
      "|    value_loss           | 0.68         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | -0.639     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 1258       |\n",
      "|    time_elapsed         | 1964       |\n",
      "|    total_timesteps      | 2576384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00821876 |\n",
      "|    clip_fraction        | 0.0681     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.32      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.195      |\n",
      "|    n_updates            | 17460      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 3.5        |\n",
      "|    value_loss           | 0.527      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.124      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 1965        |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009901808 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.32       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 0.379       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2578528, episode_reward=-0.20 +/- 4.74\n",
      "Episode length: 30.00 +/- 6.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.204      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2578528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008830132 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.213       |\n",
      "|    n_updates            | 17480       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 0.69        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.546   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 1260     |\n",
      "|    time_elapsed    | 1967     |\n",
      "|    total_timesteps | 2580480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.321      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 1968        |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009574347 |\n",
      "|    clip_fraction        | 0.0734      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 0.771       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.986      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 1970        |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012332531 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 3.55        |\n",
      "|    value_loss           | 0.807       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.637      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 1971        |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009055018 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 0.763       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2588528, episode_reward=0.39 +/- 2.98\n",
      "Episode length: 32.80 +/- 9.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | 0.388       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2588528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008596172 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 17520       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.457   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 1264     |\n",
      "|    time_elapsed    | 1973     |\n",
      "|    total_timesteps | 2588672  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.8         |\n",
      "|    ep_rew_mean          | -0.488       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1265         |\n",
      "|    time_elapsed         | 1974         |\n",
      "|    total_timesteps      | 2590720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077242116 |\n",
      "|    clip_fraction        | 0.0672       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.36        |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.907        |\n",
      "|    n_updates            | 17530        |\n",
      "|    policy_gradient_loss | -0.00987     |\n",
      "|    std                  | 3.56         |\n",
      "|    value_loss           | 2.75         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.809      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 1976        |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009188626 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.483       |\n",
      "|    n_updates            | 17540       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 3.59        |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.0846      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1267         |\n",
      "|    time_elapsed         | 1978         |\n",
      "|    total_timesteps      | 2594816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082578445 |\n",
      "|    clip_fraction        | 0.0755       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.37        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0117       |\n",
      "|    n_updates            | 17550        |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    std                  | 3.58         |\n",
      "|    value_loss           | 0.244        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.744      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 1979        |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010721425 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.379       |\n",
      "|    n_updates            | 17560       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 0.856       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2598528, episode_reward=-1.03 +/- 5.56\n",
      "Episode length: 31.80 +/- 7.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.8         |\n",
      "|    mean_reward          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2598528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075881104 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.38        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.323        |\n",
      "|    n_updates            | 17570        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 3.6          |\n",
      "|    value_loss           | 0.888        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.1     |\n",
      "|    ep_rew_mean     | 0.325    |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1269     |\n",
      "|    time_elapsed    | 1980     |\n",
      "|    total_timesteps | 2598912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.29       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1270        |\n",
      "|    time_elapsed         | 1982        |\n",
      "|    total_timesteps      | 2600960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008239876 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 17580       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.255      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1271        |\n",
      "|    time_elapsed         | 1983        |\n",
      "|    total_timesteps      | 2603008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011263148 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -4.67e-05   |\n",
      "|    n_updates            | 17590       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.127       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 1985        |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009574201 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.41       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 17600       |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    std                  | 3.69        |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.628       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 1986        |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012514096 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.43       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0787      |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 0.349       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2608528, episode_reward=0.78 +/- 4.38\n",
      "Episode length: 28.30 +/- 7.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.3        |\n",
      "|    mean_reward          | 0.782       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2608528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009416116 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 17620       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 0.483       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.804   |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1274     |\n",
      "|    time_elapsed    | 1988     |\n",
      "|    total_timesteps | 2609152  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.276      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1275        |\n",
      "|    time_elapsed         | 1989        |\n",
      "|    total_timesteps      | 2611200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010815213 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.41       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 17630       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 0.719       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.443      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 1991        |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011471711 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.41       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 0.715       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | -0.658       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 1277         |\n",
      "|    time_elapsed         | 1992         |\n",
      "|    total_timesteps      | 2615296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069621494 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.41        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.324        |\n",
      "|    n_updates            | 17650        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    std                  | 3.68         |\n",
      "|    value_loss           | 0.744        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.359      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1278        |\n",
      "|    time_elapsed         | 1994        |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011050783 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0558     |\n",
      "|    n_updates            | 17660       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 0.0728      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2618528, episode_reward=0.77 +/- 6.98\n",
      "Episode length: 27.10 +/- 10.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.1        |\n",
      "|    mean_reward          | 0.775       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2618528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011855445 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0643     |\n",
      "|    n_updates            | 17670       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 3.49        |\n",
      "|    value_loss           | 0.038       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.562   |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1279     |\n",
      "|    time_elapsed    | 1995     |\n",
      "|    total_timesteps | 2619392  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.559      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1312       |\n",
      "|    iterations           | 1280       |\n",
      "|    time_elapsed         | 1997       |\n",
      "|    total_timesteps      | 2621440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01333731 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.3       |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.464      |\n",
      "|    n_updates            | 17680      |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    std                  | 3.45       |\n",
      "|    value_loss           | 1.14       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.847       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 1998        |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010504699 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.29       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 17690       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 0.372       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.0167      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 2000        |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008544566 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.29       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 17700       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 0.345       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 2001        |\n",
      "|    total_timesteps      | 2627584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013156572 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 0.414       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2628528, episode_reward=2.56 +/- 3.32\n",
      "Episode length: 25.20 +/- 6.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.2        |\n",
      "|    mean_reward          | 2.56        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2628528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009574125 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.3        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0636     |\n",
      "|    n_updates            | 17720       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 0.0786      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.571   |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1284     |\n",
      "|    time_elapsed    | 2003     |\n",
      "|    total_timesteps | 2629632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.481      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1285        |\n",
      "|    time_elapsed         | 2004        |\n",
      "|    total_timesteps      | 2631680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011509446 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.31       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 0.322       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.635      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 2006        |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012715856 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 0.605       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.076      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 2007        |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009622922 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0103     |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.847      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 2009        |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015242411 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0531     |\n",
      "|    n_updates            | 17760       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 0.0734      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2638528, episode_reward=-0.45 +/- 5.07\n",
      "Episode length: 30.50 +/- 8.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.5        |\n",
      "|    mean_reward          | -0.45       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2638528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011434283 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.32       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 17770       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 0.476       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.473   |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1289     |\n",
      "|    time_elapsed    | 2010     |\n",
      "|    total_timesteps | 2639872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.569      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1290        |\n",
      "|    time_elapsed         | 2012        |\n",
      "|    total_timesteps      | 2641920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012970157 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 0.411       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.72       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1291        |\n",
      "|    time_elapsed         | 2014        |\n",
      "|    total_timesteps      | 2643968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009450825 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 0.668       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.491      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 2015        |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008427777 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.521       |\n",
      "|    n_updates            | 17800       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.7       |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1312       |\n",
      "|    iterations           | 1293       |\n",
      "|    time_elapsed         | 2017       |\n",
      "|    total_timesteps      | 2648064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01012208 |\n",
      "|    clip_fraction        | 0.0881     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.35      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.272      |\n",
      "|    n_updates            | 17810      |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    std                  | 3.56       |\n",
      "|    value_loss           | 0.657      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2648528, episode_reward=-2.28 +/- 5.20\n",
      "Episode length: 32.30 +/- 7.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.3         |\n",
      "|    mean_reward          | -2.28        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2648528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133382175 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.35        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.234        |\n",
      "|    n_updates            | 17820        |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    std                  | 3.53         |\n",
      "|    value_loss           | 0.723        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.511   |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1294     |\n",
      "|    time_elapsed    | 2018     |\n",
      "|    total_timesteps | 2650112  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1295        |\n",
      "|    time_elapsed         | 2020        |\n",
      "|    total_timesteps      | 2652160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008610131 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 17830       |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.0955     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 2021        |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008203057 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 0.611       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.3         |\n",
      "|    ep_rew_mean          | 0.765        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 1297         |\n",
      "|    time_elapsed         | 2023         |\n",
      "|    total_timesteps      | 2656256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105774645 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.33        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.149        |\n",
      "|    n_updates            | 17850        |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    std                  | 3.5          |\n",
      "|    value_loss           | 0.633        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.3       |\n",
      "|    ep_rew_mean          | 0.344      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1312       |\n",
      "|    iterations           | 1298       |\n",
      "|    time_elapsed         | 2024       |\n",
      "|    total_timesteps      | 2658304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00903688 |\n",
      "|    clip_fraction        | 0.0751     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.34      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 17860      |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 3.55       |\n",
      "|    value_loss           | 0.535      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2658528, episode_reward=1.44 +/- 3.57\n",
      "Episode length: 28.00 +/- 6.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 1.44        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2658528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012752071 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0495     |\n",
      "|    n_updates            | 17870       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.00681  |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1299     |\n",
      "|    time_elapsed    | 2026     |\n",
      "|    total_timesteps | 2660352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.0798      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 2027        |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009215629 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.733       |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010075977 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0328      |\n",
      "|    n_updates            | 17890       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.837      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1302        |\n",
      "|    time_elapsed         | 2030        |\n",
      "|    total_timesteps      | 2666496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013053205 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0598      |\n",
      "|    n_updates            | 17900       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2668528, episode_reward=0.01 +/- 4.46\n",
      "Episode length: 30.30 +/- 7.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.3         |\n",
      "|    mean_reward          | 0.0117       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2668528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102588665 |\n",
      "|    clip_fraction        | 0.0919       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.38        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.28         |\n",
      "|    n_updates            | 17910        |\n",
      "|    policy_gradient_loss | -0.0155      |\n",
      "|    std                  | 3.63         |\n",
      "|    value_loss           | 0.71         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.877   |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 1303     |\n",
      "|    time_elapsed    | 2032     |\n",
      "|    total_timesteps | 2668544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.837      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 2033        |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008739876 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.37       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.807       |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 2.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.133       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 2035        |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009678533 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.34       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0507     |\n",
      "|    n_updates            | 17930       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.688      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 2036        |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009540934 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.33       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -1.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 2037        |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010936608 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.35       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 0.571       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2678528, episode_reward=-1.70 +/- 4.73\n",
      "Episode length: 32.50 +/- 6.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 32.5       |\n",
      "|    mean_reward          | -1.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2678528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01107692 |\n",
      "|    clip_fraction        | 0.085      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.39      |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 17960      |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 3.66       |\n",
      "|    value_loss           | 0.362      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.544   |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 1308     |\n",
      "|    time_elapsed    | 2039     |\n",
      "|    total_timesteps | 2678784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.122      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 2040        |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011710061 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.377       |\n",
      "|    n_updates            | 17970       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 0.692       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.241      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 2042        |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011858717 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.43       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0853      |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | -0.528       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 1311         |\n",
      "|    time_elapsed         | 2043         |\n",
      "|    total_timesteps      | 2684928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110938335 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.45        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.161        |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    std                  | 3.78         |\n",
      "|    value_loss           | 0.602        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | 0.00442     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 2045        |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006577871 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.46       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.46        |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 3.79        |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2688528, episode_reward=-2.32 +/- 3.93\n",
      "Episode length: 33.50 +/- 6.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.5        |\n",
      "|    mean_reward          | -2.32       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2688528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007730412 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.46       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 18010       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 0.548       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | 0.48     |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 1313     |\n",
      "|    time_elapsed    | 2046     |\n",
      "|    total_timesteps | 2689024  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.881       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 1314         |\n",
      "|    time_elapsed         | 2048         |\n",
      "|    total_timesteps      | 2691072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116079915 |\n",
      "|    clip_fraction        | 0.0767       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.46        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.063        |\n",
      "|    n_updates            | 18020        |\n",
      "|    policy_gradient_loss | -0.00948     |\n",
      "|    std                  | 3.79         |\n",
      "|    value_loss           | 0.329        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.659       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 2049         |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107213985 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.47        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0866       |\n",
      "|    n_updates            | 18030        |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    std                  | 3.8          |\n",
      "|    value_loss           | 0.262        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 2051        |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007174311 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.48       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 18040       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 0.642       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 2052        |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010460824 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0161     |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2698528, episode_reward=-1.94 +/- 5.28\n",
      "Episode length: 31.50 +/- 9.22\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 31.5       |\n",
      "|    mean_reward          | -1.94      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2698528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01336733 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.49      |\n",
      "|    explained_variance   | 0.952      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.269      |\n",
      "|    n_updates            | 18060      |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    std                  | 3.85       |\n",
      "|    value_loss           | 0.992      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.0982  |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 1318     |\n",
      "|    time_elapsed    | 2054     |\n",
      "|    total_timesteps | 2699264  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.174      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1319        |\n",
      "|    time_elapsed         | 2055        |\n",
      "|    total_timesteps      | 2701312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008148155 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.5        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 18070       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 0.577       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.959      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 2057        |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009724842 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 0.659       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.732      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1321        |\n",
      "|    time_elapsed         | 2058        |\n",
      "|    total_timesteps      | 2705408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009949553 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.527      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 2060        |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009364484 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 18100       |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 0.701       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2708528, episode_reward=-0.25 +/- 5.37\n",
      "Episode length: 30.30 +/- 7.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | -0.255      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2708528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007457285 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 18110       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 0.828       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.224   |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 1323     |\n",
      "|    time_elapsed    | 2062     |\n",
      "|    total_timesteps | 2709504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.335      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 2063        |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009080343 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.55       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 0.723       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1325        |\n",
      "|    time_elapsed         | 2065        |\n",
      "|    total_timesteps      | 2713600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007322291 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.54       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 0.707       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.0131      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1326        |\n",
      "|    time_elapsed         | 2066        |\n",
      "|    total_timesteps      | 2715648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009543959 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0199      |\n",
      "|    n_updates            | 18140       |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.67       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 2068        |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008105321 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0128      |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 3.95        |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2718528, episode_reward=-2.00 +/- 5.92\n",
      "Episode length: 34.60 +/- 13.06\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 34.6       |\n",
      "|    mean_reward          | -2         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2718528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00847637 |\n",
      "|    clip_fraction        | 0.0593     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.54      |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.474      |\n",
      "|    n_updates            | 18160      |\n",
      "|    policy_gradient_loss | -0.00894   |\n",
      "|    std                  | 3.98       |\n",
      "|    value_loss           | 1.04       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -1.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1328     |\n",
      "|    time_elapsed    | 2069     |\n",
      "|    total_timesteps | 2719744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.137      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1329        |\n",
      "|    time_elapsed         | 2070        |\n",
      "|    total_timesteps      | 2721792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014007903 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0719      |\n",
      "|    n_updates            | 18170       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 4.02        |\n",
      "|    value_loss           | 0.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.629       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 2072        |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013042459 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 18180       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 0.697       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.129      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 2073        |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011594268 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.58       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 0.503       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | -0.517       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 2075         |\n",
      "|    total_timesteps      | 2727936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073443237 |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.57        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.128        |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 3.98         |\n",
      "|    value_loss           | 0.417        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2728528, episode_reward=1.92 +/- 4.10\n",
      "Episode length: 27.70 +/- 5.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.7        |\n",
      "|    mean_reward          | 1.92        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2728528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013077032 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0704      |\n",
      "|    n_updates            | 18210       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 3.98        |\n",
      "|    value_loss           | 0.527       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -0.898   |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1333     |\n",
      "|    time_elapsed    | 2076     |\n",
      "|    total_timesteps | 2729984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.919      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 2078        |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009435652 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | -0.83        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 1335         |\n",
      "|    time_elapsed         | 2080         |\n",
      "|    total_timesteps      | 2734080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087586045 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.57        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.236        |\n",
      "|    n_updates            | 18230        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 3.99         |\n",
      "|    value_loss           | 0.695        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1336        |\n",
      "|    time_elapsed         | 2081        |\n",
      "|    total_timesteps      | 2736128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005526877 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.297       |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 1           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 2083        |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006602493 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0181     |\n",
      "|    n_updates            | 18250       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2738528, episode_reward=-0.66 +/- 4.22\n",
      "Episode length: 30.60 +/- 5.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.6        |\n",
      "|    mean_reward          | -0.659      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2738528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008692884 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.324       |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 0.8         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -1       |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1338     |\n",
      "|    time_elapsed    | 2084     |\n",
      "|    total_timesteps | 2740224  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | 0.118        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 1339         |\n",
      "|    time_elapsed         | 2086         |\n",
      "|    total_timesteps      | 2742272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063690613 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.431        |\n",
      "|    n_updates            | 18270        |\n",
      "|    policy_gradient_loss | -0.00984     |\n",
      "|    std                  | 4.21         |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.885      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 2087        |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009458159 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.456       |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -1.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 2089        |\n",
      "|    total_timesteps      | 2746368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006871059 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 0.741       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.626      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 2090        |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008849376 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 18300       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 0.421       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2748528, episode_reward=-1.86 +/- 5.78\n",
      "Episode length: 32.80 +/- 8.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -1.86       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2748528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010396231 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 18310       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 0.825       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.41    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1343     |\n",
      "|    time_elapsed    | 2092     |\n",
      "|    total_timesteps | 2750464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.145      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 2094        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010464402 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 18320       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 0.689       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | 0.199       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1345        |\n",
      "|    time_elapsed         | 2095        |\n",
      "|    total_timesteps      | 2754560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008491125 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 0.331       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1346        |\n",
      "|    time_elapsed         | 2097        |\n",
      "|    total_timesteps      | 2756608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012176362 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.318       |\n",
      "|    n_updates            | 18340       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 4.29        |\n",
      "|    value_loss           | 0.843       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2758528, episode_reward=-0.24 +/- 4.28\n",
      "Episode length: 30.30 +/- 7.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.3         |\n",
      "|    mean_reward          | -0.24        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2758528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060400795 |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0601       |\n",
      "|    n_updates            | 18350        |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    std                  | 4.31         |\n",
      "|    value_loss           | 0.377        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.392    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1347     |\n",
      "|    time_elapsed    | 2098     |\n",
      "|    total_timesteps | 2758656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.545       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 2100        |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010229391 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 0.736       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.72       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1349        |\n",
      "|    time_elapsed         | 2101        |\n",
      "|    total_timesteps      | 2762752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006841924 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 18370       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 0.477       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0537      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 2103        |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011031879 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 18380       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 4.25        |\n",
      "|    value_loss           | 0.484       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.488      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1351        |\n",
      "|    time_elapsed         | 2105        |\n",
      "|    total_timesteps      | 2766848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009562967 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 18390       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 0.578       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2768528, episode_reward=2.14 +/- 4.01\n",
      "Episode length: 26.30 +/- 6.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.3         |\n",
      "|    mean_reward          | 2.14         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2768528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060711117 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0756       |\n",
      "|    n_updates            | 18400        |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    std                  | 4.33         |\n",
      "|    value_loss           | 0.7          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.529   |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1352     |\n",
      "|    time_elapsed    | 2106     |\n",
      "|    total_timesteps | 2768896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.546      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1353        |\n",
      "|    time_elapsed         | 2108        |\n",
      "|    total_timesteps      | 2770944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009646598 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 18410       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 0.589       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.0737      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 2109        |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007076463 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 18420       |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 0.566       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.515      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1355        |\n",
      "|    time_elapsed         | 2111        |\n",
      "|    total_timesteps      | 2775040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008854188 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0572     |\n",
      "|    n_updates            | 18430       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 0.0579      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.821      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 2112        |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008478774 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 18440       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 0.781       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2778528, episode_reward=-0.98 +/- 2.55\n",
      "Episode length: 33.30 +/- 4.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.3        |\n",
      "|    mean_reward          | -0.977      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2778528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007843506 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 18450       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 0.516       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.5     |\n",
      "|    ep_rew_mean     | -1.77    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1357     |\n",
      "|    time_elapsed    | 2114     |\n",
      "|    total_timesteps | 2779136  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -0.806       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 1358         |\n",
      "|    time_elapsed         | 2116         |\n",
      "|    total_timesteps      | 2781184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055895373 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.314        |\n",
      "|    n_updates            | 18460        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 4.35         |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.0596      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 2117        |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010929433 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 18470       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 0.393       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.376      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1360        |\n",
      "|    time_elapsed         | 2119        |\n",
      "|    total_timesteps      | 2785280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020048538 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.193       |\n",
      "|    n_updates            | 18480       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 0.509       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 2121        |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010091306 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 18490       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 4.21        |\n",
      "|    value_loss           | 0.551       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2788528, episode_reward=-0.73 +/- 3.86\n",
      "Episode length: 31.00 +/- 5.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31           |\n",
      "|    mean_reward          | -0.728       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2788528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085874945 |\n",
      "|    clip_fraction        | 0.0664       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0304       |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 4.2          |\n",
      "|    value_loss           | 0.398        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.8     |\n",
      "|    ep_rew_mean     | -1.45    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1362     |\n",
      "|    time_elapsed    | 2122     |\n",
      "|    total_timesteps | 2789376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.353      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1363        |\n",
      "|    time_elapsed         | 2124        |\n",
      "|    total_timesteps      | 2791424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010937569 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.398       |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 0.864       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.9       |\n",
      "|    ep_rew_mean          | -0.163     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1314       |\n",
      "|    iterations           | 1364       |\n",
      "|    time_elapsed         | 2125       |\n",
      "|    total_timesteps      | 2793472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01054652 |\n",
      "|    clip_fraction        | 0.0666     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00619    |\n",
      "|    n_updates            | 18520      |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 4.29       |\n",
      "|    value_loss           | 0.312      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.29        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 2127        |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007073679 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 0.521       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.42       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 2128        |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010192899 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.21        |\n",
      "|    n_updates            | 18540       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 0.654       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2798528, episode_reward=-2.73 +/- 5.21\n",
      "Episode length: 33.90 +/- 7.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.9        |\n",
      "|    mean_reward          | -2.73       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2798528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010859332 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0757      |\n",
      "|    n_updates            | 18550       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 0.43        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | 0.00406  |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1367     |\n",
      "|    time_elapsed    | 2130     |\n",
      "|    total_timesteps | 2799616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.459      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1368        |\n",
      "|    time_elapsed         | 2131        |\n",
      "|    total_timesteps      | 2801664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013619665 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 18560       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.771      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 2133        |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010660132 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 18570       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.336      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1370        |\n",
      "|    time_elapsed         | 2134        |\n",
      "|    total_timesteps      | 2805760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011533877 |\n",
      "|    clip_fraction        | 0.0999      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 18580       |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 0.741       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.624      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 2135        |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009648686 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 18590       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 4.46        |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2808528, episode_reward=1.66 +/- 3.31\n",
      "Episode length: 27.70 +/- 4.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.7        |\n",
      "|    mean_reward          | 1.66        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2808528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010917369 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 0.405       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.329    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1372     |\n",
      "|    time_elapsed    | 2137     |\n",
      "|    total_timesteps | 2809856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.525       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1373        |\n",
      "|    time_elapsed         | 2139        |\n",
      "|    total_timesteps      | 2811904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007862893 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.377       |\n",
      "|    n_updates            | 18610       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.214      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 2140        |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017978787 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.431       |\n",
      "|    n_updates            | 18620       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 0.869       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.792      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 2141        |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010203739 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0418     |\n",
      "|    n_updates            | 18630       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 4.6         |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.247       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 2143        |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009804877 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0937      |\n",
      "|    n_updates            | 18640       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 0.416       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2818528, episode_reward=0.13 +/- 3.35\n",
      "Episode length: 32.00 +/- 5.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32          |\n",
      "|    mean_reward          | 0.133       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2818528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007937567 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0652     |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 0.0608      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.0816   |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1377     |\n",
      "|    time_elapsed    | 2145     |\n",
      "|    total_timesteps | 2820096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.438       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 2146        |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011449156 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.444       |\n",
      "|    n_updates            | 18660       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 4.59        |\n",
      "|    value_loss           | 0.878       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.2       |\n",
      "|    ep_rew_mean          | 0.0664     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1314       |\n",
      "|    iterations           | 1379       |\n",
      "|    time_elapsed         | 2148       |\n",
      "|    total_timesteps      | 2824192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185148 |\n",
      "|    clip_fraction        | 0.0867     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.87      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.042     |\n",
      "|    n_updates            | 18670      |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    std                  | 4.68       |\n",
      "|    value_loss           | 0.0766     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.234      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1380        |\n",
      "|    time_elapsed         | 2149        |\n",
      "|    total_timesteps      | 2826240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011370784 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 18680       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 4.67        |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.721      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 2151        |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009211587 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 18690       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2828528, episode_reward=0.27 +/- 3.65\n",
      "Episode length: 28.30 +/- 5.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.3        |\n",
      "|    mean_reward          | 0.273       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2828528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011187753 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.87       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0868      |\n",
      "|    n_updates            | 18700       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 0.425       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -0.77    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1382     |\n",
      "|    time_elapsed    | 2152     |\n",
      "|    total_timesteps | 2830336  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.285       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1314         |\n",
      "|    iterations           | 1383         |\n",
      "|    time_elapsed         | 2154         |\n",
      "|    total_timesteps      | 2832384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098159285 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.751        |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    std                  | 4.65         |\n",
      "|    value_loss           | 1.72         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.214      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1384        |\n",
      "|    time_elapsed         | 2155        |\n",
      "|    total_timesteps      | 2834432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009295802 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.9        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 18720       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.521      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 2157        |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008551928 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 18730       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 0.756       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2838528, episode_reward=0.92 +/- 4.28\n",
      "Episode length: 29.50 +/- 7.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.5        |\n",
      "|    mean_reward          | 0.922       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2838528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007179323 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.93       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 18740       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.347   |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1386     |\n",
      "|    time_elapsed    | 2158     |\n",
      "|    total_timesteps | 2838528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1387        |\n",
      "|    time_elapsed         | 2160        |\n",
      "|    total_timesteps      | 2840576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009512462 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.94       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.096       |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 4.79        |\n",
      "|    value_loss           | 0.437       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.3      |\n",
      "|    ep_rew_mean          | -0.403    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1315      |\n",
      "|    iterations           | 1388      |\n",
      "|    time_elapsed         | 2161      |\n",
      "|    total_timesteps      | 2842624   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0107728 |\n",
      "|    clip_fraction        | 0.106     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.94     |\n",
      "|    explained_variance   | 0.984     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0516    |\n",
      "|    n_updates            | 18760     |\n",
      "|    policy_gradient_loss | -0.0153   |\n",
      "|    std                  | 4.82      |\n",
      "|    value_loss           | 0.268     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | 0.0464      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 2163        |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012542473 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.163      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 2164        |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008096452 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 18780       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 0.608       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2848528, episode_reward=2.14 +/- 4.63\n",
      "Episode length: 25.80 +/- 7.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.8        |\n",
      "|    mean_reward          | 2.14        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2848528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008355269 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.95       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0523      |\n",
      "|    n_updates            | 18790       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 0.295       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.244   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1391     |\n",
      "|    time_elapsed    | 2166     |\n",
      "|    total_timesteps | 2848768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 2167        |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008322905 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.94       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.238       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 2169        |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011663338 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 18810       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 0.551       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.3         |\n",
      "|    ep_rew_mean          | 0.279        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 2170         |\n",
      "|    total_timesteps      | 2854912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094666695 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.95        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0633      |\n",
      "|    n_updates            | 18820        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 4.76         |\n",
      "|    value_loss           | 0.066        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.717      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1395        |\n",
      "|    time_elapsed         | 2172        |\n",
      "|    total_timesteps      | 2856960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012530012 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0654     |\n",
      "|    n_updates            | 18830       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 0.0555      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2858528, episode_reward=-2.24 +/- 4.32\n",
      "Episode length: 32.20 +/- 7.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.2        |\n",
      "|    mean_reward          | -2.24       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2858528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010019853 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 0.768       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.734   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1396     |\n",
      "|    time_elapsed    | 2173     |\n",
      "|    total_timesteps | 2859008  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.4       |\n",
      "|    ep_rew_mean          | -0.817     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1315       |\n",
      "|    iterations           | 1397       |\n",
      "|    time_elapsed         | 2175       |\n",
      "|    total_timesteps      | 2861056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00777114 |\n",
      "|    clip_fraction        | 0.0884     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.92      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.226      |\n",
      "|    n_updates            | 18850      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 4.73       |\n",
      "|    value_loss           | 0.656      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.0402     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 2176        |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008969566 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 18860       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.284      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 2177        |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012382307 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.89       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 4.7         |\n",
      "|    value_loss           | 0.467       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.11       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 2179        |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009894408 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.319       |\n",
      "|    n_updates            | 18880       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 4.74        |\n",
      "|    value_loss           | 0.851       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2868528, episode_reward=-0.14 +/- 2.84\n",
      "Episode length: 31.80 +/- 4.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.8        |\n",
      "|    mean_reward          | -0.136      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2868528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009576046 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.92       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 18890       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 4.75        |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.358   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1401     |\n",
      "|    time_elapsed    | 2181     |\n",
      "|    total_timesteps | 2869248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 2182        |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010427557 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.94       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.4         |\n",
      "|    n_updates            | 18900       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -1.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1403         |\n",
      "|    time_elapsed         | 2184         |\n",
      "|    total_timesteps      | 2873344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058440575 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.98        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.177        |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.00984     |\n",
      "|    std                  | 4.9          |\n",
      "|    value_loss           | 0.747        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.7         |\n",
      "|    ep_rew_mean          | -0.425       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1404         |\n",
      "|    time_elapsed         | 2185         |\n",
      "|    total_timesteps      | 2875392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062651783 |\n",
      "|    clip_fraction        | 0.0575       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.99        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.241        |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 4.9          |\n",
      "|    value_loss           | 0.451        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -0.508      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 2186        |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012185201 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0987      |\n",
      "|    n_updates            | 18930       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2878528, episode_reward=-3.42 +/- 3.27\n",
      "Episode length: 36.30 +/- 5.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 36.3         |\n",
      "|    mean_reward          | -3.42        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2878528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050468585 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.01        |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.379        |\n",
      "|    n_updates            | 18940        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 4.97         |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.437   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1406     |\n",
      "|    time_elapsed    | 2188     |\n",
      "|    total_timesteps | 2879488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.161      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1407        |\n",
      "|    time_elapsed         | 2190        |\n",
      "|    total_timesteps      | 2881536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008084662 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.02       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 18950       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 0.557       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.0117      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 2191        |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011286883 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 18960       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 0.736       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | 0.483        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1409         |\n",
      "|    time_elapsed         | 2192         |\n",
      "|    total_timesteps      | 2885632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067085368 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.03        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0727       |\n",
      "|    n_updates            | 18970        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 5            |\n",
      "|    value_loss           | 0.37         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.177      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 2194        |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009243394 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.365       |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 5.02        |\n",
      "|    value_loss           | 0.91        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2888528, episode_reward=-1.20 +/- 6.51\n",
      "Episode length: 32.20 +/- 11.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.2        |\n",
      "|    mean_reward          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2888528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008024182 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 18990       |\n",
      "|    policy_gradient_loss | -0.00993    |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | -0.0597  |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1411     |\n",
      "|    time_elapsed    | 2196     |\n",
      "|    total_timesteps | 2889728  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.1         |\n",
      "|    ep_rew_mean          | 0.25         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1412         |\n",
      "|    time_elapsed         | 2197         |\n",
      "|    total_timesteps      | 2891776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111085335 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.01        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0608       |\n",
      "|    n_updates            | 19000        |\n",
      "|    policy_gradient_loss | -0.0127      |\n",
      "|    std                  | 5            |\n",
      "|    value_loss           | 0.409        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.0864     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 2199        |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011817714 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.04       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00294     |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.481      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1414        |\n",
      "|    time_elapsed         | 2200        |\n",
      "|    total_timesteps      | 2895872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007017521 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.04       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.558       |\n",
      "|    n_updates            | 19020       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.298      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1415        |\n",
      "|    time_elapsed         | 2202        |\n",
      "|    total_timesteps      | 2897920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006833988 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.04       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.413       |\n",
      "|    n_updates            | 19030       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 5.05        |\n",
      "|    value_loss           | 0.958       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2898528, episode_reward=-2.37 +/- 7.13\n",
      "Episode length: 34.50 +/- 17.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.5        |\n",
      "|    mean_reward          | -2.37       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2898528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010806987 |\n",
      "|    clip_fraction        | 0.0861      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 19040       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 0.635       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.504   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1416     |\n",
      "|    time_elapsed    | 2204     |\n",
      "|    total_timesteps | 2899968  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | 0.051        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1417         |\n",
      "|    time_elapsed         | 2205         |\n",
      "|    total_timesteps      | 2902016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063163317 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.02        |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.648        |\n",
      "|    n_updates            | 19050        |\n",
      "|    policy_gradient_loss | -0.00969     |\n",
      "|    std                  | 4.97         |\n",
      "|    value_loss           | 1.7          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -0.599      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1418        |\n",
      "|    time_elapsed         | 2207        |\n",
      "|    total_timesteps      | 2904064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005064816 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 19060       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    std                  | 4.96        |\n",
      "|    value_loss           | 0.637       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.151      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 2208        |\n",
      "|    total_timesteps      | 2906112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007602576 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.325       |\n",
      "|    n_updates            | 19070       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -0.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 2210        |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006841606 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.395       |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2908528, episode_reward=1.11 +/- 5.85\n",
      "Episode length: 29.50 +/- 8.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.5        |\n",
      "|    mean_reward          | 1.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2908528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009981199 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.28        |\n",
      "|    n_updates            | 19090       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 0.858       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.796   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1421     |\n",
      "|    time_elapsed    | 2212     |\n",
      "|    total_timesteps | 2910208  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.419      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 2213        |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006862635 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.266       |\n",
      "|    n_updates            | 19100       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 0.727       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.906      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 2215        |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008572702 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 19110       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 0.357       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 2216        |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006128555 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.265       |\n",
      "|    n_updates            | 19120       |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 0.968       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.824      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1425        |\n",
      "|    time_elapsed         | 2217        |\n",
      "|    total_timesteps      | 2918400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009619499 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 19130       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2918528, episode_reward=-1.31 +/- 6.00\n",
      "Episode length: 31.00 +/- 7.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31          |\n",
      "|    mean_reward          | -1.31       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2918528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006315657 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.306       |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 0.96        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33       |\n",
      "|    ep_rew_mean     | -1.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1426     |\n",
      "|    time_elapsed    | 2219     |\n",
      "|    total_timesteps | 2920448  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.578      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 2220        |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007745567 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.223       |\n",
      "|    n_updates            | 19150       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 0.725       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.586      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1428        |\n",
      "|    time_elapsed         | 2222        |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006624725 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.218       |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 0.658       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.126      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1429        |\n",
      "|    time_elapsed         | 2223        |\n",
      "|    total_timesteps      | 2926592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009763567 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.29        |\n",
      "|    n_updates            | 19170       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 0.76        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2928528, episode_reward=1.03 +/- 5.44\n",
      "Episode length: 28.50 +/- 8.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.5        |\n",
      "|    mean_reward          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2928528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008308115 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.702   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1430     |\n",
      "|    time_elapsed    | 2225     |\n",
      "|    total_timesteps | 2928640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.826      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1431        |\n",
      "|    time_elapsed         | 2226        |\n",
      "|    total_timesteps      | 2930688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009928714 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 19190       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 0.755       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.0494      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 2228        |\n",
      "|    total_timesteps      | 2932736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009209851 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 19200       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.427       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 2229        |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008892177 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0969      |\n",
      "|    n_updates            | 19210       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 4.88        |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.4        |\n",
      "|    ep_rew_mean          | 0.672       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 2231        |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123254 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 0.658       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2938528, episode_reward=0.92 +/- 3.71\n",
      "Episode length: 29.30 +/- 5.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.3        |\n",
      "|    mean_reward          | 0.921       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2938528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010309423 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0689     |\n",
      "|    n_updates            | 19230       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 0.0846      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.403   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1435     |\n",
      "|    time_elapsed    | 2232     |\n",
      "|    total_timesteps | 2938880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.711      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 2234        |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009473931 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6          |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 19240       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 0.734       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.732      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1437        |\n",
      "|    time_elapsed         | 2235        |\n",
      "|    total_timesteps      | 2942976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008681792 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.036       |\n",
      "|    n_updates            | 19250       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.851       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1438         |\n",
      "|    time_elapsed         | 2237         |\n",
      "|    total_timesteps      | 2945024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089540295 |\n",
      "|    clip_fraction        | 0.0828       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.96        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0811       |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 4.83         |\n",
      "|    value_loss           | 0.488        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.252      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 2238        |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014635313 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 19270       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 0.609       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2948528, episode_reward=2.18 +/- 3.41\n",
      "Episode length: 26.50 +/- 5.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.5        |\n",
      "|    mean_reward          | 2.18        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2948528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009840838 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 19280       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 0.568       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.401   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1440     |\n",
      "|    time_elapsed    | 2240     |\n",
      "|    total_timesteps | 2949120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.412      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 2241        |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010028388 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6          |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0373      |\n",
      "|    n_updates            | 19290       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.739      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1442        |\n",
      "|    time_elapsed         | 2243        |\n",
      "|    total_timesteps      | 2953216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008104359 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6          |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0803      |\n",
      "|    n_updates            | 19300       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 4.86        |\n",
      "|    value_loss           | 0.267       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -1.07       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 2244        |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008813392 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 19310       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 0.892       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31         |\n",
      "|    ep_rew_mean          | -0.421     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1444       |\n",
      "|    time_elapsed         | 2246       |\n",
      "|    total_timesteps      | 2957312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01241902 |\n",
      "|    clip_fraction        | 0.0996     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.01      |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.152      |\n",
      "|    n_updates            | 19320      |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 4.98       |\n",
      "|    value_loss           | 0.51       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2958528, episode_reward=0.67 +/- 4.47\n",
      "Episode length: 28.50 +/- 7.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.5        |\n",
      "|    mean_reward          | 0.669       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2958528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007994321 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 19330       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 4.99        |\n",
      "|    value_loss           | 0.685       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.831   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1445     |\n",
      "|    time_elapsed    | 2247     |\n",
      "|    total_timesteps | 2959360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 2249        |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008271858 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.612       |\n",
      "|    n_updates            | 19340       |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.44        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1447         |\n",
      "|    time_elapsed         | 2250         |\n",
      "|    total_timesteps      | 2963456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091991685 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.02        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0577      |\n",
      "|    n_updates            | 19350        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    std                  | 4.94         |\n",
      "|    value_loss           | 0.083        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.225      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 2251        |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015178068 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0364     |\n",
      "|    n_updates            | 19360       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.463      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1449        |\n",
      "|    time_elapsed         | 2253        |\n",
      "|    total_timesteps      | 2967552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012457725 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 19370       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 0.576       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2968528, episode_reward=2.41 +/- 4.35\n",
      "Episode length: 25.80 +/- 9.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.8        |\n",
      "|    mean_reward          | 2.41        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2968528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012947991 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 19380       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.34     |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1450     |\n",
      "|    time_elapsed    | 2254     |\n",
      "|    total_timesteps | 2969600  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.377      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 2256        |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012753835 |\n",
      "|    clip_fraction        | 0.0995      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 19390       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 4.88        |\n",
      "|    value_loss           | 0.69        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | -0.176       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 2257         |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073774094 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.99        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.16         |\n",
      "|    n_updates            | 19400        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    std                  | 4.84         |\n",
      "|    value_loss           | 0.516        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.582      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1453        |\n",
      "|    time_elapsed         | 2259        |\n",
      "|    total_timesteps      | 2975744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008831274 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 19410       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33         |\n",
      "|    ep_rew_mean          | -0.972     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1317       |\n",
      "|    iterations           | 1454       |\n",
      "|    time_elapsed         | 2260       |\n",
      "|    total_timesteps      | 2977792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00688099 |\n",
      "|    clip_fraction        | 0.0677     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.97      |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.394      |\n",
      "|    n_updates            | 19420      |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    std                  | 4.84       |\n",
      "|    value_loss           | 1.27       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2978528, episode_reward=-0.69 +/- 4.68\n",
      "Episode length: 31.30 +/- 6.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.3        |\n",
      "|    mean_reward          | -0.694      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2978528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006767189 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.328       |\n",
      "|    n_updates            | 19430       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 0.966       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.322   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1455     |\n",
      "|    time_elapsed    | 2262     |\n",
      "|    total_timesteps | 2979840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1456        |\n",
      "|    time_elapsed         | 2263        |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013361583 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 19440       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.181      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 2265        |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006981329 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.469       |\n",
      "|    n_updates            | 19450       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.836      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1458        |\n",
      "|    time_elapsed         | 2266        |\n",
      "|    total_timesteps      | 2985984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008013331 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.97       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 19460       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 4.83        |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.679      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 2268        |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008101676 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.366       |\n",
      "|    n_updates            | 19470       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2988528, episode_reward=-1.20 +/- 4.04\n",
      "Episode length: 30.70 +/- 5.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.7         |\n",
      "|    mean_reward          | -1.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2988528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063865827 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6           |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0904       |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 4.9          |\n",
      "|    value_loss           | 0.502        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | 0.331    |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1460     |\n",
      "|    time_elapsed    | 2270     |\n",
      "|    total_timesteps | 2990080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 2271        |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009807978 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6          |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 19490       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 4.93        |\n",
      "|    value_loss           | 0.819       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | -0.000457   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1462        |\n",
      "|    time_elapsed         | 2273        |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012300316 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.01       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 19500       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 4.93        |\n",
      "|    value_loss           | 0.437       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.187       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1463        |\n",
      "|    time_elapsed         | 2274        |\n",
      "|    total_timesteps      | 2996224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010102443 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.03       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0619      |\n",
      "|    n_updates            | 19510       |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 0.435       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1464        |\n",
      "|    time_elapsed         | 2276        |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011102119 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.06       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 19520       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 5.07        |\n",
      "|    value_loss           | 0.448       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2998528, episode_reward=-0.86 +/- 5.48\n",
      "Episode length: 30.30 +/- 8.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | -0.861      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2998528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009960857 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.08       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 19530       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 0.347       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | -0.155   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1465     |\n",
      "|    time_elapsed    | 2277     |\n",
      "|    total_timesteps | 3000320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.243       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 2279        |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010490522 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.09       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 19540       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 5.15        |\n",
      "|    value_loss           | 0.634       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.603      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 2280        |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008107537 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.1        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0529     |\n",
      "|    n_updates            | 19550       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 5.12        |\n",
      "|    value_loss           | 0.0897      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | -0.927       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1468         |\n",
      "|    time_elapsed         | 2282         |\n",
      "|    total_timesteps      | 3006464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077251536 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.09        |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.336        |\n",
      "|    n_updates            | 19560        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 5.12         |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.563      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 2283        |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008833066 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.1        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 19570       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 0.68        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3008528, episode_reward=-1.84 +/- 6.66\n",
      "Episode length: 32.20 +/- 8.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.2         |\n",
      "|    mean_reward          | -1.84        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3008528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076373992 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.12        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.174        |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    std                  | 5.21         |\n",
      "|    value_loss           | 0.626        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.0248  |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1470     |\n",
      "|    time_elapsed    | 2285     |\n",
      "|    total_timesteps | 3010560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.575       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 2286        |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006487876 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.12       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 19590       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 0.747       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.4       |\n",
      "|    ep_rew_mean          | -0.739     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1317       |\n",
      "|    iterations           | 1472       |\n",
      "|    time_elapsed         | 2288       |\n",
      "|    total_timesteps      | 3014656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00864243 |\n",
      "|    clip_fraction        | 0.0663     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.12      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0659    |\n",
      "|    n_updates            | 19600      |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 5.2        |\n",
      "|    value_loss           | 0.064      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.109       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1473        |\n",
      "|    time_elapsed         | 2289        |\n",
      "|    total_timesteps      | 3016704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008055175 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.12       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 19610       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 0.357       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3018528, episode_reward=-2.83 +/- 6.16\n",
      "Episode length: 32.30 +/- 9.96\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 32.3       |\n",
      "|    mean_reward          | -2.83      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3018528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00736616 |\n",
      "|    clip_fraction        | 0.0492     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.13      |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.481      |\n",
      "|    n_updates            | 19620      |\n",
      "|    policy_gradient_loss | -0.00956   |\n",
      "|    std                  | 5.28       |\n",
      "|    value_loss           | 1.41       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.989   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1474     |\n",
      "|    time_elapsed    | 2291     |\n",
      "|    total_timesteps | 3018752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.863      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1475        |\n",
      "|    time_elapsed         | 2293        |\n",
      "|    total_timesteps      | 3020800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007524005 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.15       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 19630       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 0.559       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.323      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 2294        |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012763272 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.13       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0251     |\n",
      "|    n_updates            | 19640       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.111       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1477        |\n",
      "|    time_elapsed         | 2296        |\n",
      "|    total_timesteps      | 3024896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009887387 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.15       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.014       |\n",
      "|    n_updates            | 19650       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | -0.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1478         |\n",
      "|    time_elapsed         | 2297         |\n",
      "|    total_timesteps      | 3026944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076695243 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.17        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.214        |\n",
      "|    n_updates            | 19660        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 5.32         |\n",
      "|    value_loss           | 0.689        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3028528, episode_reward=1.65 +/- 4.70\n",
      "Episode length: 26.20 +/- 7.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.2        |\n",
      "|    mean_reward          | 1.65        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3028528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007906404 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.14       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0642     |\n",
      "|    n_updates            | 19670       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 0.0709      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | -0.235   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1479     |\n",
      "|    time_elapsed    | 2299     |\n",
      "|    total_timesteps | 3028992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0827      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1480        |\n",
      "|    time_elapsed         | 2300        |\n",
      "|    total_timesteps      | 3031040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009984844 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.12       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 19680       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 0.438       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.134       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 2302        |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009513914 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.12       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.234       |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 0.688       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.8         |\n",
      "|    ep_rew_mean          | 0.402        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1482         |\n",
      "|    time_elapsed         | 2303         |\n",
      "|    total_timesteps      | 3035136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058047203 |\n",
      "|    clip_fraction        | 0.067        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.13        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0924       |\n",
      "|    n_updates            | 19700        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 5.24         |\n",
      "|    value_loss           | 0.525        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.0473      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1483        |\n",
      "|    time_elapsed         | 2305        |\n",
      "|    total_timesteps      | 3037184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008612288 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.12       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0559     |\n",
      "|    n_updates            | 19710       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3038528, episode_reward=1.74 +/- 5.47\n",
      "Episode length: 28.30 +/- 8.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.3        |\n",
      "|    mean_reward          | 1.74        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3038528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010117919 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.11       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0573     |\n",
      "|    n_updates            | 19720       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.312    |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1484     |\n",
      "|    time_elapsed    | 2306     |\n",
      "|    total_timesteps | 3039232  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.1       |\n",
      "|    ep_rew_mean          | -0.869     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1317       |\n",
      "|    iterations           | 1485       |\n",
      "|    time_elapsed         | 2308       |\n",
      "|    total_timesteps      | 3041280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00683048 |\n",
      "|    clip_fraction        | 0.0944     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.13      |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.116      |\n",
      "|    n_updates            | 19730      |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 5.27       |\n",
      "|    value_loss           | 0.369      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1486        |\n",
      "|    time_elapsed         | 2309        |\n",
      "|    total_timesteps      | 3043328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007911567 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.14       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.285       |\n",
      "|    n_updates            | 19740       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 0.883       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.284      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1487        |\n",
      "|    time_elapsed         | 2311        |\n",
      "|    total_timesteps      | 3045376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009589111 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.16       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 19750       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.554      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 2312        |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008014502 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.15       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 19760       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 0.331       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3048528, episode_reward=0.21 +/- 3.79\n",
      "Episode length: 29.90 +/- 5.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | 0.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3048528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007447711 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.16       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0161     |\n",
      "|    n_updates            | 19770       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.154    |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1489     |\n",
      "|    time_elapsed    | 2314     |\n",
      "|    total_timesteps | 3049472  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.5         |\n",
      "|    ep_rew_mean          | -0.0404      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1490         |\n",
      "|    time_elapsed         | 2315         |\n",
      "|    total_timesteps      | 3051520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068849777 |\n",
      "|    clip_fraction        | 0.0734       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.16        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.00225      |\n",
      "|    n_updates            | 19780        |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    std                  | 5.36         |\n",
      "|    value_loss           | 0.238        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.423      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1491        |\n",
      "|    time_elapsed         | 2317        |\n",
      "|    total_timesteps      | 3053568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012393347 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.15       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0839     |\n",
      "|    n_updates            | 19790       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 5.26        |\n",
      "|    value_loss           | 0.0353      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.403       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1492         |\n",
      "|    time_elapsed         | 2318         |\n",
      "|    total_timesteps      | 3055616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065255007 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.12        |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.311        |\n",
      "|    n_updates            | 19800        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 5.27         |\n",
      "|    value_loss           | 1            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.452      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 2320        |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008343854 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.14       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.678       |\n",
      "|    n_updates            | 19810       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3058528, episode_reward=-0.66 +/- 7.35\n",
      "Episode length: 30.40 +/- 9.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.4        |\n",
      "|    mean_reward          | -0.661      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3058528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009420242 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.15       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 19820       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1494     |\n",
      "|    time_elapsed    | 2322     |\n",
      "|    total_timesteps | 3059712  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29           |\n",
      "|    ep_rew_mean          | 0.507        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1495         |\n",
      "|    time_elapsed         | 2323         |\n",
      "|    total_timesteps      | 3061760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075086094 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.14        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.255        |\n",
      "|    n_updates            | 19830        |\n",
      "|    policy_gradient_loss | -0.00858     |\n",
      "|    std                  | 5.29         |\n",
      "|    value_loss           | 0.896        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.175       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 2325        |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009309876 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.13       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 19840       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 0.391       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1497        |\n",
      "|    time_elapsed         | 2326        |\n",
      "|    total_timesteps      | 3065856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009079875 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.12       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.058       |\n",
      "|    n_updates            | 19850       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 0.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.54       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 2328        |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005708484 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.14       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0405      |\n",
      "|    n_updates            | 19860       |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    std                  | 5.3         |\n",
      "|    value_loss           | 0.364       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3068528, episode_reward=-1.80 +/- 4.18\n",
      "Episode length: 33.10 +/- 5.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.1        |\n",
      "|    mean_reward          | -1.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3068528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008263348 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.15       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.328       |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 0.964       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.565   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1499     |\n",
      "|    time_elapsed    | 2329     |\n",
      "|    total_timesteps | 3069952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.148      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1500        |\n",
      "|    time_elapsed         | 2331        |\n",
      "|    total_timesteps      | 3072000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006200043 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.16       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 19880       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 5.35        |\n",
      "|    value_loss           | 0.587       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.818      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1501        |\n",
      "|    time_elapsed         | 2332        |\n",
      "|    total_timesteps      | 3074048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009828001 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.18       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 19890       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 0.559       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -1.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1502         |\n",
      "|    time_elapsed         | 2334         |\n",
      "|    total_timesteps      | 3076096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084859505 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.21        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.221        |\n",
      "|    n_updates            | 19900        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 5.53         |\n",
      "|    value_loss           | 0.753        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.843       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1503         |\n",
      "|    time_elapsed         | 2336         |\n",
      "|    total_timesteps      | 3078144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076584443 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.23        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0545       |\n",
      "|    n_updates            | 19910        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 5.47         |\n",
      "|    value_loss           | 0.302        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3078528, episode_reward=-1.57 +/- 5.75\n",
      "Episode length: 34.60 +/- 12.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.6        |\n",
      "|    mean_reward          | -1.57       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3078528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008070293 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.2        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.192       |\n",
      "|    n_updates            | 19920       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 0.921       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.6     |\n",
      "|    ep_rew_mean     | -1.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1504     |\n",
      "|    time_elapsed    | 2337     |\n",
      "|    total_timesteps | 3080192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.0769     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 2339        |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008228193 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.23       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.378       |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    std                  | 5.56        |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.198       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1506        |\n",
      "|    time_elapsed         | 2340        |\n",
      "|    total_timesteps      | 3084288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009681197 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.24       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 19940       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 0.548       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.155       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1507        |\n",
      "|    time_elapsed         | 2342        |\n",
      "|    total_timesteps      | 3086336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009433069 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.25       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 19950       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 0.567       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -0.821       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1508         |\n",
      "|    time_elapsed         | 2343         |\n",
      "|    total_timesteps      | 3088384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065335664 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.25        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0778       |\n",
      "|    n_updates            | 19960        |\n",
      "|    policy_gradient_loss | -0.00814     |\n",
      "|    std                  | 5.55         |\n",
      "|    value_loss           | 0.46         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3088528, episode_reward=0.84 +/- 4.52\n",
      "Episode length: 28.70 +/- 6.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.7        |\n",
      "|    mean_reward          | 0.843       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3088528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006264976 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.23       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.294       |\n",
      "|    n_updates            | 19970       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 5.52        |\n",
      "|    value_loss           | 0.975       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.323   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1509     |\n",
      "|    time_elapsed    | 2345     |\n",
      "|    total_timesteps | 3090432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.635      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 2347        |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009455516 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.24       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.382       |\n",
      "|    n_updates            | 19980       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 0.063        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1511         |\n",
      "|    time_elapsed         | 2348         |\n",
      "|    total_timesteps      | 3094528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077099437 |\n",
      "|    clip_fraction        | 0.0537       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.25        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.0138      |\n",
      "|    std                  | 5.54         |\n",
      "|    value_loss           | 0.559        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.365       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1512         |\n",
      "|    time_elapsed         | 2350         |\n",
      "|    total_timesteps      | 3096576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058878614 |\n",
      "|    clip_fraction        | 0.061        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.24        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0189       |\n",
      "|    n_updates            | 20000        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 5.54         |\n",
      "|    value_loss           | 0.305        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3098528, episode_reward=-0.75 +/- 4.15\n",
      "Episode length: 32.50 +/- 9.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.5        |\n",
      "|    mean_reward          | -0.746      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3098528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007159475 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.23       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 5.55        |\n",
      "|    value_loss           | 0.641       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -1.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1513     |\n",
      "|    time_elapsed    | 2351     |\n",
      "|    total_timesteps | 3098624  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -1.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1514         |\n",
      "|    time_elapsed         | 2353         |\n",
      "|    total_timesteps      | 3100672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047950796 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.24        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.385        |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.00769     |\n",
      "|    std                  | 5.59         |\n",
      "|    value_loss           | 0.686        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.386      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 2354        |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009325031 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.25       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0986      |\n",
      "|    n_updates            | 20030       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 5.58        |\n",
      "|    value_loss           | 0.526       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.267       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1516        |\n",
      "|    time_elapsed         | 2356        |\n",
      "|    total_timesteps      | 3104768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009800919 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.26       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0428     |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 5.61        |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.511      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1517        |\n",
      "|    time_elapsed         | 2357        |\n",
      "|    total_timesteps      | 3106816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010195052 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.26       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0538     |\n",
      "|    n_updates            | 20050       |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 0.0835      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3108528, episode_reward=2.65 +/- 5.03\n",
      "Episode length: 25.80 +/- 7.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.8        |\n",
      "|    mean_reward          | 2.65        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3108528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009936515 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.24       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.628   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1518     |\n",
      "|    time_elapsed    | 2359     |\n",
      "|    total_timesteps | 3108864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 2360        |\n",
      "|    total_timesteps      | 3110912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005663316 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.23       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0498      |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 5.48        |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 2362        |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008611042 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.22       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 20080       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 5.48        |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.787      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1521        |\n",
      "|    time_elapsed         | 2363        |\n",
      "|    total_timesteps      | 3115008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007838996 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.25       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.067       |\n",
      "|    n_updates            | 20090       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 0.343       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.307      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 2365        |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008230912 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.28       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 20100       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 5.62        |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3118528, episode_reward=-3.06 +/- 5.84\n",
      "Episode length: 35.00 +/- 7.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35          |\n",
      "|    mean_reward          | -3.06       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3118528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012829821 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.28       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0775     |\n",
      "|    n_updates            | 20110       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 0.0367      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.838   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1523     |\n",
      "|    time_elapsed    | 2366     |\n",
      "|    total_timesteps | 3119104  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1524         |\n",
      "|    time_elapsed         | 2368         |\n",
      "|    total_timesteps      | 3121152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053693075 |\n",
      "|    clip_fraction        | 0.06         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.29        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.477        |\n",
      "|    n_updates            | 20120        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    std                  | 5.62         |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | -0.126       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1525         |\n",
      "|    time_elapsed         | 2370         |\n",
      "|    total_timesteps      | 3123200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074805566 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.29        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.199        |\n",
      "|    n_updates            | 20130        |\n",
      "|    policy_gradient_loss | -0.00954     |\n",
      "|    std                  | 5.67         |\n",
      "|    value_loss           | 0.516        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1526        |\n",
      "|    time_elapsed         | 2371        |\n",
      "|    total_timesteps      | 3125248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007542359 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.3        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00365     |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -1.31        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1527         |\n",
      "|    time_elapsed         | 2373         |\n",
      "|    total_timesteps      | 3127296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046042847 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.31        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.433        |\n",
      "|    n_updates            | 20150        |\n",
      "|    policy_gradient_loss | -0.00907     |\n",
      "|    std                  | 5.72         |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3128528, episode_reward=-0.21 +/- 5.14\n",
      "Episode length: 32.70 +/- 6.96\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 32.7      |\n",
      "|    mean_reward          | -0.206    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3128528   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0085827 |\n",
      "|    clip_fraction        | 0.0686    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -6.32     |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0263   |\n",
      "|    n_updates            | 20160     |\n",
      "|    policy_gradient_loss | -0.0125   |\n",
      "|    std                  | 5.75      |\n",
      "|    value_loss           | 0.182     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -1.17    |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1528     |\n",
      "|    time_elapsed    | 2374     |\n",
      "|    total_timesteps | 3129344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1529        |\n",
      "|    time_elapsed         | 2376        |\n",
      "|    total_timesteps      | 3131392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009861491 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.33       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 20170       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 0.731       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.8       |\n",
      "|    ep_rew_mean          | -0.551     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1317       |\n",
      "|    iterations           | 1530       |\n",
      "|    time_elapsed         | 2377       |\n",
      "|    total_timesteps      | 3133440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01183781 |\n",
      "|    clip_fraction        | 0.0944     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.34      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0692     |\n",
      "|    n_updates            | 20180      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 5.86       |\n",
      "|    value_loss           | 0.353      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.0719      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1531        |\n",
      "|    time_elapsed         | 2379        |\n",
      "|    total_timesteps      | 3135488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009472496 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 20190       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.145       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 2380        |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005454416 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 20200       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3138528, episode_reward=-1.15 +/- 5.54\n",
      "Episode length: 31.30 +/- 8.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.3        |\n",
      "|    mean_reward          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3138528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011654263 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.35       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0773     |\n",
      "|    n_updates            | 20210       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 5.75        |\n",
      "|    value_loss           | 0.0339      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.148    |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1533     |\n",
      "|    time_elapsed    | 2382     |\n",
      "|    total_timesteps | 3139584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -1.23       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1534        |\n",
      "|    time_elapsed         | 2384        |\n",
      "|    total_timesteps      | 3141632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009529704 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.32       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.305       |\n",
      "|    n_updates            | 20220       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 5.78        |\n",
      "|    value_loss           | 0.931       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.762       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1535         |\n",
      "|    time_elapsed         | 2385         |\n",
      "|    total_timesteps      | 3143680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043895347 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.34        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.265        |\n",
      "|    n_updates            | 20230        |\n",
      "|    policy_gradient_loss | -0.00859     |\n",
      "|    std                  | 5.79         |\n",
      "|    value_loss           | 0.744        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.273      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1536        |\n",
      "|    time_elapsed         | 2387        |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009453044 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 20240       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 0.528       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.5         |\n",
      "|    ep_rew_mean          | 0.0359       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1537         |\n",
      "|    time_elapsed         | 2389         |\n",
      "|    total_timesteps      | 3147776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070879096 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.33        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0667      |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 5.7          |\n",
      "|    value_loss           | 0.102        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3148528, episode_reward=1.06 +/- 4.34\n",
      "Episode length: 26.90 +/- 10.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 26.9       |\n",
      "|    mean_reward          | 1.06       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3148528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00811233 |\n",
      "|    clip_fraction        | 0.0691     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.3       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0807     |\n",
      "|    n_updates            | 20260      |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 5.67       |\n",
      "|    value_loss           | 0.506      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.433    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1538     |\n",
      "|    time_elapsed    | 2391     |\n",
      "|    total_timesteps | 3149824  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | -0.233       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1539         |\n",
      "|    time_elapsed         | 2393         |\n",
      "|    total_timesteps      | 3151872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076336004 |\n",
      "|    clip_fraction        | 0.0773       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.29        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0782       |\n",
      "|    n_updates            | 20270        |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    std                  | 5.67         |\n",
      "|    value_loss           | 0.421        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | -0.434       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1540         |\n",
      "|    time_elapsed         | 2394         |\n",
      "|    total_timesteps      | 3153920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069911564 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.3         |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0773       |\n",
      "|    n_updates            | 20280        |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    std                  | 5.74         |\n",
      "|    value_loss           | 0.422        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1541        |\n",
      "|    time_elapsed         | 2396        |\n",
      "|    total_timesteps      | 3155968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008421536 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.33       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 20290       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.7         |\n",
      "|    ep_rew_mean          | -0.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1542         |\n",
      "|    time_elapsed         | 2397         |\n",
      "|    total_timesteps      | 3158016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036670938 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.34        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.346        |\n",
      "|    n_updates            | 20300        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    std                  | 5.84         |\n",
      "|    value_loss           | 0.921        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3158528, episode_reward=2.01 +/- 4.35\n",
      "Episode length: 27.50 +/- 11.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.5        |\n",
      "|    mean_reward          | 2.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3158528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007738391 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.36       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0776      |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 0.304       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.416   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1543     |\n",
      "|    time_elapsed    | 2399     |\n",
      "|    total_timesteps | 3160064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.838      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1544        |\n",
      "|    time_elapsed         | 2401        |\n",
      "|    total_timesteps      | 3162112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009682163 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.36       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.322       |\n",
      "|    n_updates            | 20320       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 0.942       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.0268      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1545        |\n",
      "|    time_elapsed         | 2402        |\n",
      "|    total_timesteps      | 3164160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011855801 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.35       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 20330       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.668       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1546        |\n",
      "|    time_elapsed         | 2404        |\n",
      "|    total_timesteps      | 3166208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976763 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.33       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0632     |\n",
      "|    n_updates            | 20340       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 5.8         |\n",
      "|    value_loss           | 0.0775      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.264      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1547        |\n",
      "|    time_elapsed         | 2405        |\n",
      "|    total_timesteps      | 3168256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014664812 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0231      |\n",
      "|    n_updates            | 20350       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3168528, episode_reward=2.85 +/- 2.68\n",
      "Episode length: 27.50 +/- 4.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 27.5       |\n",
      "|    mean_reward          | 2.85       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3168528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00799761 |\n",
      "|    clip_fraction        | 0.0979     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.35      |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.108      |\n",
      "|    n_updates            | 20360      |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 5.89       |\n",
      "|    value_loss           | 0.549      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | -0.952   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1548     |\n",
      "|    time_elapsed    | 2407     |\n",
      "|    total_timesteps | 3170304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.708       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 2408        |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007246167 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.38       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.858       |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | 0.721        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1550         |\n",
      "|    time_elapsed         | 2410         |\n",
      "|    total_timesteps      | 3174400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070674904 |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.39        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0738       |\n",
      "|    n_updates            | 20380        |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    std                  | 5.93         |\n",
      "|    value_loss           | 0.439        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.259       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1551         |\n",
      "|    time_elapsed         | 2411         |\n",
      "|    total_timesteps      | 3176448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076667853 |\n",
      "|    clip_fraction        | 0.0694       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.37        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0984       |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 5.88         |\n",
      "|    value_loss           | 0.406        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.0135     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1552        |\n",
      "|    time_elapsed         | 2413        |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007726482 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0565     |\n",
      "|    n_updates            | 20400       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 5.94        |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3178528, episode_reward=2.47 +/- 4.83\n",
      "Episode length: 28.00 +/- 8.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 2.47        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3178528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008456884 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.38       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.437    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1553     |\n",
      "|    time_elapsed    | 2415     |\n",
      "|    total_timesteps | 3180544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.344      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1554        |\n",
      "|    time_elapsed         | 2416        |\n",
      "|    total_timesteps      | 3182592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007855264 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 20420       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 5.76        |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.29       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1555        |\n",
      "|    time_elapsed         | 2417        |\n",
      "|    total_timesteps      | 3184640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012993819 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.33       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0205     |\n",
      "|    n_updates            | 20430       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 5.77        |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.511      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1556        |\n",
      "|    time_elapsed         | 2419        |\n",
      "|    total_timesteps      | 3186688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011204721 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 20440       |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    std                  | 5.85        |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3188528, episode_reward=1.80 +/- 4.76\n",
      "Episode length: 28.50 +/- 7.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.5        |\n",
      "|    mean_reward          | 1.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3188528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009415783 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.36       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0644     |\n",
      "|    n_updates            | 20450       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 0.0557      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.481   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1557     |\n",
      "|    time_elapsed    | 2421     |\n",
      "|    total_timesteps | 3188736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.299       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1558        |\n",
      "|    time_elapsed         | 2422        |\n",
      "|    total_timesteps      | 3190784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011868125 |\n",
      "|    clip_fraction        | 0.0856      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0882      |\n",
      "|    n_updates            | 20460       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 0.557       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.597       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1559         |\n",
      "|    time_elapsed         | 2424         |\n",
      "|    total_timesteps      | 3192832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077224914 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.38        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.198        |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00857     |\n",
      "|    std                  | 5.96         |\n",
      "|    value_loss           | 0.591        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.881      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 2425        |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010859377 |\n",
      "|    clip_fraction        | 0.0806      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0763      |\n",
      "|    n_updates            | 20480       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 0.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.212      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1561        |\n",
      "|    time_elapsed         | 2427        |\n",
      "|    total_timesteps      | 3196928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007615191 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.38       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 20490       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 0.524       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3198528, episode_reward=-1.96 +/- 4.76\n",
      "Episode length: 31.50 +/- 8.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.5         |\n",
      "|    mean_reward          | -1.96        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3198528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059685498 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.4         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.212        |\n",
      "|    n_updates            | 20500        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 0.738        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.348   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1562     |\n",
      "|    time_elapsed    | 2429     |\n",
      "|    total_timesteps | 3198976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.686      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1563        |\n",
      "|    time_elapsed         | 2430        |\n",
      "|    total_timesteps      | 3201024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011921823 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.013       |\n",
      "|    n_updates            | 20510       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 5.95        |\n",
      "|    value_loss           | 0.303       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.592      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 2432        |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006345857 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 20520       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 5.94        |\n",
      "|    value_loss           | 0.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.238       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1565        |\n",
      "|    time_elapsed         | 2434        |\n",
      "|    total_timesteps      | 3205120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008569634 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.221       |\n",
      "|    n_updates            | 20530       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 0.709       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1566        |\n",
      "|    time_elapsed         | 2435        |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007671957 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 20540       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 6           |\n",
      "|    value_loss           | 0.565       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3208528, episode_reward=1.43 +/- 4.32\n",
      "Episode length: 26.80 +/- 8.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.8        |\n",
      "|    mean_reward          | 1.43        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3208528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011959719 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.346       |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 6.02        |\n",
      "|    value_loss           | 0.849       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.0562   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1567     |\n",
      "|    time_elapsed    | 2437     |\n",
      "|    total_timesteps | 3209216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.211       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1568        |\n",
      "|    time_elapsed         | 2439        |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007623709 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.42       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 20560       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.378      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1569        |\n",
      "|    time_elapsed         | 2440        |\n",
      "|    total_timesteps      | 3213312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007933384 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.41       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00965    |\n",
      "|    n_updates            | 20570       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.914      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1570        |\n",
      "|    time_elapsed         | 2442        |\n",
      "|    total_timesteps      | 3215360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008156194 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.41       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0931      |\n",
      "|    n_updates            | 20580       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.7       |\n",
      "|    ep_rew_mean          | -0.259     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1571       |\n",
      "|    time_elapsed         | 2444       |\n",
      "|    total_timesteps      | 3217408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00953769 |\n",
      "|    clip_fraction        | 0.0608     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.4       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.119      |\n",
      "|    n_updates            | 20590      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 6.06       |\n",
      "|    value_loss           | 0.412      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3218528, episode_reward=1.69 +/- 4.53\n",
      "Episode length: 28.10 +/- 6.59\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 28.1       |\n",
      "|    mean_reward          | 1.69       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3218528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01532734 |\n",
      "|    clip_fraction        | 0.073      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.42      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0162     |\n",
      "|    n_updates            | 20600      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 6.08       |\n",
      "|    value_loss           | 0.263      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.548   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1572     |\n",
      "|    time_elapsed    | 2445     |\n",
      "|    total_timesteps | 3219456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.655      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1573        |\n",
      "|    time_elapsed         | 2447        |\n",
      "|    total_timesteps      | 3221504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012350728 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.43       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 20610       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 6.1         |\n",
      "|    value_loss           | 0.489       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.922       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1574         |\n",
      "|    time_elapsed         | 2448         |\n",
      "|    total_timesteps      | 3223552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061511397 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.44        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.167        |\n",
      "|    n_updates            | 20620        |\n",
      "|    policy_gradient_loss | -0.00975     |\n",
      "|    std                  | 6.12         |\n",
      "|    value_loss           | 0.848        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.764      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1575        |\n",
      "|    time_elapsed         | 2450        |\n",
      "|    total_timesteps      | 3225600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008909115 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 20630       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 6.13        |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.5       |\n",
      "|    ep_rew_mean          | -0.0574    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1576       |\n",
      "|    time_elapsed         | 2451       |\n",
      "|    total_timesteps      | 3227648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00665404 |\n",
      "|    clip_fraction        | 0.0645     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.45      |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.327      |\n",
      "|    n_updates            | 20640      |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    std                  | 6.17       |\n",
      "|    value_loss           | 1.2        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3228528, episode_reward=-0.58 +/- 5.72\n",
      "Episode length: 29.20 +/- 9.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.2         |\n",
      "|    mean_reward          | -0.58        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3228528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063656275 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.44        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0248       |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.0085      |\n",
      "|    std                  | 6.04         |\n",
      "|    value_loss           | 0.264        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.634   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1577     |\n",
      "|    time_elapsed    | 2453     |\n",
      "|    total_timesteps | 3229696  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.7         |\n",
      "|    ep_rew_mean          | -0.313       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1578         |\n",
      "|    time_elapsed         | 2455         |\n",
      "|    total_timesteps      | 3231744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077950275 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.42        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.531        |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.01        |\n",
      "|    std                  | 6.12         |\n",
      "|    value_loss           | 1.27         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | 0.0684       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 2457         |\n",
      "|    total_timesteps      | 3233792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075345524 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.43        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.065        |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 6.01         |\n",
      "|    value_loss           | 0.355        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.804      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1580        |\n",
      "|    time_elapsed         | 2458        |\n",
      "|    total_timesteps      | 3235840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008697428 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 20680       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 0.431       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.0723     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1581        |\n",
      "|    time_elapsed         | 2460        |\n",
      "|    total_timesteps      | 3237888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007819922 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0564      |\n",
      "|    n_updates            | 20690       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 0.332       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3238528, episode_reward=-2.07 +/- 5.30\n",
      "Episode length: 34.70 +/- 5.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 34.7         |\n",
      "|    mean_reward          | -2.07        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3238528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062922537 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.38        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 5.95         |\n",
      "|    value_loss           | 0.686        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | -0.0682  |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1582     |\n",
      "|    time_elapsed    | 2461     |\n",
      "|    total_timesteps | 3239936  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.0518      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1583         |\n",
      "|    time_elapsed         | 2463         |\n",
      "|    total_timesteps      | 3241984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054884558 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.38        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.053        |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00916     |\n",
      "|    std                  | 5.94         |\n",
      "|    value_loss           | 0.475        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1584        |\n",
      "|    time_elapsed         | 2464        |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008220795 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0315      |\n",
      "|    n_updates            | 20720       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 5.87        |\n",
      "|    value_loss           | 0.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 2466        |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006193448 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 20730       |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 0.416       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.4         |\n",
      "|    ep_rew_mean          | -1.59        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1586         |\n",
      "|    time_elapsed         | 2467         |\n",
      "|    total_timesteps      | 3248128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058997613 |\n",
      "|    clip_fraction        | 0.0528       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.4         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.115        |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 0.614        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3248528, episode_reward=-2.37 +/- 4.08\n",
      "Episode length: 34.40 +/- 5.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 34.4         |\n",
      "|    mean_reward          | -2.37        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3248528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072183264 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.4         |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.255        |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 5.96         |\n",
      "|    value_loss           | 0.746        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -1.16    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1587     |\n",
      "|    time_elapsed    | 2469     |\n",
      "|    total_timesteps | 3250176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.0653      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 2471        |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008159081 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.38       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.235       |\n",
      "|    n_updates            | 20760       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    std                  | 5.9         |\n",
      "|    value_loss           | 0.561       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.393      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1589        |\n",
      "|    time_elapsed         | 2472        |\n",
      "|    total_timesteps      | 3254272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008658578 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.37       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0659     |\n",
      "|    n_updates            | 20770       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 0.0773      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1590        |\n",
      "|    time_elapsed         | 2474        |\n",
      "|    total_timesteps      | 3256320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009137062 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 20780       |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.2       |\n",
      "|    ep_rew_mean          | -0.715     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1591       |\n",
      "|    time_elapsed         | 2475       |\n",
      "|    total_timesteps      | 3258368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01063902 |\n",
      "|    clip_fraction        | 0.0917     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.41      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0795    |\n",
      "|    n_updates            | 20790      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    std                  | 5.99       |\n",
      "|    value_loss           | 0.0324     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3258528, episode_reward=1.42 +/- 3.89\n",
      "Episode length: 27.70 +/- 6.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.7        |\n",
      "|    mean_reward          | 1.42        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3258528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008921315 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.254       |\n",
      "|    n_updates            | 20800       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 6.01        |\n",
      "|    value_loss           | 0.914       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | -0.677   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1592     |\n",
      "|    time_elapsed    | 2477     |\n",
      "|    total_timesteps | 3260416  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.761       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 2478         |\n",
      "|    total_timesteps      | 3262464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063836463 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.42        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.191        |\n",
      "|    n_updates            | 20810        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 6.04         |\n",
      "|    value_loss           | 0.67         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.0275      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 2480        |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010343456 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.41       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0619     |\n",
      "|    n_updates            | 20820       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 5.99        |\n",
      "|    value_loss           | 0.0991      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31         |\n",
      "|    ep_rew_mean          | -0.0148    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1595       |\n",
      "|    time_elapsed         | 2481       |\n",
      "|    total_timesteps      | 3266560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00922285 |\n",
      "|    clip_fraction        | 0.0828     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.41      |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0962     |\n",
      "|    n_updates            | 20830      |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 6          |\n",
      "|    value_loss           | 0.456      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3268528, episode_reward=-0.93 +/- 4.76\n",
      "Episode length: 31.10 +/- 7.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.1         |\n",
      "|    mean_reward          | -0.933       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3268528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083750645 |\n",
      "|    clip_fraction        | 0.0803       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.41        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.127        |\n",
      "|    n_updates            | 20840        |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    std                  | 5.96         |\n",
      "|    value_loss           | 0.624        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.427   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1596     |\n",
      "|    time_elapsed    | 2483     |\n",
      "|    total_timesteps | 3268608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.63       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 2484        |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013320963 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 20850       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 5.97        |\n",
      "|    value_loss           | 0.699       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.192       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1598         |\n",
      "|    time_elapsed         | 2486         |\n",
      "|    total_timesteps      | 3272704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069432873 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.41        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0857       |\n",
      "|    n_updates            | 20860        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 0.344        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0847      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1599        |\n",
      "|    time_elapsed         | 2487        |\n",
      "|    total_timesteps      | 3274752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008689802 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.41       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 20870       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 6.03        |\n",
      "|    value_loss           | 0.724       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.561      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1600        |\n",
      "|    time_elapsed         | 2489        |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010046486 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0739     |\n",
      "|    n_updates            | 20880       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 0.0477      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3278528, episode_reward=-2.10 +/- 5.49\n",
      "Episode length: 33.40 +/- 7.35\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 33.4       |\n",
      "|    mean_reward          | -2.1       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3278528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00856703 |\n",
      "|    clip_fraction        | 0.0684     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.37      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0996     |\n",
      "|    n_updates            | 20890      |\n",
      "|    policy_gradient_loss | -0.00989   |\n",
      "|    std                  | 5.9        |\n",
      "|    value_loss           | 0.394      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.252   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1601     |\n",
      "|    time_elapsed    | 2491     |\n",
      "|    total_timesteps | 3278848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.486      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1602        |\n",
      "|    time_elapsed         | 2492        |\n",
      "|    total_timesteps      | 3280896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008603875 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.38       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0824      |\n",
      "|    n_updates            | 20900       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 5.92        |\n",
      "|    value_loss           | 0.376       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.0378     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1603        |\n",
      "|    time_elapsed         | 2494        |\n",
      "|    total_timesteps      | 3282944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015048879 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.38       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.023       |\n",
      "|    n_updates            | 20910       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 5.91        |\n",
      "|    value_loss           | 0.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.119       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 2495        |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010067142 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.36       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0432      |\n",
      "|    n_updates            | 20920       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 0.239       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.226      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1605        |\n",
      "|    time_elapsed         | 2497        |\n",
      "|    total_timesteps      | 3287040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007517662 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    std                  | 5.81        |\n",
      "|    value_loss           | 0.531       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3288528, episode_reward=-1.95 +/- 4.69\n",
      "Episode length: 33.30 +/- 6.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.3        |\n",
      "|    mean_reward          | -1.95       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3288528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010683601 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.33       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 20940       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.2     |\n",
      "|    ep_rew_mean     | 0.64     |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1606     |\n",
      "|    time_elapsed    | 2498     |\n",
      "|    total_timesteps | 3289088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | 0.926       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1607        |\n",
      "|    time_elapsed         | 2500        |\n",
      "|    total_timesteps      | 3291136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013153338 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 20950       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    std                  | 5.84        |\n",
      "|    value_loss           | 0.415       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.141      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1608        |\n",
      "|    time_elapsed         | 2501        |\n",
      "|    total_timesteps      | 3293184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013626537 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.35       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.191       |\n",
      "|    n_updates            | 20960       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 5.84        |\n",
      "|    value_loss           | 0.584       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.739      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1609        |\n",
      "|    time_elapsed         | 2503        |\n",
      "|    total_timesteps      | 3295232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008765629 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0918      |\n",
      "|    n_updates            | 20970       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 0.448       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1610        |\n",
      "|    time_elapsed         | 2504        |\n",
      "|    total_timesteps      | 3297280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008026224 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.33       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0596     |\n",
      "|    n_updates            | 20980       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 5.79        |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3298528, episode_reward=-2.66 +/- 3.45\n",
      "Episode length: 33.70 +/- 5.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.7        |\n",
      "|    mean_reward          | -2.66       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3298528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008300215 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.34       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 20990       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 5.86        |\n",
      "|    value_loss           | 0.803       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.948   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1611     |\n",
      "|    time_elapsed    | 2506     |\n",
      "|    total_timesteps | 3299328  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.73        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1612         |\n",
      "|    time_elapsed         | 2507         |\n",
      "|    total_timesteps      | 3301376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066504343 |\n",
      "|    clip_fraction        | 0.0591       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.35        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.597        |\n",
      "|    n_updates            | 21000        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 5.84         |\n",
      "|    value_loss           | 1.15         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.0673      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1613        |\n",
      "|    time_elapsed         | 2509        |\n",
      "|    total_timesteps      | 3303424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006367526 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.35       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 21010       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    std                  | 5.84        |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.929      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 2510        |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013255952 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.36       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.000988   |\n",
      "|    n_updates            | 21020       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 5.89        |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.437       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1615         |\n",
      "|    time_elapsed         | 2512         |\n",
      "|    total_timesteps      | 3307520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068555465 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.37        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0952       |\n",
      "|    n_updates            | 21030        |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    std                  | 5.94         |\n",
      "|    value_loss           | 0.451        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3308528, episode_reward=-2.35 +/- 4.91\n",
      "Episode length: 32.20 +/- 7.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.2        |\n",
      "|    mean_reward          | -2.35       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3308528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009804874 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0556      |\n",
      "|    n_updates            | 21040       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 5.96        |\n",
      "|    value_loss           | 0.447       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.1     |\n",
      "|    ep_rew_mean     | 0.368    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1616     |\n",
      "|    time_elapsed    | 2513     |\n",
      "|    total_timesteps | 3309568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1617        |\n",
      "|    time_elapsed         | 2515        |\n",
      "|    total_timesteps      | 3311616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010646617 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0196      |\n",
      "|    n_updates            | 21050       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 5.98        |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.269       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1618         |\n",
      "|    time_elapsed         | 2516         |\n",
      "|    total_timesteps      | 3313664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073998235 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.39        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0034       |\n",
      "|    n_updates            | 21060        |\n",
      "|    policy_gradient_loss | -0.00786     |\n",
      "|    std                  | 5.99         |\n",
      "|    value_loss           | 0.248        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -0.882      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1619        |\n",
      "|    time_elapsed         | 2518        |\n",
      "|    total_timesteps      | 3315712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008924734 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.41       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.521       |\n",
      "|    n_updates            | 21070       |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.609       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 2519         |\n",
      "|    total_timesteps      | 3317760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075210948 |\n",
      "|    clip_fraction        | 0.0825       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.44        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.3          |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 6.16         |\n",
      "|    value_loss           | 0.881        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3318528, episode_reward=-3.39 +/- 4.74\n",
      "Episode length: 34.80 +/- 5.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.8        |\n",
      "|    mean_reward          | -3.39       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3318528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008788556 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.45       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 21090       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 0.493       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.626   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1621     |\n",
      "|    time_elapsed    | 2521     |\n",
      "|    total_timesteps | 3319808  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1622        |\n",
      "|    time_elapsed         | 2522        |\n",
      "|    total_timesteps      | 3321856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008719576 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 6.15        |\n",
      "|    value_loss           | 0.975       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.351       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1623        |\n",
      "|    time_elapsed         | 2524        |\n",
      "|    total_timesteps      | 3323904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007426561 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.45       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0366     |\n",
      "|    n_updates            | 21110       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.745      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1624        |\n",
      "|    time_elapsed         | 2525        |\n",
      "|    total_timesteps      | 3325952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010896331 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0458      |\n",
      "|    n_updates            | 21120       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 6.17        |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.777      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 2527        |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006007266 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.45       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0892      |\n",
      "|    n_updates            | 21130       |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    std                  | 6.12        |\n",
      "|    value_loss           | 0.45        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3328528, episode_reward=-1.54 +/- 4.26\n",
      "Episode length: 31.40 +/- 7.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.4        |\n",
      "|    mean_reward          | -1.54       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3328528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009457119 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0771      |\n",
      "|    n_updates            | 21140       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 0.542       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.284   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1626     |\n",
      "|    time_elapsed    | 2529     |\n",
      "|    total_timesteps | 3330048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.184      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1627        |\n",
      "|    time_elapsed         | 2530        |\n",
      "|    total_timesteps      | 3332096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007143097 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 21150       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 0.628       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.7         |\n",
      "|    ep_rew_mean          | 0.281        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1628         |\n",
      "|    time_elapsed         | 2532         |\n",
      "|    total_timesteps      | 3334144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077222483 |\n",
      "|    clip_fraction        | 0.0624       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.44        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0211       |\n",
      "|    n_updates            | 21160        |\n",
      "|    policy_gradient_loss | -0.0095      |\n",
      "|    std                  | 6.11         |\n",
      "|    value_loss           | 0.294        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.557       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1629        |\n",
      "|    time_elapsed         | 2533        |\n",
      "|    total_timesteps      | 3336192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008655965 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.43       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0419      |\n",
      "|    n_updates            | 21170       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 6.06        |\n",
      "|    value_loss           | 0.357       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.189       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1630        |\n",
      "|    time_elapsed         | 2535        |\n",
      "|    total_timesteps      | 3338240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008373489 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.43       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0825      |\n",
      "|    n_updates            | 21180       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 6.11        |\n",
      "|    value_loss           | 0.367       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3338528, episode_reward=0.00 +/- 5.04\n",
      "Episode length: 29.70 +/- 8.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.7         |\n",
      "|    mean_reward          | 0.00123      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3338528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102468915 |\n",
      "|    clip_fraction        | 0.08         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.43        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0228      |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 6.11         |\n",
      "|    value_loss           | 0.143        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.0549  |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1631     |\n",
      "|    time_elapsed    | 2536     |\n",
      "|    total_timesteps | 3340288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.28       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 2538        |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008247094 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.43       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 21200       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 6.14        |\n",
      "|    value_loss           | 0.465       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.598       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1633         |\n",
      "|    time_elapsed         | 2539         |\n",
      "|    total_timesteps      | 3344384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076881177 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.45        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.465        |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00918     |\n",
      "|    std                  | 6.2          |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.1         |\n",
      "|    ep_rew_mean          | -0.979       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1634         |\n",
      "|    time_elapsed         | 2541         |\n",
      "|    total_timesteps      | 3346432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075928103 |\n",
      "|    clip_fraction        | 0.0679       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.47        |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.217        |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 0.767        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.898      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 2542        |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007725425 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.48       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.444       |\n",
      "|    n_updates            | 21230       |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3348528, episode_reward=2.00 +/- 5.08\n",
      "Episode length: 26.40 +/- 8.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.4         |\n",
      "|    mean_reward          | 2            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3348528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047565573 |\n",
      "|    clip_fraction        | 0.0522       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.47        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.177        |\n",
      "|    n_updates            | 21240        |\n",
      "|    policy_gradient_loss | -0.00973     |\n",
      "|    std                  | 6.2          |\n",
      "|    value_loss           | 0.874        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.58    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1636     |\n",
      "|    time_elapsed    | 2544     |\n",
      "|    total_timesteps | 3350528  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | -0.376       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 2545         |\n",
      "|    total_timesteps      | 3352576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061382796 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.46        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0262       |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00876     |\n",
      "|    std                  | 6.27         |\n",
      "|    value_loss           | 0.305        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.0119      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 2547        |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011346885 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.48       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0714     |\n",
      "|    n_updates            | 21260       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 6.23        |\n",
      "|    value_loss           | 0.0624      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.615      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1639        |\n",
      "|    time_elapsed         | 2548        |\n",
      "|    total_timesteps      | 3356672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009389881 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.46       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0225     |\n",
      "|    n_updates            | 21270       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 6.22        |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3358528, episode_reward=-4.76 +/- 4.91\n",
      "Episode length: 36.70 +/- 6.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 36.7        |\n",
      "|    mean_reward          | -4.76       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3358528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008529124 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.46       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 21280       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 0.472       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | 0.026    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1640     |\n",
      "|    time_elapsed    | 2550     |\n",
      "|    total_timesteps | 3358720  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.324      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1641        |\n",
      "|    time_elapsed         | 2551        |\n",
      "|    total_timesteps      | 3360768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007252073 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.47       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.368       |\n",
      "|    n_updates            | 21290       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    std                  | 6.27        |\n",
      "|    value_loss           | 0.653       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.8       |\n",
      "|    ep_rew_mean          | -0.854     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1642       |\n",
      "|    time_elapsed         | 2553       |\n",
      "|    total_timesteps      | 3362816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01038624 |\n",
      "|    clip_fraction        | 0.0737     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.47      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.133      |\n",
      "|    n_updates            | 21300      |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 6.27       |\n",
      "|    value_loss           | 0.392      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.0139     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1643        |\n",
      "|    time_elapsed         | 2554        |\n",
      "|    total_timesteps      | 3364864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008797353 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.48       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 21310       |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    std                  | 6.34        |\n",
      "|    value_loss           | 0.349       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.286        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1644         |\n",
      "|    time_elapsed         | 2556         |\n",
      "|    total_timesteps      | 3366912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074443533 |\n",
      "|    clip_fraction        | 0.0674       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.5         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.123        |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    std                  | 6.4          |\n",
      "|    value_loss           | 0.486        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3368528, episode_reward=0.94 +/- 5.79\n",
      "Episode length: 26.20 +/- 10.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.2         |\n",
      "|    mean_reward          | 0.936        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3368528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068692025 |\n",
      "|    clip_fraction        | 0.0797       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.53        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.113        |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 6.48         |\n",
      "|    value_loss           | 0.418        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.766   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1645     |\n",
      "|    time_elapsed    | 2557     |\n",
      "|    total_timesteps | 3368960  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.1         |\n",
      "|    ep_rew_mean          | -1.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1646         |\n",
      "|    time_elapsed         | 2559         |\n",
      "|    total_timesteps      | 3371008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075836834 |\n",
      "|    clip_fraction        | 0.0645       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.54        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.924        |\n",
      "|    n_updates            | 21340        |\n",
      "|    policy_gradient_loss | -0.00967     |\n",
      "|    std                  | 6.55         |\n",
      "|    value_loss           | 1.76         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -1.22        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1647         |\n",
      "|    time_elapsed         | 2560         |\n",
      "|    total_timesteps      | 3373056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061779986 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.56        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.106        |\n",
      "|    n_updates            | 21350        |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    std                  | 6.56         |\n",
      "|    value_loss           | 0.387        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1648        |\n",
      "|    time_elapsed         | 2562        |\n",
      "|    total_timesteps      | 3375104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008597473 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.56       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.26        |\n",
      "|    n_updates            | 21360       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 6.57        |\n",
      "|    value_loss           | 0.939       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | -1.39      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1317       |\n",
      "|    iterations           | 1649       |\n",
      "|    time_elapsed         | 2563       |\n",
      "|    total_timesteps      | 3377152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00851751 |\n",
      "|    clip_fraction        | 0.0613     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.57      |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.117      |\n",
      "|    n_updates            | 21370      |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    std                  | 6.59       |\n",
      "|    value_loss           | 0.781      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3378528, episode_reward=-1.00 +/- 4.42\n",
      "Episode length: 30.10 +/- 7.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | -1          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3378528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008928066 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.56       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0721     |\n",
      "|    n_updates            | 21380       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 6.52        |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.569   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1650     |\n",
      "|    time_elapsed    | 2565     |\n",
      "|    total_timesteps | 3379200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.687      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1651        |\n",
      "|    time_elapsed         | 2567        |\n",
      "|    total_timesteps      | 3381248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007343309 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.53       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 21390       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 6.5         |\n",
      "|    value_loss           | 0.633       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1652        |\n",
      "|    time_elapsed         | 2568        |\n",
      "|    total_timesteps      | 3383296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006272325 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.53       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 21400       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 6.51        |\n",
      "|    value_loss           | 0.897       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.429      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1653        |\n",
      "|    time_elapsed         | 2570        |\n",
      "|    total_timesteps      | 3385344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007445814 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.53       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 21410       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 6.51        |\n",
      "|    value_loss           | 0.871       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.521       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 1654         |\n",
      "|    time_elapsed         | 2571         |\n",
      "|    total_timesteps      | 3387392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058540907 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.52        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.195        |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 6.47         |\n",
      "|    value_loss           | 0.741        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3388528, episode_reward=-1.40 +/- 5.93\n",
      "Episode length: 32.10 +/- 8.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.1        |\n",
      "|    mean_reward          | -1.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3388528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008118744 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.51       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 21430       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 6.49        |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.358   |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1655     |\n",
      "|    time_elapsed    | 2573     |\n",
      "|    total_timesteps | 3389440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.249      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 2575        |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005731518 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.53       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.438       |\n",
      "|    n_updates            | 21440       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    std                  | 6.62        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.313      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1657        |\n",
      "|    time_elapsed         | 2576        |\n",
      "|    total_timesteps      | 3393536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009518091 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.56       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 21450       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 6.65        |\n",
      "|    value_loss           | 0.484       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | -0.192       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1658         |\n",
      "|    time_elapsed         | 2578         |\n",
      "|    total_timesteps      | 3395584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083560925 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.56        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.109        |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 6.63         |\n",
      "|    value_loss           | 0.371        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.607       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1659         |\n",
      "|    time_elapsed         | 2579         |\n",
      "|    total_timesteps      | 3397632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095529035 |\n",
      "|    clip_fraction        | 0.0666       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.55        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.017       |\n",
      "|    n_updates            | 21470        |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    std                  | 6.57         |\n",
      "|    value_loss           | 0.154        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3398528, episode_reward=-0.71 +/- 6.01\n",
      "Episode length: 31.50 +/- 7.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.5        |\n",
      "|    mean_reward          | -0.71       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3398528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010679539 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.55       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0543     |\n",
      "|    n_updates            | 21480       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 6.69        |\n",
      "|    value_loss           | 0.0782      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.802   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1660     |\n",
      "|    time_elapsed    | 2581     |\n",
      "|    total_timesteps | 3399680  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.6       |\n",
      "|    ep_rew_mean          | -0.499     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1661       |\n",
      "|    time_elapsed         | 2583       |\n",
      "|    total_timesteps      | 3401728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00816272 |\n",
      "|    clip_fraction        | 0.0788     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.59      |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.28       |\n",
      "|    n_updates            | 21490      |\n",
      "|    policy_gradient_loss | -0.00985   |\n",
      "|    std                  | 6.81       |\n",
      "|    value_loss           | 0.887      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33         |\n",
      "|    ep_rew_mean          | -1.12      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1662       |\n",
      "|    time_elapsed         | 2584       |\n",
      "|    total_timesteps      | 3403776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00837926 |\n",
      "|    clip_fraction        | 0.0848     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.62      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.167      |\n",
      "|    n_updates            | 21500      |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 6.86       |\n",
      "|    value_loss           | 0.412      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.295      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1663        |\n",
      "|    time_elapsed         | 2586        |\n",
      "|    total_timesteps      | 3405824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007721855 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 21510       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 6.92        |\n",
      "|    value_loss           | 0.617       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | -0.445       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1664         |\n",
      "|    time_elapsed         | 2588         |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064242836 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.66        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.23         |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    std                  | 6.93         |\n",
      "|    value_loss           | 0.549        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3408528, episode_reward=0.16 +/- 5.04\n",
      "Episode length: 29.30 +/- 8.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.3       |\n",
      "|    mean_reward          | 0.163      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3408528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00681647 |\n",
      "|    clip_fraction        | 0.0574     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.66      |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.284      |\n",
      "|    n_updates            | 21530      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 6.91       |\n",
      "|    value_loss           | 0.812      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.505   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1665     |\n",
      "|    time_elapsed    | 2589     |\n",
      "|    total_timesteps | 3409920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1666        |\n",
      "|    time_elapsed         | 2591        |\n",
      "|    total_timesteps      | 3411968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006906721 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.508       |\n",
      "|    n_updates            | 21540       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 6.96        |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.267      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1667        |\n",
      "|    time_elapsed         | 2592        |\n",
      "|    total_timesteps      | 3414016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008534263 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.67       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 21550       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 0.682       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | 0.0119       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1668         |\n",
      "|    time_elapsed         | 2594         |\n",
      "|    total_timesteps      | 3416064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055835177 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.67        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.244        |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00932     |\n",
      "|    std                  | 6.99         |\n",
      "|    value_loss           | 0.727        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.603      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 2595        |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006850646 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.69       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.326       |\n",
      "|    n_updates            | 21570       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 7.05        |\n",
      "|    value_loss           | 0.901       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3418528, episode_reward=0.01 +/- 4.10\n",
      "Episode length: 30.20 +/- 5.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.2        |\n",
      "|    mean_reward          | 0.00857     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3418528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006031006 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.69       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 0.737       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.0446  |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1670     |\n",
      "|    time_elapsed    | 2597     |\n",
      "|    total_timesteps | 3420160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.278      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1671        |\n",
      "|    time_elapsed         | 2598        |\n",
      "|    total_timesteps      | 3422208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009678226 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.69       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.000761    |\n",
      "|    n_updates            | 21590       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.323      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1672        |\n",
      "|    time_elapsed         | 2600        |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011194128 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.68       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 21600       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 0.603       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.258      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1673        |\n",
      "|    time_elapsed         | 2601        |\n",
      "|    total_timesteps      | 3426304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012324703 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.68       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 21610       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 0.559       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.541       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1674         |\n",
      "|    time_elapsed         | 2603         |\n",
      "|    total_timesteps      | 3428352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069360835 |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.69        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.164        |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    std                  | 7.09         |\n",
      "|    value_loss           | 0.449        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3428528, episode_reward=0.86 +/- 4.65\n",
      "Episode length: 29.30 +/- 7.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.3        |\n",
      "|    mean_reward          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3428528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008823622 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.69       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 21630       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 6.95        |\n",
      "|    value_loss           | 0.472       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | 0.0417   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1675     |\n",
      "|    time_elapsed    | 2604     |\n",
      "|    total_timesteps | 3430400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.763      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1676        |\n",
      "|    time_elapsed         | 2606        |\n",
      "|    total_timesteps      | 3432448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008065893 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.257       |\n",
      "|    n_updates            | 21640       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 6.9         |\n",
      "|    value_loss           | 0.836       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.652      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1677        |\n",
      "|    time_elapsed         | 2607        |\n",
      "|    total_timesteps      | 3434496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008938901 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.65       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.207       |\n",
      "|    n_updates            | 21650       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 6.9         |\n",
      "|    value_loss           | 0.625       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.0691     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1678        |\n",
      "|    time_elapsed         | 2609        |\n",
      "|    total_timesteps      | 3436544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007716854 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0827      |\n",
      "|    n_updates            | 21660       |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    std                  | 6.94        |\n",
      "|    value_loss           | 0.4         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3438528, episode_reward=1.29 +/- 4.03\n",
      "Episode length: 28.50 +/- 5.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.5        |\n",
      "|    mean_reward          | 1.29        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3438528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009175571 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.67       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 21670       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 6.98        |\n",
      "|    value_loss           | 0.595       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.0664  |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1679     |\n",
      "|    time_elapsed    | 2610     |\n",
      "|    total_timesteps | 3438592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.114      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1680        |\n",
      "|    time_elapsed         | 2612        |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008392436 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.575       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 2613        |\n",
      "|    total_timesteps      | 3442688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008414084 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.000824   |\n",
      "|    n_updates            | 21690       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 6.86        |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.169       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 2615        |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013028757 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 21700       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 0.422       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.839      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1317        |\n",
      "|    iterations           | 1683        |\n",
      "|    time_elapsed         | 2616        |\n",
      "|    total_timesteps      | 3446784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010259426 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00386     |\n",
      "|    n_updates            | 21710       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 0.257       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3448528, episode_reward=-1.56 +/- 6.15\n",
      "Episode length: 31.60 +/- 7.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.6        |\n",
      "|    mean_reward          | -1.56       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3448528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005979159 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 21720       |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 0.544       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -1.31    |\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 1684     |\n",
      "|    time_elapsed    | 2618     |\n",
      "|    total_timesteps | 3448832  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.642       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1685         |\n",
      "|    time_elapsed         | 2620         |\n",
      "|    total_timesteps      | 3450880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052118376 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.65        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.58         |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 6.98         |\n",
      "|    value_loss           | 1.44         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.249       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1686        |\n",
      "|    time_elapsed         | 2622        |\n",
      "|    total_timesteps      | 3452928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006559671 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.67       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 21740       |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.9       |\n",
      "|    ep_rew_mean          | 0.165      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1687       |\n",
      "|    time_elapsed         | 2623       |\n",
      "|    total_timesteps      | 3454976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00903561 |\n",
      "|    clip_fraction        | 0.0709     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.67      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.052     |\n",
      "|    n_updates            | 21750      |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    std                  | 7.04       |\n",
      "|    value_loss           | 0.124      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.112       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1688        |\n",
      "|    time_elapsed         | 2626        |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008481998 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.064       |\n",
      "|    n_updates            | 21760       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 7.01        |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3458528, episode_reward=-2.91 +/- 7.01\n",
      "Episode length: 35.80 +/- 14.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.8        |\n",
      "|    mean_reward          | -2.91       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3458528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009672917 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.65       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 21770       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 7.06        |\n",
      "|    value_loss           | 0.529       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.0796  |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1689     |\n",
      "|    time_elapsed    | 2628     |\n",
      "|    total_timesteps | 3459072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | 0.0607      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1690        |\n",
      "|    time_elapsed         | 2629        |\n",
      "|    total_timesteps      | 3461120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007645686 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.239       |\n",
      "|    n_updates            | 21780       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 7.07        |\n",
      "|    value_loss           | 0.716       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.155      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1691        |\n",
      "|    time_elapsed         | 2631        |\n",
      "|    total_timesteps      | 3463168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007150659 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 21790       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 7.06        |\n",
      "|    value_loss           | 0.417       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.498      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1692        |\n",
      "|    time_elapsed         | 2633        |\n",
      "|    total_timesteps      | 3465216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004875356 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.221       |\n",
      "|    n_updates            | 21800       |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 0.849       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1693        |\n",
      "|    time_elapsed         | 2634        |\n",
      "|    total_timesteps      | 3467264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007371376 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0487      |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    std                  | 7.04        |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3468528, episode_reward=1.99 +/- 6.02\n",
      "Episode length: 25.50 +/- 9.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25.5         |\n",
      "|    mean_reward          | 1.99         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3468528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094985925 |\n",
      "|    clip_fraction        | 0.0827       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.66        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0162       |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 7.02         |\n",
      "|    value_loss           | 0.293        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -0.531   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1694     |\n",
      "|    time_elapsed    | 2636     |\n",
      "|    total_timesteps | 3469312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.0714     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1695        |\n",
      "|    time_elapsed         | 2638        |\n",
      "|    total_timesteps      | 3471360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010145735 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.66       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 21830       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 6.98        |\n",
      "|    value_loss           | 0.679       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.5       |\n",
      "|    ep_rew_mean          | 0.573      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1315       |\n",
      "|    iterations           | 1696       |\n",
      "|    time_elapsed         | 2640       |\n",
      "|    total_timesteps      | 3473408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00868883 |\n",
      "|    clip_fraction        | 0.063      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.64      |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0203    |\n",
      "|    n_updates            | 21840      |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 6.83       |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | 1.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1697        |\n",
      "|    time_elapsed         | 2642        |\n",
      "|    total_timesteps      | 3475456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008696826 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 0.3         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | 0.0259       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1698         |\n",
      "|    time_elapsed         | 2643         |\n",
      "|    total_timesteps      | 3477504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075518237 |\n",
      "|    clip_fraction        | 0.0758       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.64        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0601       |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 6.9          |\n",
      "|    value_loss           | 0.407        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3478528, episode_reward=-0.52 +/- 4.35\n",
      "Episode length: 29.50 +/- 7.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.5        |\n",
      "|    mean_reward          | -0.518      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3478528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010877664 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.34        |\n",
      "|    n_updates            | 21870       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 0.772       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.128   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1699     |\n",
      "|    time_elapsed    | 2645     |\n",
      "|    total_timesteps | 3479552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.442      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1700        |\n",
      "|    time_elapsed         | 2646        |\n",
      "|    total_timesteps      | 3481600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006704753 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.546       |\n",
      "|    n_updates            | 21880       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.409       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 2648         |\n",
      "|    total_timesteps      | 3483648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072119473 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.63        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.418        |\n",
      "|    n_updates            | 21890        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    std                  | 6.85         |\n",
      "|    value_loss           | 1            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1702        |\n",
      "|    time_elapsed         | 2649        |\n",
      "|    total_timesteps      | 3485696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007910641 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00966     |\n",
      "|    n_updates            | 21900       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 0.253       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.84       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 2651        |\n",
      "|    total_timesteps      | 3487744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007152785 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 21910       |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 0.486       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3488528, episode_reward=0.30 +/- 4.80\n",
      "Episode length: 29.60 +/- 6.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.6        |\n",
      "|    mean_reward          | 0.304       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3488528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012404716 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0967      |\n",
      "|    n_updates            | 21920       |\n",
      "|    policy_gradient_loss | -0.00964    |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.526   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1704     |\n",
      "|    time_elapsed    | 2652     |\n",
      "|    total_timesteps | 3489792  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.6         |\n",
      "|    ep_rew_mean          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1705         |\n",
      "|    time_elapsed         | 2654         |\n",
      "|    total_timesteps      | 3491840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074202637 |\n",
      "|    clip_fraction        | 0.0709       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.64        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.262        |\n",
      "|    n_updates            | 21930        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 6.88         |\n",
      "|    value_loss           | 0.621        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.349      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 2655        |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770692 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 21940       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 6.89        |\n",
      "|    value_loss           | 0.842       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -1.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1707         |\n",
      "|    time_elapsed         | 2657         |\n",
      "|    total_timesteps      | 3495936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055548707 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.64        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.14         |\n",
      "|    n_updates            | 21950        |\n",
      "|    policy_gradient_loss | -0.00914     |\n",
      "|    std                  | 6.82         |\n",
      "|    value_loss           | 0.538        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1708        |\n",
      "|    time_elapsed         | 2658        |\n",
      "|    total_timesteps      | 3497984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009137131 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 21960       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 0.587       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3498528, episode_reward=0.63 +/- 6.22\n",
      "Episode length: 27.10 +/- 10.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27.1         |\n",
      "|    mean_reward          | 0.634        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3498528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066370163 |\n",
      "|    clip_fraction        | 0.0745       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.64        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0222       |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    std                  | 6.88         |\n",
      "|    value_loss           | 0.414        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -1.08    |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1709     |\n",
      "|    time_elapsed    | 2659     |\n",
      "|    total_timesteps | 3500032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | -0.199      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1710        |\n",
      "|    time_elapsed         | 2661        |\n",
      "|    total_timesteps      | 3502080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006345203 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 21980       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    std                  | 6.82        |\n",
      "|    value_loss           | 0.678       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.174      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1711        |\n",
      "|    time_elapsed         | 2662        |\n",
      "|    total_timesteps      | 3504128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008547258 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0531     |\n",
      "|    n_updates            | 21990       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 6.8         |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.318       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1712         |\n",
      "|    time_elapsed         | 2664         |\n",
      "|    total_timesteps      | 3506176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075075775 |\n",
      "|    clip_fraction        | 0.085        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.61        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.362        |\n",
      "|    n_updates            | 22000        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 6.82         |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.691      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1713        |\n",
      "|    time_elapsed         | 2665        |\n",
      "|    total_timesteps      | 3508224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007090481 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.304       |\n",
      "|    n_updates            | 22010       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 0.854       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3508528, episode_reward=0.65 +/- 2.90\n",
      "Episode length: 28.60 +/- 5.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.6        |\n",
      "|    mean_reward          | 0.647       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3508528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010032962 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0157      |\n",
      "|    n_updates            | 22020       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 0.379       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32       |\n",
      "|    ep_rew_mean     | -0.675   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1714     |\n",
      "|    time_elapsed    | 2667     |\n",
      "|    total_timesteps | 3510272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.44       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1715        |\n",
      "|    time_elapsed         | 2668        |\n",
      "|    total_timesteps      | 3512320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009310082 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.6        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.318       |\n",
      "|    n_updates            | 22030       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 0.939       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.809      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1716        |\n",
      "|    time_elapsed         | 2670        |\n",
      "|    total_timesteps      | 3514368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007458076 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.6        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.066      |\n",
      "|    n_updates            | 22040       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.592      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1717        |\n",
      "|    time_elapsed         | 2671        |\n",
      "|    total_timesteps      | 3516416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009540593 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.58       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 22050       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 6.73        |\n",
      "|    value_loss           | 0.534       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.3         |\n",
      "|    ep_rew_mean          | 0.519        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1718         |\n",
      "|    time_elapsed         | 2673         |\n",
      "|    total_timesteps      | 3518464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069113364 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.58        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.153        |\n",
      "|    n_updates            | 22060        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 6.7          |\n",
      "|    value_loss           | 0.421        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3518528, episode_reward=2.65 +/- 3.97\n",
      "Episode length: 25.70 +/- 7.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25.7        |\n",
      "|    mean_reward          | 2.65        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3518528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008543488 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.58       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0907      |\n",
      "|    n_updates            | 22070       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 6.71        |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.1     |\n",
      "|    ep_rew_mean     | -0.0242  |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1719     |\n",
      "|    time_elapsed    | 2674     |\n",
      "|    total_timesteps | 3520512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.782      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 2676        |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308862 |\n",
      "|    clip_fraction        | 0.0632      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.59       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 22080       |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    std                  | 6.78        |\n",
      "|    value_loss           | 0.688       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.784      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 2677        |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711836 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.62       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 22090       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 6.91        |\n",
      "|    value_loss           | 0.637       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.102       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1722        |\n",
      "|    time_elapsed         | 2679        |\n",
      "|    total_timesteps      | 3526656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008810127 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 22100       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 6.88        |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3528528, episode_reward=-1.77 +/- 5.58\n",
      "Episode length: 32.80 +/- 7.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -1.77       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3528528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010595754 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00353    |\n",
      "|    n_updates            | 22110       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 6.87        |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.5     |\n",
      "|    ep_rew_mean     | 0.884    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1723     |\n",
      "|    time_elapsed    | 2681     |\n",
      "|    total_timesteps | 3528704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.555      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1724        |\n",
      "|    time_elapsed         | 2682        |\n",
      "|    total_timesteps      | 3530752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012305293 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0536     |\n",
      "|    n_updates            | 22120       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 6.81        |\n",
      "|    value_loss           | 0.0882      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 2684        |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007112006 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0836      |\n",
      "|    n_updates            | 22130       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 6.9         |\n",
      "|    value_loss           | 0.515       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.713      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 2685        |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013179436 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 22140       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 6.85        |\n",
      "|    value_loss           | 0.647       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -0.814       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1727         |\n",
      "|    time_elapsed         | 2687         |\n",
      "|    total_timesteps      | 3536896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076925075 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.63        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.162        |\n",
      "|    n_updates            | 22150        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 6.84         |\n",
      "|    value_loss           | 0.521        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3538528, episode_reward=-3.15 +/- 2.97\n",
      "Episode length: 34.50 +/- 3.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.5        |\n",
      "|    mean_reward          | -3.15       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3538528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011374421 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 0.552       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.453   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1728     |\n",
      "|    time_elapsed    | 2688     |\n",
      "|    total_timesteps | 3538944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.192       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1729        |\n",
      "|    time_elapsed         | 2690        |\n",
      "|    total_timesteps      | 3540992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007662783 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.67       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0118      |\n",
      "|    n_updates            | 22170       |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    std                  | 6.97        |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.4         |\n",
      "|    ep_rew_mean          | 0.158        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1730         |\n",
      "|    time_elapsed         | 2691         |\n",
      "|    total_timesteps      | 3543040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080734035 |\n",
      "|    clip_fraction        | 0.0721       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.67        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0387      |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    std                  | 6.99         |\n",
      "|    value_loss           | 0.135        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.882      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1731        |\n",
      "|    time_elapsed         | 2693        |\n",
      "|    total_timesteps      | 3545088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009129024 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.67       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 22190       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 7.02        |\n",
      "|    value_loss           | 0.632       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1732        |\n",
      "|    time_elapsed         | 2694        |\n",
      "|    total_timesteps      | 3547136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006862593 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.68       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 22200       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 7.03        |\n",
      "|    value_loss           | 0.67        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3548528, episode_reward=-2.22 +/- 5.90\n",
      "Episode length: 33.80 +/- 6.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 33.8         |\n",
      "|    mean_reward          | -2.22        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3548528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077693528 |\n",
      "|    clip_fraction        | 0.0766       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.69        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0191       |\n",
      "|    n_updates            | 22210        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 7.12         |\n",
      "|    value_loss           | 0.424        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.401   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1733     |\n",
      "|    time_elapsed    | 2696     |\n",
      "|    total_timesteps | 3549184  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.707      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1734        |\n",
      "|    time_elapsed         | 2697        |\n",
      "|    total_timesteps      | 3551232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009666014 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.71       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 22220       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 7.12        |\n",
      "|    value_loss           | 0.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.558      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1735        |\n",
      "|    time_elapsed         | 2699        |\n",
      "|    total_timesteps      | 3553280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012537069 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.72       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 22230       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 0.505       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.415      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1736        |\n",
      "|    time_elapsed         | 2700        |\n",
      "|    total_timesteps      | 3555328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009249698 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.74       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 22240       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 7.25        |\n",
      "|    value_loss           | 0.368       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.564      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1737        |\n",
      "|    time_elapsed         | 2702        |\n",
      "|    total_timesteps      | 3557376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009819535 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.74       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 22250       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 7.29        |\n",
      "|    value_loss           | 0.545       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3558528, episode_reward=-0.79 +/- 3.51\n",
      "Episode length: 31.40 +/- 5.08\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.4         |\n",
      "|    mean_reward          | -0.791       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3558528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057609333 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.76        |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.307        |\n",
      "|    n_updates            | 22260        |\n",
      "|    policy_gradient_loss | -0.00886     |\n",
      "|    std                  | 7.37         |\n",
      "|    value_loss           | 0.967        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.839   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1738     |\n",
      "|    time_elapsed    | 2703     |\n",
      "|    total_timesteps | 3559424  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.0412      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1739         |\n",
      "|    time_elapsed         | 2705         |\n",
      "|    total_timesteps      | 3561472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077474955 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.77        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 22270        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 7.37         |\n",
      "|    value_loss           | 0.418        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | -0.11        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1740         |\n",
      "|    time_elapsed         | 2706         |\n",
      "|    total_timesteps      | 3563520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057432614 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.77        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0698       |\n",
      "|    n_updates            | 22280        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 7.43         |\n",
      "|    value_loss           | 0.342        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.848      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 2708        |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007819072 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 22290       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 7.59        |\n",
      "|    value_loss           | 0.557       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.0126      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1742        |\n",
      "|    time_elapsed         | 2710        |\n",
      "|    total_timesteps      | 3567616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010350964 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0734      |\n",
      "|    n_updates            | 22300       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 7.71        |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3568528, episode_reward=-3.01 +/- 4.25\n",
      "Episode length: 34.80 +/- 5.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 34.8         |\n",
      "|    mean_reward          | -3.01        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3568528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073394217 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.84        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    std                  | 7.7          |\n",
      "|    value_loss           | 0.571        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | 0.119    |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1743     |\n",
      "|    time_elapsed    | 2711     |\n",
      "|    total_timesteps | 3569664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.126       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1744        |\n",
      "|    time_elapsed         | 2713        |\n",
      "|    total_timesteps      | 3571712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004026794 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.681       |\n",
      "|    n_updates            | 22320       |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    std                  | 7.69        |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | 0.0197       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 2714         |\n",
      "|    total_timesteps      | 3573760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066831056 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.83        |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.178        |\n",
      "|    n_updates            | 22330        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 7.72         |\n",
      "|    value_loss           | 0.684        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.4       |\n",
      "|    ep_rew_mean          | -0.0241    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1746       |\n",
      "|    time_elapsed         | 2716       |\n",
      "|    total_timesteps      | 3575808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00902301 |\n",
      "|    clip_fraction        | 0.0858     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.82      |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.105      |\n",
      "|    n_updates            | 22340      |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    std                  | 7.6        |\n",
      "|    value_loss           | 0.442      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.554       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1316         |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 2718         |\n",
      "|    total_timesteps      | 3577856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071882345 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.79        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.337        |\n",
      "|    n_updates            | 22350        |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    std                  | 7.55         |\n",
      "|    value_loss           | 0.762        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3578528, episode_reward=-1.22 +/- 5.73\n",
      "Episode length: 31.50 +/- 8.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.5        |\n",
      "|    mean_reward          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3578528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010142919 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.79       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 22360       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 7.52        |\n",
      "|    value_loss           | 0.434       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.046   |\n",
      "| time/              |          |\n",
      "|    fps             | 1316     |\n",
      "|    iterations      | 1748     |\n",
      "|    time_elapsed    | 2719     |\n",
      "|    total_timesteps | 3579904  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.2       |\n",
      "|    ep_rew_mean          | 0.514      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1316       |\n",
      "|    iterations           | 1749       |\n",
      "|    time_elapsed         | 2721       |\n",
      "|    total_timesteps      | 3581952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01061522 |\n",
      "|    clip_fraction        | 0.096      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.79      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.252      |\n",
      "|    n_updates            | 22370      |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 7.58       |\n",
      "|    value_loss           | 0.564      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.219       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 2723        |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009735686 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.81       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0723     |\n",
      "|    n_updates            | 22380       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 7.64        |\n",
      "|    value_loss           | 0.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.494      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1751        |\n",
      "|    time_elapsed         | 2724        |\n",
      "|    total_timesteps      | 3586048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009765061 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.81       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 22390       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 7.64        |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.616      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1752        |\n",
      "|    time_elapsed         | 2726        |\n",
      "|    total_timesteps      | 3588096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007360143 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.81       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.197       |\n",
      "|    n_updates            | 22400       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 7.65        |\n",
      "|    value_loss           | 0.549       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3588528, episode_reward=-0.71 +/- 4.49\n",
      "Episode length: 28.80 +/- 6.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28.8         |\n",
      "|    mean_reward          | -0.714       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3588528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100674825 |\n",
      "|    clip_fraction        | 0.0633       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.81        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0731       |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.00864     |\n",
      "|    std                  | 7.65         |\n",
      "|    value_loss           | 0.209        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.8     |\n",
      "|    ep_rew_mean     | -1.24    |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1753     |\n",
      "|    time_elapsed    | 2728     |\n",
      "|    total_timesteps | 3590144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.525      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1754        |\n",
      "|    time_elapsed         | 2729        |\n",
      "|    total_timesteps      | 3592192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007613171 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.81       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 22420       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 7.69        |\n",
      "|    value_loss           | 0.755       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.421      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1755        |\n",
      "|    time_elapsed         | 2731        |\n",
      "|    total_timesteps      | 3594240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009572095 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 7.69        |\n",
      "|    value_loss           | 0.686       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.238       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1756        |\n",
      "|    time_elapsed         | 2732        |\n",
      "|    total_timesteps      | 3596288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005507928 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 22440       |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    std                  | 7.72        |\n",
      "|    value_loss           | 0.483       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1757        |\n",
      "|    time_elapsed         | 2734        |\n",
      "|    total_timesteps      | 3598336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008407772 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.86       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 22450       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 7.87        |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3598528, episode_reward=-3.57 +/- 2.71\n",
      "Episode length: 35.10 +/- 3.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 35.1        |\n",
      "|    mean_reward          | -3.57       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3598528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007412231 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.342       |\n",
      "|    n_updates            | 22460       |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    std                  | 7.96        |\n",
      "|    value_loss           | 0.868       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | -0.54    |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1758     |\n",
      "|    time_elapsed    | 2735     |\n",
      "|    total_timesteps | 3600384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.512      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1759        |\n",
      "|    time_elapsed         | 2737        |\n",
      "|    total_timesteps      | 3602432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008255055 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.91       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 22470       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 7.92        |\n",
      "|    value_loss           | 0.826       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.73       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1760        |\n",
      "|    time_elapsed         | 2738        |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008818811 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.3         |\n",
      "|    n_updates            | 22480       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 7.91        |\n",
      "|    value_loss           | 0.881       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.16       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1316        |\n",
      "|    iterations           | 1761        |\n",
      "|    time_elapsed         | 2740        |\n",
      "|    total_timesteps      | 3606528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008182667 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.25        |\n",
      "|    n_updates            | 22490       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 7.83        |\n",
      "|    value_loss           | 0.756       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3608528, episode_reward=2.53 +/- 4.38\n",
      "Episode length: 27.10 +/- 8.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27.1         |\n",
      "|    mean_reward          | 2.53         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3608528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062617427 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.89        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0822       |\n",
      "|    n_updates            | 22500        |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    std                  | 7.85         |\n",
      "|    value_loss           | 0.443        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -1.25    |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1762     |\n",
      "|    time_elapsed    | 2742     |\n",
      "|    total_timesteps | 3608576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1763        |\n",
      "|    time_elapsed         | 2743        |\n",
      "|    total_timesteps      | 3610624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009000797 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 22510       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 7.89        |\n",
      "|    value_loss           | 0.706       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.726      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1764        |\n",
      "|    time_elapsed         | 2745        |\n",
      "|    total_timesteps      | 3612672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011107293 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.89       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.067       |\n",
      "|    n_updates            | 22520       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 7.79        |\n",
      "|    value_loss           | 0.533       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.585       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1765         |\n",
      "|    time_elapsed         | 2746         |\n",
      "|    total_timesteps      | 3614720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068720933 |\n",
      "|    clip_fraction        | 0.0706       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.88        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.166        |\n",
      "|    n_updates            | 22530        |\n",
      "|    policy_gradient_loss | -0.0123      |\n",
      "|    std                  | 7.76         |\n",
      "|    value_loss           | 0.495        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.564      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1766        |\n",
      "|    time_elapsed         | 2748        |\n",
      "|    total_timesteps      | 3616768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006709499 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.88       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 7.81        |\n",
      "|    value_loss           | 0.717       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3618528, episode_reward=-1.45 +/- 5.12\n",
      "Episode length: 31.20 +/- 7.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.2        |\n",
      "|    mean_reward          | -1.45       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3618528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008756789 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.91       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 22550       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 7.98        |\n",
      "|    value_loss           | 0.623       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.196   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1767     |\n",
      "|    time_elapsed    | 2750     |\n",
      "|    total_timesteps | 3618816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.807      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1768        |\n",
      "|    time_elapsed         | 2751        |\n",
      "|    total_timesteps      | 3620864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009897789 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.93       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0858      |\n",
      "|    n_updates            | 22560       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 0.363       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -0.599      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 2753        |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010611131 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 8.02        |\n",
      "|    value_loss           | 0.936       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.523      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1770        |\n",
      "|    time_elapsed         | 2754        |\n",
      "|    total_timesteps      | 3624960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007123852 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.208       |\n",
      "|    n_updates            | 22580       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 8.05        |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.0223      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1771        |\n",
      "|    time_elapsed         | 2756        |\n",
      "|    total_timesteps      | 3627008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005411915 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.96       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 22590       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    std                  | 8.15        |\n",
      "|    value_loss           | 0.61        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3628528, episode_reward=-0.07 +/- 5.80\n",
      "Episode length: 29.40 +/- 9.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.4         |\n",
      "|    mean_reward          | -0.0694      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3628528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071677677 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.97        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0443       |\n",
      "|    n_updates            | 22600        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 8.09         |\n",
      "|    value_loss           | 0.346        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.217   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1772     |\n",
      "|    time_elapsed    | 2758     |\n",
      "|    total_timesteps | 3629056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.0867      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1773        |\n",
      "|    time_elapsed         | 2760        |\n",
      "|    total_timesteps      | 3631104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006035417 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.761       |\n",
      "|    n_updates            | 22610       |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    std                  | 8.05        |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | 0.489       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1774        |\n",
      "|    time_elapsed         | 2761        |\n",
      "|    total_timesteps      | 3633152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005975931 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 22620       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    std                  | 8.01        |\n",
      "|    value_loss           | 0.523       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.264       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1775         |\n",
      "|    time_elapsed         | 2763         |\n",
      "|    total_timesteps      | 3635200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069318484 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.93        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0601       |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -0.00869     |\n",
      "|    std                  | 7.95         |\n",
      "|    value_loss           | 0.333        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.637      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1776        |\n",
      "|    time_elapsed         | 2764        |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008297807 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.93       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 22640       |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    std                  | 7.97        |\n",
      "|    value_loss           | 0.81        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3638528, episode_reward=-0.63 +/- 5.11\n",
      "Episode length: 31.00 +/- 9.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31           |\n",
      "|    mean_reward          | -0.635       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3638528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072677117 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.93        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0119      |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 7.88         |\n",
      "|    value_loss           | 0.131        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.341   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1777     |\n",
      "|    time_elapsed    | 2766     |\n",
      "|    total_timesteps | 3639296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.636      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1778        |\n",
      "|    time_elapsed         | 2768        |\n",
      "|    total_timesteps      | 3641344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006804698 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.304       |\n",
      "|    n_updates            | 22660       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 7.82        |\n",
      "|    value_loss           | 0.901       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.113      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 2769        |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016206386 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 22670       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 7.88        |\n",
      "|    value_loss           | 0.436       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.651      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1780        |\n",
      "|    time_elapsed         | 2771        |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008171915 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.92       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 22680       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 7.91        |\n",
      "|    value_loss           | 0.584       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.845      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1781        |\n",
      "|    time_elapsed         | 2773        |\n",
      "|    total_timesteps      | 3647488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007075364 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.93       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 22690       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 7.96        |\n",
      "|    value_loss           | 0.75        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3648528, episode_reward=1.32 +/- 4.14\n",
      "Episode length: 28.10 +/- 6.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.1        |\n",
      "|    mean_reward          | 1.32        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3648528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009098118 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0419     |\n",
      "|    n_updates            | 22700       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    std                  | 7.96        |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.451   |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1782     |\n",
      "|    time_elapsed    | 2774     |\n",
      "|    total_timesteps | 3649536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.055      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1783        |\n",
      "|    time_elapsed         | 2776        |\n",
      "|    total_timesteps      | 3651584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008161491 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.569       |\n",
      "|    n_updates            | 22710       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 8.07        |\n",
      "|    value_loss           | 0.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1784        |\n",
      "|    time_elapsed         | 2777        |\n",
      "|    total_timesteps      | 3653632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008470444 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.96       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 22720       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 8.06        |\n",
      "|    value_loss           | 0.873       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.5         |\n",
      "|    ep_rew_mean          | -0.874       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1785         |\n",
      "|    time_elapsed         | 2779         |\n",
      "|    total_timesteps      | 3655680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068279477 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.96        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.64         |\n",
      "|    n_updates            | 22730        |\n",
      "|    policy_gradient_loss | -0.00817     |\n",
      "|    std                  | 8.05         |\n",
      "|    value_loss           | 1.41         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.116      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 2781        |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009546327 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.96       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 22740       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 8.06        |\n",
      "|    value_loss           | 0.548       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3658528, episode_reward=1.71 +/- 3.09\n",
      "Episode length: 26.40 +/- 5.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.4         |\n",
      "|    mean_reward          | 1.71         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3658528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073621725 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.95        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0639       |\n",
      "|    n_updates            | 22750        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 7.91         |\n",
      "|    value_loss           | 0.435        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.25     |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1787     |\n",
      "|    time_elapsed    | 2782     |\n",
      "|    total_timesteps | 3659776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.544      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1788        |\n",
      "|    time_elapsed         | 2784        |\n",
      "|    total_timesteps      | 3661824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010317032 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.429       |\n",
      "|    n_updates            | 22760       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 7.97        |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -1.28        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1315         |\n",
      "|    iterations           | 1789         |\n",
      "|    time_elapsed         | 2785         |\n",
      "|    total_timesteps      | 3663872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044992245 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.95        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.109        |\n",
      "|    n_updates            | 22770        |\n",
      "|    policy_gradient_loss | -0.00829     |\n",
      "|    std                  | 7.96         |\n",
      "|    value_loss           | 0.439        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1790        |\n",
      "|    time_elapsed         | 2787        |\n",
      "|    total_timesteps      | 3665920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007704274 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 22780       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 7.96        |\n",
      "|    value_loss           | 0.251       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.4       |\n",
      "|    ep_rew_mean          | -0.25      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1315       |\n",
      "|    iterations           | 1791       |\n",
      "|    time_elapsed         | 2788       |\n",
      "|    total_timesteps      | 3667968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01207328 |\n",
      "|    clip_fraction        | 0.0959     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.93      |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.205      |\n",
      "|    n_updates            | 22790      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    std                  | 7.92       |\n",
      "|    value_loss           | 0.708      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3668528, episode_reward=0.41 +/- 4.87\n",
      "Episode length: 28.10 +/- 6.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.1        |\n",
      "|    mean_reward          | 0.406       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3668528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007525338 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 22800       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 7.99        |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -1.15    |\n",
      "| time/              |          |\n",
      "|    fps             | 1315     |\n",
      "|    iterations      | 1792     |\n",
      "|    time_elapsed    | 2790     |\n",
      "|    total_timesteps | 3670016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | 0.0158      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1793        |\n",
      "|    time_elapsed         | 2792        |\n",
      "|    total_timesteps      | 3672064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007705221 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.259       |\n",
      "|    n_updates            | 22810       |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    std                  | 8.05        |\n",
      "|    value_loss           | 0.87        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.7       |\n",
      "|    ep_rew_mean          | -0.296     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1315       |\n",
      "|    iterations           | 1794       |\n",
      "|    time_elapsed         | 2793       |\n",
      "|    total_timesteps      | 3674112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00709899 |\n",
      "|    clip_fraction        | 0.0417     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.96      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.00628    |\n",
      "|    n_updates            | 22820      |\n",
      "|    policy_gradient_loss | -0.0097    |\n",
      "|    std                  | 7.95       |\n",
      "|    value_loss           | 0.271      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.219      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1315        |\n",
      "|    iterations           | 1795        |\n",
      "|    time_elapsed         | 2795        |\n",
      "|    total_timesteps      | 3676160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007496789 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.94       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0428      |\n",
      "|    n_updates            | 22830       |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    std                  | 7.92        |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.247      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1314        |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 2797        |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009437492 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 22840       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 8.02        |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3678528, episode_reward=-2.03 +/- 5.15\n",
      "Episode length: 32.80 +/- 6.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -2.03       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3678528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010958508 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.97       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0967      |\n",
      "|    n_updates            | 22850       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 8           |\n",
      "|    value_loss           | 0.566       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | 0.606    |\n",
      "| time/              |          |\n",
      "|    fps             | 1314     |\n",
      "|    iterations      | 1797     |\n",
      "|    time_elapsed    | 2800     |\n",
      "|    total_timesteps | 3680256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.61        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1798        |\n",
      "|    time_elapsed         | 2802        |\n",
      "|    total_timesteps      | 3682304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011412841 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.97       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 22860       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 8.02        |\n",
      "|    value_loss           | 0.558       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.0285      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 2804        |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008603213 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.98       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 22870       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 8.12        |\n",
      "|    value_loss           | 0.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.553      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1800        |\n",
      "|    time_elapsed         | 2805        |\n",
      "|    total_timesteps      | 3686400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011027765 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0662      |\n",
      "|    n_updates            | 22880       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 8.18        |\n",
      "|    value_loss           | 0.392       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.277      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 2807        |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006532208 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.01       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 22890       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    std                  | 8.19        |\n",
      "|    value_loss           | 0.55        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3688528, episode_reward=2.22 +/- 5.62\n",
      "Episode length: 25.00 +/- 9.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 25          |\n",
      "|    mean_reward          | 2.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3688528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008141881 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 22900       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    std                  | 8.14        |\n",
      "|    value_loss           | 0.983       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.227   |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 1802     |\n",
      "|    time_elapsed    | 2809     |\n",
      "|    total_timesteps | 3690496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.117      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 2810        |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007368554 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.539       |\n",
      "|    n_updates            | 22910       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 8.2         |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.14        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1804        |\n",
      "|    time_elapsed         | 2812        |\n",
      "|    total_timesteps      | 3694592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009977788 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.02       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 22920       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    std                  | 8.28        |\n",
      "|    value_loss           | 0.872       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.169      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1805        |\n",
      "|    time_elapsed         | 2814        |\n",
      "|    total_timesteps      | 3696640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008399645 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.03       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 22930       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 8.26        |\n",
      "|    value_loss           | 0.501       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3698528, episode_reward=0.75 +/- 4.30\n",
      "Episode length: 27.30 +/- 5.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27.3         |\n",
      "|    mean_reward          | 0.75         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3698528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098520275 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.02        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0891       |\n",
      "|    n_updates            | 22940        |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 8.2          |\n",
      "|    value_loss           | 0.433        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.493    |\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 1806     |\n",
      "|    time_elapsed    | 2815     |\n",
      "|    total_timesteps | 3698688  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 0.223        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 1807         |\n",
      "|    time_elapsed         | 2817         |\n",
      "|    total_timesteps      | 3700736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105317915 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.99        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0484       |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    std                  | 8.06         |\n",
      "|    value_loss           | 0.303        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.536       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 1808         |\n",
      "|    time_elapsed         | 2819         |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065454477 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.96        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.162        |\n",
      "|    n_updates            | 22960        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    std                  | 7.98         |\n",
      "|    value_loss           | 0.43         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.3       |\n",
      "|    ep_rew_mean          | -0.408     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1313       |\n",
      "|    iterations           | 1809       |\n",
      "|    time_elapsed         | 2821       |\n",
      "|    total_timesteps      | 3704832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00886129 |\n",
      "|    clip_fraction        | 0.095      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.96      |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.137      |\n",
      "|    n_updates            | 22970      |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 8.01       |\n",
      "|    value_loss           | 0.534      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.591       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1313        |\n",
      "|    iterations           | 1810        |\n",
      "|    time_elapsed         | 2823        |\n",
      "|    total_timesteps      | 3706880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008641613 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.96       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 22980       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 7.99        |\n",
      "|    value_loss           | 0.581       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3708528, episode_reward=-1.14 +/- 3.76\n",
      "Episode length: 33.00 +/- 5.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33          |\n",
      "|    mean_reward          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3708528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010095224 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0283      |\n",
      "|    n_updates            | 22990       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 7.94        |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.145   |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1811     |\n",
      "|    time_elapsed    | 2825     |\n",
      "|    total_timesteps | 3708928  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.347       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 1812         |\n",
      "|    time_elapsed         | 2826         |\n",
      "|    total_timesteps      | 3710976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062295026 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -6.94        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.186        |\n",
      "|    n_updates            | 23000        |\n",
      "|    policy_gradient_loss | -0.00848     |\n",
      "|    std                  | 8            |\n",
      "|    value_loss           | 0.676        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.242       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 2828        |\n",
      "|    total_timesteps      | 3713024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008129656 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.96       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 23010       |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    std                  | 8.07        |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.272       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1814        |\n",
      "|    time_elapsed         | 2830        |\n",
      "|    total_timesteps      | 3715072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006873359 |\n",
      "|    clip_fraction        | 0.0487      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.97       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 23020       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 8.12        |\n",
      "|    value_loss           | 0.419       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.7        |\n",
      "|    ep_rew_mean          | 0.835       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1815        |\n",
      "|    time_elapsed         | 2831        |\n",
      "|    total_timesteps      | 3717120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010057086 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 23030       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 8.28        |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3718528, episode_reward=-1.08 +/- 6.25\n",
      "Episode length: 33.30 +/- 13.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 33.3         |\n",
      "|    mean_reward          | -1.08        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3718528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065623033 |\n",
      "|    clip_fraction        | 0.0784       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.02        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0654       |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 8.29         |\n",
      "|    value_loss           | 0.222        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.34    |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1816     |\n",
      "|    time_elapsed    | 2833     |\n",
      "|    total_timesteps | 3719168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.956      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1817        |\n",
      "|    time_elapsed         | 2834        |\n",
      "|    total_timesteps      | 3721216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006746496 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.02       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0442      |\n",
      "|    n_updates            | 23050       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 8.27        |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1818        |\n",
      "|    time_elapsed         | 2836        |\n",
      "|    total_timesteps      | 3723264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008982764 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.04       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00209    |\n",
      "|    n_updates            | 23060       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 8.42        |\n",
      "|    value_loss           | 0.343       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.172       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 1819         |\n",
      "|    time_elapsed         | 2837         |\n",
      "|    total_timesteps      | 3725312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074047404 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.07        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.119        |\n",
      "|    n_updates            | 23070        |\n",
      "|    policy_gradient_loss | -0.00857     |\n",
      "|    std                  | 8.5          |\n",
      "|    value_loss           | 0.535        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.0844      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 2839        |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010070758 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.06       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 23080       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 8.49        |\n",
      "|    value_loss           | 0.614       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3728528, episode_reward=0.00 +/- 4.16\n",
      "Episode length: 29.60 +/- 6.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.6         |\n",
      "|    mean_reward          | 0.000584     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3728528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068485597 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.06        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.000952     |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00944     |\n",
      "|    std                  | 8.45         |\n",
      "|    value_loss           | 0.239        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | 0.171    |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1821     |\n",
      "|    time_elapsed    | 2841     |\n",
      "|    total_timesteps | 3729408  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | 0.0116       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1312         |\n",
      "|    iterations           | 1822         |\n",
      "|    time_elapsed         | 2843         |\n",
      "|    total_timesteps      | 3731456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065440116 |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.04        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.146        |\n",
      "|    n_updates            | 23100        |\n",
      "|    policy_gradient_loss | -0.00955     |\n",
      "|    std                  | 8.39         |\n",
      "|    value_loss           | 0.622        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.323       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1823        |\n",
      "|    time_elapsed         | 2844        |\n",
      "|    total_timesteps      | 3733504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009394252 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.04       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0805      |\n",
      "|    n_updates            | 23110       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 8.39        |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.226       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1824        |\n",
      "|    time_elapsed         | 2845        |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009711704 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.03       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0979      |\n",
      "|    n_updates            | 23120       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 8.36        |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.167       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 2847        |\n",
      "|    total_timesteps      | 3737600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007957943 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.05       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0713      |\n",
      "|    n_updates            | 23130       |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    std                  | 8.52        |\n",
      "|    value_loss           | 0.36        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3738528, episode_reward=0.93 +/- 3.18\n",
      "Episode length: 29.70 +/- 5.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.7         |\n",
      "|    mean_reward          | 0.935        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3738528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076919966 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.06        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.06         |\n",
      "|    n_updates            | 23140        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 8.44         |\n",
      "|    value_loss           | 0.479        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | 0.177    |\n",
      "| time/              |          |\n",
      "|    fps             | 1312     |\n",
      "|    iterations      | 1826     |\n",
      "|    time_elapsed    | 2849     |\n",
      "|    total_timesteps | 3739648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.707      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1827        |\n",
      "|    time_elapsed         | 2851        |\n",
      "|    total_timesteps      | 3741696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009552674 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.07       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 23150       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 8.6         |\n",
      "|    value_loss           | 0.603       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.928      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 2853        |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009196108 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 23160       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 8.65        |\n",
      "|    value_loss           | 0.368       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.421      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1312        |\n",
      "|    iterations           | 1829        |\n",
      "|    time_elapsed         | 2854        |\n",
      "|    total_timesteps      | 3745792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007828798 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0498     |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 8.65        |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.9        |\n",
      "|    ep_rew_mean          | -0.951      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 2856        |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006488161 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 8.63        |\n",
      "|    value_loss           | 0.735       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3748528, episode_reward=-0.55 +/- 5.67\n",
      "Episode length: 31.10 +/- 10.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.1        |\n",
      "|    mean_reward          | -0.555      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3748528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008691423 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.084       |\n",
      "|    n_updates            | 23190       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 8.72        |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -0.616   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 1831     |\n",
      "|    time_elapsed    | 2858     |\n",
      "|    total_timesteps | 3749888  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.7         |\n",
      "|    ep_rew_mean          | -0.0857      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1832         |\n",
      "|    time_elapsed         | 2860         |\n",
      "|    total_timesteps      | 3751936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122979665 |\n",
      "|    clip_fraction        | 0.0843       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.258        |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 8.74         |\n",
      "|    value_loss           | 0.748        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.213       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1833        |\n",
      "|    time_elapsed         | 2862        |\n",
      "|    total_timesteps      | 3753984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007786339 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0745     |\n",
      "|    n_updates            | 23210       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    std                  | 8.74        |\n",
      "|    value_loss           | 0.097       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.447       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1834        |\n",
      "|    time_elapsed         | 2863        |\n",
      "|    total_timesteps      | 3756032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010949316 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0808     |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 8.67        |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | 0.00215      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1835         |\n",
      "|    time_elapsed         | 2865         |\n",
      "|    total_timesteps      | 3758080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113689685 |\n",
      "|    clip_fraction        | 0.0717       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.215        |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00842     |\n",
      "|    std                  | 8.68         |\n",
      "|    value_loss           | 0.544        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3758528, episode_reward=0.48 +/- 6.62\n",
      "Episode length: 26.70 +/- 11.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.7         |\n",
      "|    mean_reward          | 0.484        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3758528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072981003 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0923       |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.00986     |\n",
      "|    std                  | 8.7          |\n",
      "|    value_loss           | 0.244        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | 0.369    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 1836     |\n",
      "|    time_elapsed    | 2867     |\n",
      "|    total_timesteps | 3760128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.985       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 2868        |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007396603 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 23250       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 8.7         |\n",
      "|    value_loss           | 0.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.733      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 1838        |\n",
      "|    time_elapsed         | 2870        |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007331757 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0433     |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 8.85        |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.564       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1839         |\n",
      "|    time_elapsed         | 2872         |\n",
      "|    total_timesteps      | 3766272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068355026 |\n",
      "|    clip_fraction        | 0.0694       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.16        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0242       |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    std                  | 9.06         |\n",
      "|    value_loss           | 0.185        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | 0.214        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1840         |\n",
      "|    time_elapsed         | 2874         |\n",
      "|    total_timesteps      | 3768320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080895815 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.2         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0599       |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00942     |\n",
      "|    std                  | 9.22         |\n",
      "|    value_loss           | 0.381        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3768528, episode_reward=-1.05 +/- 5.01\n",
      "Episode length: 31.90 +/- 8.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.9        |\n",
      "|    mean_reward          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3768528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008014293 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.21       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 23290       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 9.28        |\n",
      "|    value_loss           | 0.43        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | 0.36     |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 1841     |\n",
      "|    time_elapsed    | 2875     |\n",
      "|    total_timesteps | 3770368  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.0717      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 1842         |\n",
      "|    time_elapsed         | 2877         |\n",
      "|    total_timesteps      | 3772416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056425454 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.23        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.206        |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00796     |\n",
      "|    std                  | 9.36         |\n",
      "|    value_loss           | 0.741        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.402      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1843        |\n",
      "|    time_elapsed         | 2879        |\n",
      "|    total_timesteps      | 3774464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010155306 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0469      |\n",
      "|    n_updates            | 23310       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 9.45        |\n",
      "|    value_loss           | 0.496       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.961      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1844        |\n",
      "|    time_elapsed         | 2880        |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008719407 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0664      |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 9.41        |\n",
      "|    value_loss           | 0.464       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3778528, episode_reward=-1.52 +/- 4.73\n",
      "Episode length: 32.30 +/- 6.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.3        |\n",
      "|    mean_reward          | -1.52       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3778528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007827695 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.196       |\n",
      "|    n_updates            | 23330       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 9.45        |\n",
      "|    value_loss           | 0.966       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.134   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1845     |\n",
      "|    time_elapsed    | 2882     |\n",
      "|    total_timesteps | 3778560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.562      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1846        |\n",
      "|    time_elapsed         | 2884        |\n",
      "|    total_timesteps      | 3780608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006771013 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0594      |\n",
      "|    n_updates            | 23340       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 9.5         |\n",
      "|    value_loss           | 0.35        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.375       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 1847         |\n",
      "|    time_elapsed         | 2885         |\n",
      "|    total_timesteps      | 3782656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063780476 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.24        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 23350        |\n",
      "|    policy_gradient_loss | -0.0096      |\n",
      "|    std                  | 9.49         |\n",
      "|    value_loss           | 0.436        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.47       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1848        |\n",
      "|    time_elapsed         | 2887        |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004768226 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 23360       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    std                  | 9.44        |\n",
      "|    value_loss           | 0.458       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 0.243        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 1849         |\n",
      "|    time_elapsed         | 2889         |\n",
      "|    total_timesteps      | 3786752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051242504 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.24        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.178        |\n",
      "|    n_updates            | 23370        |\n",
      "|    policy_gradient_loss | -0.00978     |\n",
      "|    std                  | 9.52         |\n",
      "|    value_loss           | 0.554        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3788528, episode_reward=2.94 +/- 5.14\n",
      "Episode length: 22.40 +/- 10.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 22.4        |\n",
      "|    mean_reward          | 2.94        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3788528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005253588 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0136     |\n",
      "|    n_updates            | 23380       |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 0.274       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.173   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 1850     |\n",
      "|    time_elapsed    | 2891     |\n",
      "|    total_timesteps | 3788800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.0223     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 1851        |\n",
      "|    time_elapsed         | 2893        |\n",
      "|    total_timesteps      | 3790848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010090772 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 23390       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 9.41        |\n",
      "|    value_loss           | 0.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.0987      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1852        |\n",
      "|    time_elapsed         | 2895        |\n",
      "|    total_timesteps      | 3792896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007817133 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0608      |\n",
      "|    n_updates            | 23400       |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    std                  | 9.51        |\n",
      "|    value_loss           | 0.388       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.308      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1853        |\n",
      "|    time_elapsed         | 2897        |\n",
      "|    total_timesteps      | 3794944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009516751 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0704     |\n",
      "|    n_updates            | 23410       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 9.47        |\n",
      "|    value_loss           | 0.0995      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.102      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1854        |\n",
      "|    time_elapsed         | 2899        |\n",
      "|    total_timesteps      | 3796992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009021362 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00969    |\n",
      "|    n_updates            | 23420       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 9.45        |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3798528, episode_reward=0.91 +/- 4.41\n",
      "Episode length: 28.40 +/- 6.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.4        |\n",
      "|    mean_reward          | 0.906       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3798528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007978602 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0948      |\n",
      "|    n_updates            | 23430       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 9.46        |\n",
      "|    value_loss           | 0.354       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.505   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1855     |\n",
      "|    time_elapsed    | 2901     |\n",
      "|    total_timesteps | 3799040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.248      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1856        |\n",
      "|    time_elapsed         | 2902        |\n",
      "|    total_timesteps      | 3801088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008054618 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.23       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 23440       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 9.33        |\n",
      "|    value_loss           | 0.418       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1857        |\n",
      "|    time_elapsed         | 2904        |\n",
      "|    total_timesteps      | 3803136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010866367 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.22       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 23450       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 9.42        |\n",
      "|    value_loss           | 0.477       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33          |\n",
      "|    ep_rew_mean          | -1.54       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1858        |\n",
      "|    time_elapsed         | 2906        |\n",
      "|    total_timesteps      | 3805184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005923779 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.408       |\n",
      "|    n_updates            | 23460       |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    std                  | 9.4         |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.5         |\n",
      "|    ep_rew_mean          | 0.0455       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1859         |\n",
      "|    time_elapsed         | 2908         |\n",
      "|    total_timesteps      | 3807232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074934913 |\n",
      "|    clip_fraction        | 0.0652       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.23        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.154        |\n",
      "|    n_updates            | 23470        |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 9.32         |\n",
      "|    value_loss           | 0.601        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3808528, episode_reward=-0.97 +/- 3.70\n",
      "Episode length: 31.30 +/- 5.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.3        |\n",
      "|    mean_reward          | -0.969      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3808528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009824052 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.22       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 23480       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 9.31        |\n",
      "|    value_loss           | 0.518       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.0379  |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1860     |\n",
      "|    time_elapsed    | 2910     |\n",
      "|    total_timesteps | 3809280  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.5         |\n",
      "|    ep_rew_mean          | -0.974       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1861         |\n",
      "|    time_elapsed         | 2911         |\n",
      "|    total_timesteps      | 3811328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074334755 |\n",
      "|    clip_fraction        | 0.0712       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.23        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.138        |\n",
      "|    n_updates            | 23490        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 9.39         |\n",
      "|    value_loss           | 0.597        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1862        |\n",
      "|    time_elapsed         | 2913        |\n",
      "|    total_timesteps      | 3813376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009196251 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 23500       |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    std                  | 9.35        |\n",
      "|    value_loss           | 0.772       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.695       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1863         |\n",
      "|    time_elapsed         | 2915         |\n",
      "|    total_timesteps      | 3815424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074755037 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.23        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.264        |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00937     |\n",
      "|    std                  | 9.32         |\n",
      "|    value_loss           | 0.843        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.361       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1864         |\n",
      "|    time_elapsed         | 2917         |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050823465 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.22        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0458       |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    std                  | 9.27         |\n",
      "|    value_loss           | 0.508        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3818528, episode_reward=-2.21 +/- 5.22\n",
      "Episode length: 32.80 +/- 7.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.8         |\n",
      "|    mean_reward          | -2.21        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3818528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048606955 |\n",
      "|    clip_fraction        | 0.0523       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.21        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.299        |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.00917     |\n",
      "|    std                  | 9.25         |\n",
      "|    value_loss           | 0.989        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | -0.266   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1865     |\n",
      "|    time_elapsed    | 2919     |\n",
      "|    total_timesteps | 3819520  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.445      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1866        |\n",
      "|    time_elapsed         | 2920        |\n",
      "|    total_timesteps      | 3821568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008930372 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.21       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 23540       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 9.18        |\n",
      "|    value_loss           | 0.339       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1867        |\n",
      "|    time_elapsed         | 2922        |\n",
      "|    total_timesteps      | 3823616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005612337 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.19       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.279       |\n",
      "|    n_updates            | 23550       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    std                  | 9.03        |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.507       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1868         |\n",
      "|    time_elapsed         | 2924         |\n",
      "|    total_timesteps      | 3825664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063635916 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.15        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.267        |\n",
      "|    n_updates            | 23560        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 8.88         |\n",
      "|    value_loss           | 1.1          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.7         |\n",
      "|    ep_rew_mean          | 0.509        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1869         |\n",
      "|    time_elapsed         | 2925         |\n",
      "|    total_timesteps      | 3827712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060688183 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.13        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0526      |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00834     |\n",
      "|    std                  | 8.72         |\n",
      "|    value_loss           | 0.162        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3828528, episode_reward=-4.15 +/- 4.23\n",
      "Episode length: 36.90 +/- 6.79\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 36.9       |\n",
      "|    mean_reward          | -4.15      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3828528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00967809 |\n",
      "|    clip_fraction        | 0.0694     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.11      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0616    |\n",
      "|    n_updates            | 23580      |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 8.81       |\n",
      "|    value_loss           | 0.0541     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.8     |\n",
      "|    ep_rew_mean     | 0.294    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1870     |\n",
      "|    time_elapsed    | 2927     |\n",
      "|    total_timesteps | 3829760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.602      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1871        |\n",
      "|    time_elapsed         | 2929        |\n",
      "|    total_timesteps      | 3831808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006894676 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.191       |\n",
      "|    n_updates            | 23590       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    std                  | 8.76        |\n",
      "|    value_loss           | 0.446       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | 0.368        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1872         |\n",
      "|    time_elapsed         | 2930         |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077906107 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.408        |\n",
      "|    n_updates            | 23600        |\n",
      "|    policy_gradient_loss | -0.0088      |\n",
      "|    std                  | 8.79         |\n",
      "|    value_loss           | 0.996        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.545      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1873        |\n",
      "|    time_elapsed         | 2932        |\n",
      "|    total_timesteps      | 3835904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008522788 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 23610       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 8.85        |\n",
      "|    value_loss           | 0.929       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.617      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 2933        |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006501773 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 23620       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    std                  | 8.84        |\n",
      "|    value_loss           | 0.847       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3838528, episode_reward=-0.06 +/- 5.94\n",
      "Episode length: 30.00 +/- 8.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30           |\n",
      "|    mean_reward          | -0.0629      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060777864 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0101       |\n",
      "|    n_updates            | 23630        |\n",
      "|    policy_gradient_loss | -0.00814     |\n",
      "|    std                  | 8.85         |\n",
      "|    value_loss           | 0.355        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.0737  |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1875     |\n",
      "|    time_elapsed    | 2935     |\n",
      "|    total_timesteps | 3840000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.323       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1876        |\n",
      "|    time_elapsed         | 2936        |\n",
      "|    total_timesteps      | 3842048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008993368 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0472      |\n",
      "|    n_updates            | 23640       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 8.98        |\n",
      "|    value_loss           | 0.258       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.0234      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1877        |\n",
      "|    time_elapsed         | 2938        |\n",
      "|    total_timesteps      | 3844096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008775963 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.18       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 23650       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 9.23        |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1878        |\n",
      "|    time_elapsed         | 2940        |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006683725 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.22       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0923      |\n",
      "|    n_updates            | 23660       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 9.36        |\n",
      "|    value_loss           | 0.589       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.582      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1879        |\n",
      "|    time_elapsed         | 2941        |\n",
      "|    total_timesteps      | 3848192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007144302 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.35        |\n",
      "|    n_updates            | 23670       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 9.39        |\n",
      "|    value_loss           | 0.844       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3848528, episode_reward=2.13 +/- 3.66\n",
      "Episode length: 28.60 +/- 5.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.6        |\n",
      "|    mean_reward          | 2.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3848528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007397454 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.24       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 23680       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 9.38        |\n",
      "|    value_loss           | 0.447       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.8     |\n",
      "|    ep_rew_mean     | -1.29    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1880     |\n",
      "|    time_elapsed    | 2943     |\n",
      "|    total_timesteps | 3850240  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.521       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1881         |\n",
      "|    time_elapsed         | 2945         |\n",
      "|    total_timesteps      | 3852288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064286306 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.25        |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.436        |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    std                  | 9.47         |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.5         |\n",
      "|    ep_rew_mean          | -0.382       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1882         |\n",
      "|    time_elapsed         | 2946         |\n",
      "|    total_timesteps      | 3854336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054210746 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.26        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.261        |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.00791     |\n",
      "|    std                  | 9.49         |\n",
      "|    value_loss           | 0.788        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.322      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1883        |\n",
      "|    time_elapsed         | 2948        |\n",
      "|    total_timesteps      | 3856384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007079048 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.27       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 23710       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    std                  | 9.54        |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1884        |\n",
      "|    time_elapsed         | 2949        |\n",
      "|    total_timesteps      | 3858432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007619287 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.28       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.186       |\n",
      "|    n_updates            | 23720       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 9.57        |\n",
      "|    value_loss           | 0.5         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3858528, episode_reward=0.99 +/- 4.59\n",
      "Episode length: 28.00 +/- 7.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28           |\n",
      "|    mean_reward          | 0.992        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3858528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057346737 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.27        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0835       |\n",
      "|    n_updates            | 23730        |\n",
      "|    policy_gradient_loss | -0.00752     |\n",
      "|    std                  | 9.48         |\n",
      "|    value_loss           | 0.338        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.699   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1885     |\n",
      "|    time_elapsed    | 2951     |\n",
      "|    total_timesteps | 3860480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.638      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1886        |\n",
      "|    time_elapsed         | 2952        |\n",
      "|    total_timesteps      | 3862528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011733881 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.27       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 23740       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 9.6         |\n",
      "|    value_loss           | 0.772       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.6       |\n",
      "|    ep_rew_mean          | 0.28       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 1887       |\n",
      "|    time_elapsed         | 2954       |\n",
      "|    total_timesteps      | 3864576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00510998 |\n",
      "|    clip_fraction        | 0.0326     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.29      |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.221      |\n",
      "|    n_updates            | 23750      |\n",
      "|    policy_gradient_loss | -0.0068    |\n",
      "|    std                  | 9.72       |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.5         |\n",
      "|    ep_rew_mean          | 0.177        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1888         |\n",
      "|    time_elapsed         | 2955         |\n",
      "|    total_timesteps      | 3866624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084814485 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.33        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0428      |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.00948     |\n",
      "|    std                  | 9.95         |\n",
      "|    value_loss           | 0.217        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3868528, episode_reward=-0.94 +/- 3.55\n",
      "Episode length: 32.10 +/- 5.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.1        |\n",
      "|    mean_reward          | -0.939      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3868528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007252466 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.34       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0451     |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 9.86        |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.4     |\n",
      "|    ep_rew_mean     | 0.565    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1889     |\n",
      "|    time_elapsed    | 2957     |\n",
      "|    total_timesteps | 3868672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.288      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1890        |\n",
      "|    time_elapsed         | 2959        |\n",
      "|    total_timesteps      | 3870720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011249997 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.33       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 23780       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 9.93        |\n",
      "|    value_loss           | 0.44        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.461       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1891         |\n",
      "|    time_elapsed         | 2960         |\n",
      "|    total_timesteps      | 3872768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072758924 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.34        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.174        |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 9.87         |\n",
      "|    value_loss           | 0.401        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.709       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1892        |\n",
      "|    time_elapsed         | 2962        |\n",
      "|    total_timesteps      | 3874816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008429498 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.34       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00709     |\n",
      "|    n_updates            | 23800       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    std                  | 9.8         |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.248       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1893        |\n",
      "|    time_elapsed         | 2963        |\n",
      "|    total_timesteps      | 3876864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007107943 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.34       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 23810       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 9.93        |\n",
      "|    value_loss           | 0.271       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3878528, episode_reward=-1.17 +/- 5.77\n",
      "Episode length: 32.70 +/- 13.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.7        |\n",
      "|    mean_reward          | -1.17       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3878528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012041528 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.35       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0118      |\n",
      "|    n_updates            | 23820       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 9.81        |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.5     |\n",
      "|    ep_rew_mean     | 0.713    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1894     |\n",
      "|    time_elapsed    | 2965     |\n",
      "|    total_timesteps | 3878912  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | 0.176        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1895         |\n",
      "|    time_elapsed         | 2966         |\n",
      "|    total_timesteps      | 3880960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080899475 |\n",
      "|    clip_fraction        | 0.0879       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.33        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.000398     |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    std                  | 9.8          |\n",
      "|    value_loss           | 0.231        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.3         |\n",
      "|    ep_rew_mean          | -0.27        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1896         |\n",
      "|    time_elapsed         | 2968         |\n",
      "|    total_timesteps      | 3883008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038245185 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.33        |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.642        |\n",
      "|    n_updates            | 23840        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    std                  | 9.78         |\n",
      "|    value_loss           | 1.87         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.111      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1897        |\n",
      "|    time_elapsed         | 2969        |\n",
      "|    total_timesteps      | 3885056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004355473 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.32       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 23850       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    std                  | 9.8         |\n",
      "|    value_loss           | 0.566       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.6         |\n",
      "|    ep_rew_mean          | 0.833        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1898         |\n",
      "|    time_elapsed         | 2971         |\n",
      "|    total_timesteps      | 3887104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043855254 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.33        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0439       |\n",
      "|    n_updates            | 23860        |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    std                  | 9.81         |\n",
      "|    value_loss           | 0.41         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3888528, episode_reward=3.33 +/- 2.54\n",
      "Episode length: 24.50 +/- 5.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.5        |\n",
      "|    mean_reward          | 3.33        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3888528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006514685 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.33       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00395    |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    std                  | 9.81        |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | -0.127   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1899     |\n",
      "|    time_elapsed    | 2972     |\n",
      "|    total_timesteps | 3889152  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -1.15        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1900         |\n",
      "|    time_elapsed         | 2974         |\n",
      "|    total_timesteps      | 3891200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068245716 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.33        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.103        |\n",
      "|    n_updates            | 23880        |\n",
      "|    policy_gradient_loss | -0.00967     |\n",
      "|    std                  | 9.86         |\n",
      "|    value_loss           | 0.468        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.601      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 2975        |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008132034 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.33       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 23890       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 9.9         |\n",
      "|    value_loss           | 0.534       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.8         |\n",
      "|    ep_rew_mean          | 0.403        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1902         |\n",
      "|    time_elapsed         | 2977         |\n",
      "|    total_timesteps      | 3895296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072458824 |\n",
      "|    clip_fraction        | 0.0672       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.34        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.15         |\n",
      "|    n_updates            | 23900        |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    std                  | 9.99         |\n",
      "|    value_loss           | 0.335        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.403      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1903        |\n",
      "|    time_elapsed         | 2978        |\n",
      "|    total_timesteps      | 3897344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008365765 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.37       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0748     |\n",
      "|    n_updates            | 23910       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 0.0472      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3898528, episode_reward=-1.69 +/- 5.37\n",
      "Episode length: 33.40 +/- 5.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.4        |\n",
      "|    mean_reward          | -1.69       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3898528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010470603 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.36       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 23920       |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 0.49        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.2     |\n",
      "|    ep_rew_mean     | -1.73    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1904     |\n",
      "|    time_elapsed    | 2980     |\n",
      "|    total_timesteps | 3899392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -0.906      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1905        |\n",
      "|    time_elapsed         | 2981        |\n",
      "|    total_timesteps      | 3901440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005381196 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.36       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.403       |\n",
      "|    n_updates            | 23930       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.584       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1906        |\n",
      "|    time_elapsed         | 2983        |\n",
      "|    total_timesteps      | 3903488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006638131 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.36       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.295       |\n",
      "|    n_updates            | 23940       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.513       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1907         |\n",
      "|    time_elapsed         | 2984         |\n",
      "|    total_timesteps      | 3905536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056033363 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.37        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0746       |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.00927     |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 0.458        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.663      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1908        |\n",
      "|    time_elapsed         | 2986        |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006590039 |\n",
      "|    clip_fraction        | 0.0538      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.38       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.325       |\n",
      "|    n_updates            | 23960       |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3908528, episode_reward=1.24 +/- 4.29\n",
      "Episode length: 29.20 +/- 7.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.2        |\n",
      "|    mean_reward          | 1.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3908528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008576938 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.39       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.534       |\n",
      "|    n_updates            | 23970       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | -0.945   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1909     |\n",
      "|    time_elapsed    | 2988     |\n",
      "|    total_timesteps | 3909632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.184      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1910        |\n",
      "|    time_elapsed         | 2989        |\n",
      "|    total_timesteps      | 3911680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004592308 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.39       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.382       |\n",
      "|    n_updates            | 23980       |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.0326      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1911         |\n",
      "|    time_elapsed         | 2991         |\n",
      "|    total_timesteps      | 3913728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058667874 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.39        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.133        |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.00946     |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 0.666        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1912        |\n",
      "|    time_elapsed         | 2992        |\n",
      "|    total_timesteps      | 3915776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006231703 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.37       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 24000       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 0.767       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.286       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1913        |\n",
      "|    time_elapsed         | 2994        |\n",
      "|    total_timesteps      | 3917824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006826422 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.38       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0131      |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3918528, episode_reward=-3.29 +/- 5.32\n",
      "Episode length: 33.80 +/- 7.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.8        |\n",
      "|    mean_reward          | -3.29       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3918528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008052204 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.39       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 24020       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 0.54        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | -0.0821  |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1914     |\n",
      "|    time_elapsed    | 2995     |\n",
      "|    total_timesteps | 3919872  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.421      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1915        |\n",
      "|    time_elapsed         | 2997        |\n",
      "|    total_timesteps      | 3921920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006646091 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.41       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00187    |\n",
      "|    n_updates            | 24030       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 0.391       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.1       |\n",
      "|    ep_rew_mean          | 0.627      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 1916       |\n",
      "|    time_elapsed         | 2998       |\n",
      "|    total_timesteps      | 3923968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00923921 |\n",
      "|    clip_fraction        | 0.0712     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.4       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0389     |\n",
      "|    n_updates            | 24040      |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 10.1       |\n",
      "|    value_loss           | 0.432      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.205       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1917        |\n",
      "|    time_elapsed         | 3000        |\n",
      "|    total_timesteps      | 3926016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008994088 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.37       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0793     |\n",
      "|    n_updates            | 24050       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 10          |\n",
      "|    value_loss           | 0.0475      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.502       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1918         |\n",
      "|    time_elapsed         | 3001         |\n",
      "|    total_timesteps      | 3928064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067857066 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.37        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.112        |\n",
      "|    n_updates            | 24060        |\n",
      "|    policy_gradient_loss | -0.00933     |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 0.381        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3928528, episode_reward=-1.45 +/- 4.95\n",
      "Episode length: 31.50 +/- 7.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.5        |\n",
      "|    mean_reward          | -1.45       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3928528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006528916 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.39       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.242       |\n",
      "|    n_updates            | 24070       |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    std                  | 10.2        |\n",
      "|    value_loss           | 0.78        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.624   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1919     |\n",
      "|    time_elapsed    | 3003     |\n",
      "|    total_timesteps | 3930112  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | 0.0675       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1920         |\n",
      "|    time_elapsed         | 3005         |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053560873 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.39        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.246        |\n",
      "|    n_updates            | 24080        |\n",
      "|    policy_gradient_loss | -0.00801     |\n",
      "|    std                  | 10.1         |\n",
      "|    value_loss           | 0.667        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.446      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1921        |\n",
      "|    time_elapsed         | 3006        |\n",
      "|    total_timesteps      | 3934208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007858352 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.38       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0986      |\n",
      "|    n_updates            | 24090       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 10.1        |\n",
      "|    value_loss           | 0.549       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.7         |\n",
      "|    ep_rew_mean          | 0.404        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1922         |\n",
      "|    time_elapsed         | 3008         |\n",
      "|    total_timesteps      | 3936256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062058945 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.38        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.106        |\n",
      "|    n_updates            | 24100        |\n",
      "|    policy_gradient_loss | -0.0095      |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 0.406        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | 0.144        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1923         |\n",
      "|    time_elapsed         | 3009         |\n",
      "|    total_timesteps      | 3938304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061008213 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.39        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0888       |\n",
      "|    n_updates            | 24110        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 0.515        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3938528, episode_reward=-1.02 +/- 5.66\n",
      "Episode length: 31.10 +/- 7.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.1         |\n",
      "|    mean_reward          | -1.02        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3938528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077529643 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.39        |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.197        |\n",
      "|    n_updates            | 24120        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    std                  | 10.2         |\n",
      "|    value_loss           | 0.76         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.3     |\n",
      "|    ep_rew_mean     | -0.505   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1924     |\n",
      "|    time_elapsed    | 3011     |\n",
      "|    total_timesteps | 3940352  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | -0.0838      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1925         |\n",
      "|    time_elapsed         | 3012         |\n",
      "|    total_timesteps      | 3942400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073056137 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.39        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.304        |\n",
      "|    n_updates            | 24130        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 0.855        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.965       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1926         |\n",
      "|    time_elapsed         | 3014         |\n",
      "|    total_timesteps      | 3944448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070729665 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.4         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0557       |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 0.383        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1927        |\n",
      "|    time_elapsed         | 3015        |\n",
      "|    total_timesteps      | 3946496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009061583 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.41       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.000486   |\n",
      "|    n_updates            | 24150       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3948528, episode_reward=-2.41 +/- 4.65\n",
      "Episode length: 32.90 +/- 6.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.9        |\n",
      "|    mean_reward          | -2.41       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3948528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006068068 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.41       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.205       |\n",
      "|    n_updates            | 24160       |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 0.456       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -1.58    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1928     |\n",
      "|    time_elapsed    | 3017     |\n",
      "|    total_timesteps | 3948544  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33           |\n",
      "|    ep_rew_mean          | -1.15        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1929         |\n",
      "|    time_elapsed         | 3019         |\n",
      "|    total_timesteps      | 3950592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044602007 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.4         |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.656        |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 10.3         |\n",
      "|    value_loss           | 1.11         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.6        |\n",
      "|    ep_rew_mean          | -1.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1930        |\n",
      "|    time_elapsed         | 3020        |\n",
      "|    total_timesteps      | 3952640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007948132 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.4        |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.432       |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.00573    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1931        |\n",
      "|    time_elapsed         | 3022        |\n",
      "|    total_timesteps      | 3954688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007979931 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.4        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.488       |\n",
      "|    n_updates            | 24190       |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | 0.0407       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1932         |\n",
      "|    time_elapsed         | 3023         |\n",
      "|    total_timesteps      | 3956736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045687826 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.41        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.2          |\n",
      "|    n_updates            | 24200        |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 0.882        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3958528, episode_reward=1.55 +/- 4.44\n",
      "Episode length: 26.50 +/- 8.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.5        |\n",
      "|    mean_reward          | 1.55        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3958528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009686663 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.44       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 24210       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 0.521       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.149    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1933     |\n",
      "|    time_elapsed    | 3025     |\n",
      "|    total_timesteps | 3958784  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | -0.103       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1934         |\n",
      "|    time_elapsed         | 3026         |\n",
      "|    total_timesteps      | 3960832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071513653 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.45        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0248       |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 0.247        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.00197    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1935        |\n",
      "|    time_elapsed         | 3028        |\n",
      "|    total_timesteps      | 3962880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008435378 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.45       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0435      |\n",
      "|    n_updates            | 24230       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 0.00551      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1936         |\n",
      "|    time_elapsed         | 3029         |\n",
      "|    total_timesteps      | 3964928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062622586 |\n",
      "|    clip_fraction        | 0.0623       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.48        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0908       |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 0.255        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.5       |\n",
      "|    ep_rew_mean          | -0.23      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 1937       |\n",
      "|    time_elapsed         | 3030       |\n",
      "|    total_timesteps      | 3966976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00863062 |\n",
      "|    clip_fraction        | 0.0703     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.47      |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0357    |\n",
      "|    n_updates            | 24250      |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 10.7       |\n",
      "|    value_loss           | 0.141      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3968528, episode_reward=-1.66 +/- 5.37\n",
      "Episode length: 33.70 +/- 11.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.7        |\n",
      "|    mean_reward          | -1.66       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3968528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008400694 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.44       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0326      |\n",
      "|    n_updates            | 24260       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.929   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1938     |\n",
      "|    time_elapsed    | 3032     |\n",
      "|    total_timesteps | 3969024  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1939         |\n",
      "|    time_elapsed         | 3034         |\n",
      "|    total_timesteps      | 3971072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052505145 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.47        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.382        |\n",
      "|    n_updates            | 24270        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 0.801        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.413      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1940        |\n",
      "|    time_elapsed         | 3035        |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004754808 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.47       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.479       |\n",
      "|    n_updates            | 24280       |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.23       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1941        |\n",
      "|    time_elapsed         | 3037        |\n",
      "|    total_timesteps      | 3975168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011516383 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.47       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0655      |\n",
      "|    n_updates            | 24290       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.176       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1942        |\n",
      "|    time_elapsed         | 3038        |\n",
      "|    total_timesteps      | 3977216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010641277 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.47       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 24300       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.641       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3978528, episode_reward=-2.17 +/- 4.69\n",
      "Episode length: 32.50 +/- 6.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 32.5       |\n",
      "|    mean_reward          | -2.17      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3978528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00715086 |\n",
      "|    clip_fraction        | 0.0582     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.49      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0841     |\n",
      "|    n_updates            | 24310      |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 10.9       |\n",
      "|    value_loss           | 0.514      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.777   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1943     |\n",
      "|    time_elapsed    | 3040     |\n",
      "|    total_timesteps | 3979264  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1944        |\n",
      "|    time_elapsed         | 3041        |\n",
      "|    total_timesteps      | 3981312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004797468 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.5        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.404       |\n",
      "|    n_updates            | 24320       |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.787       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.934      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1945        |\n",
      "|    time_elapsed         | 3043        |\n",
      "|    total_timesteps      | 3983360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007782473 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.48       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 24330       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | -0.241       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1946         |\n",
      "|    time_elapsed         | 3044         |\n",
      "|    total_timesteps      | 3985408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067188065 |\n",
      "|    clip_fraction        | 0.0672       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.47        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0167       |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 0.303        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.521      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1947        |\n",
      "|    time_elapsed         | 3046        |\n",
      "|    total_timesteps      | 3987456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007941323 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.46       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00784     |\n",
      "|    n_updates            | 24350       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3988528, episode_reward=1.17 +/- 5.02\n",
      "Episode length: 27.40 +/- 7.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27.4         |\n",
      "|    mean_reward          | 1.17         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3988528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072485595 |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.46        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.22         |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 0.731        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -0.995   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1948     |\n",
      "|    time_elapsed    | 3048     |\n",
      "|    total_timesteps | 3989504  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -0.641      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1949        |\n",
      "|    time_elapsed         | 3049        |\n",
      "|    total_timesteps      | 3991552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007483433 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.46       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.559       |\n",
      "|    n_updates            | 24370       |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 1.74        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.366       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1950         |\n",
      "|    time_elapsed         | 3051         |\n",
      "|    total_timesteps      | 3993600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047083884 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.46        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0249      |\n",
      "|    n_updates            | 24380        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 0.314        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.714      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1951        |\n",
      "|    time_elapsed         | 3052        |\n",
      "|    total_timesteps      | 3995648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005333414 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.46       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 24390       |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 0.872       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -1.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1952         |\n",
      "|    time_elapsed         | 3054         |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050692568 |\n",
      "|    clip_fraction        | 0.0443       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.45        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.395        |\n",
      "|    n_updates            | 24400        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3998528, episode_reward=0.18 +/- 4.48\n",
      "Episode length: 29.00 +/- 6.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29           |\n",
      "|    mean_reward          | 0.184        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3998528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057886094 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.44        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.194        |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 0.5          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.12     |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1953     |\n",
      "|    time_elapsed    | 3056     |\n",
      "|    total_timesteps | 3999744  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.3         |\n",
      "|    ep_rew_mean          | 0.831        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1954         |\n",
      "|    time_elapsed         | 3057         |\n",
      "|    total_timesteps      | 4001792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059096264 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.43        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0753       |\n",
      "|    n_updates            | 24420        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 0.381        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.155      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1955        |\n",
      "|    time_elapsed         | 3059        |\n",
      "|    total_timesteps      | 4003840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007020748 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.44       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0917      |\n",
      "|    n_updates            | 24430       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 0.356       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.628       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1956        |\n",
      "|    time_elapsed         | 3060        |\n",
      "|    total_timesteps      | 4005888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007175004 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.46       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0685      |\n",
      "|    n_updates            | 24440       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.389      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 3062        |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005116823 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.44       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 24450       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 0.618       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4008528, episode_reward=-1.19 +/- 5.87\n",
      "Episode length: 30.40 +/- 8.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.4        |\n",
      "|    mean_reward          | -1.19       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4008528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009374773 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.43       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 24460       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 0.715       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -1.26    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1958     |\n",
      "|    time_elapsed    | 3063     |\n",
      "|    total_timesteps | 4009984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34          |\n",
      "|    ep_rew_mean          | -1.98       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1959        |\n",
      "|    time_elapsed         | 3065        |\n",
      "|    total_timesteps      | 4012032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008557731 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.43       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.484       |\n",
      "|    n_updates            | 24470       |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.1         |\n",
      "|    ep_rew_mean          | -0.966       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1960         |\n",
      "|    time_elapsed         | 3066         |\n",
      "|    total_timesteps      | 4014080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057323948 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.43        |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.449        |\n",
      "|    n_updates            | 24480        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.116       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1961         |\n",
      "|    time_elapsed         | 3068         |\n",
      "|    total_timesteps      | 4016128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048024775 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.42        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.265        |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 1.03         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1962        |\n",
      "|    time_elapsed         | 3070        |\n",
      "|    total_timesteps      | 4018176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006421664 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.41       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0473     |\n",
      "|    n_updates            | 24500       |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4018528, episode_reward=1.53 +/- 3.39\n",
      "Episode length: 27.80 +/- 4.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.8        |\n",
      "|    mean_reward          | 1.53        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4018528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010877491 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.4        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 24510       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 0.601       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.91    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1963     |\n",
      "|    time_elapsed    | 3071     |\n",
      "|    total_timesteps | 4020224  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | -0.259       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1964         |\n",
      "|    time_elapsed         | 3073         |\n",
      "|    total_timesteps      | 4022272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058356314 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.43        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.517        |\n",
      "|    n_updates            | 24520        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 1.19         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.174      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1965        |\n",
      "|    time_elapsed         | 3074        |\n",
      "|    total_timesteps      | 4024320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010202056 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.45       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0203      |\n",
      "|    n_updates            | 24530       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 0.413       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.43       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1966        |\n",
      "|    time_elapsed         | 3076        |\n",
      "|    total_timesteps      | 4026368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011858791 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.46       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 24540       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 0.613       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | -0.0222      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1967         |\n",
      "|    time_elapsed         | 3077         |\n",
      "|    total_timesteps      | 4028416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074762823 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.44        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0263      |\n",
      "|    n_updates            | 24550        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 10.4         |\n",
      "|    value_loss           | 0.248        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4028528, episode_reward=0.22 +/- 4.15\n",
      "Episode length: 30.30 +/- 6.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.3        |\n",
      "|    mean_reward          | 0.219       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4028528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010151484 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.44       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0697     |\n",
      "|    n_updates            | 24560       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 10.3        |\n",
      "|    value_loss           | 0.0825      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28       |\n",
      "|    ep_rew_mean     | 1.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1968     |\n",
      "|    time_elapsed    | 3079     |\n",
      "|    total_timesteps | 4030464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | -0.0272     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1969        |\n",
      "|    time_elapsed         | 3080        |\n",
      "|    total_timesteps      | 4032512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008831286 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.44       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 24570       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 10.4        |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.5       |\n",
      "|    ep_rew_mean          | 0.0204     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 1970       |\n",
      "|    time_elapsed         | 3082       |\n",
      "|    total_timesteps      | 4034560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00825794 |\n",
      "|    clip_fraction        | 0.0777     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.47      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0663     |\n",
      "|    n_updates            | 24580      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 10.6       |\n",
      "|    value_loss           | 0.326      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.6         |\n",
      "|    ep_rew_mean          | -0.445       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1971         |\n",
      "|    time_elapsed         | 3083         |\n",
      "|    total_timesteps      | 4036608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078000664 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.5         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.125        |\n",
      "|    n_updates            | 24590        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 0.385        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4038528, episode_reward=1.09 +/- 3.89\n",
      "Episode length: 27.40 +/- 5.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.4        |\n",
      "|    mean_reward          | 1.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4038528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006817273 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.49       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.508       |\n",
      "|    n_updates            | 24600       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 10.5        |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.891   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1972     |\n",
      "|    time_elapsed    | 3085     |\n",
      "|    total_timesteps | 4038656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.758      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1973        |\n",
      "|    time_elapsed         | 3087        |\n",
      "|    total_timesteps      | 4040704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008061003 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.48       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.614       |\n",
      "|    n_updates            | 24610       |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | 0.184        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 1974         |\n",
      "|    time_elapsed         | 3088         |\n",
      "|    total_timesteps      | 4042752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056318995 |\n",
      "|    clip_fraction        | 0.0531       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.5         |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.337        |\n",
      "|    n_updates            | 24620        |\n",
      "|    policy_gradient_loss | -0.00962     |\n",
      "|    std                  | 10.6         |\n",
      "|    value_loss           | 0.865        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.0368     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1975        |\n",
      "|    time_elapsed         | 3090        |\n",
      "|    total_timesteps      | 4044800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498205 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.51       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.351       |\n",
      "|    n_updates            | 24630       |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 0.913       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | -0.528       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1976         |\n",
      "|    time_elapsed         | 3091         |\n",
      "|    total_timesteps      | 4046848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065752612 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.51        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    std                  | 10.7         |\n",
      "|    value_loss           | 0.533        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4048528, episode_reward=-1.83 +/- 5.43\n",
      "Episode length: 31.90 +/- 8.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.9        |\n",
      "|    mean_reward          | -1.83       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4048528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008182864 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.51       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0693     |\n",
      "|    n_updates            | 24650       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 0.0874      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.216   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 1977     |\n",
      "|    time_elapsed    | 3093     |\n",
      "|    total_timesteps | 4048896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.131       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 1978        |\n",
      "|    time_elapsed         | 3094        |\n",
      "|    total_timesteps      | 4050944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008586365 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.5        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.324       |\n",
      "|    n_updates            | 24660       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.344       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1979         |\n",
      "|    time_elapsed         | 3096         |\n",
      "|    total_timesteps      | 4052992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050629238 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.51        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.159        |\n",
      "|    n_updates            | 24670        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 0.507        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.527      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1980        |\n",
      "|    time_elapsed         | 3097        |\n",
      "|    total_timesteps      | 4055040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005197581 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.51       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00751    |\n",
      "|    n_updates            | 24680       |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.349       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.254      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 3099        |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007534177 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.52       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.199       |\n",
      "|    n_updates            | 24690       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 10.9        |\n",
      "|    value_loss           | 0.759       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4058528, episode_reward=0.52 +/- 3.97\n",
      "Episode length: 29.10 +/- 6.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.1        |\n",
      "|    mean_reward          | 0.521       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4058528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007079147 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.53       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 24700       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.491       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -0.886   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1982     |\n",
      "|    time_elapsed    | 3100     |\n",
      "|    total_timesteps | 4059136  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | -0.214      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1983        |\n",
      "|    time_elapsed         | 3102        |\n",
      "|    total_timesteps      | 4061184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011824472 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.53       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.447       |\n",
      "|    n_updates            | 24710       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.997       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | -0.465       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1984         |\n",
      "|    time_elapsed         | 3103         |\n",
      "|    total_timesteps      | 4063232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073562106 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.54        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0908       |\n",
      "|    n_updates            | 24720        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 0.803        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.115      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1985        |\n",
      "|    time_elapsed         | 3105        |\n",
      "|    total_timesteps      | 4065280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006093197 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.55       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0311     |\n",
      "|    n_updates            | 24730       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.399      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1986        |\n",
      "|    time_elapsed         | 3106        |\n",
      "|    total_timesteps      | 4067328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008340318 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.56       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0233      |\n",
      "|    n_updates            | 24740       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 11          |\n",
      "|    value_loss           | 0.429       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4068528, episode_reward=0.97 +/- 4.97\n",
      "Episode length: 30.10 +/- 9.73\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30.1       |\n",
      "|    mean_reward          | 0.974      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4068528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00869365 |\n",
      "|    clip_fraction        | 0.054      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.57      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0114     |\n",
      "|    n_updates            | 24750      |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    std                  | 11         |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.457   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1987     |\n",
      "|    time_elapsed    | 3108     |\n",
      "|    total_timesteps | 4069376  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.8       |\n",
      "|    ep_rew_mean          | -0.847     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 1988       |\n",
      "|    time_elapsed         | 3110       |\n",
      "|    total_timesteps      | 4071424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01070899 |\n",
      "|    clip_fraction        | 0.099      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.57      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.148      |\n",
      "|    n_updates            | 24760      |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    std                  | 11         |\n",
      "|    value_loss           | 0.6        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.682      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1989        |\n",
      "|    time_elapsed         | 3111        |\n",
      "|    total_timesteps      | 4073472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006858089 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.56       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0103     |\n",
      "|    n_updates            | 24770       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | -1.75       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1990        |\n",
      "|    time_elapsed         | 3113        |\n",
      "|    total_timesteps      | 4075520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015702955 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.52       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 24780       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.849      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 3114        |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010820175 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.52       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 24790       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 0.652       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4078528, episode_reward=1.50 +/- 4.37\n",
      "Episode length: 29.00 +/- 7.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 1.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4078528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005202059 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.54       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.339       |\n",
      "|    n_updates            | 24800       |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.93        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -0.301   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1992     |\n",
      "|    time_elapsed    | 3116     |\n",
      "|    total_timesteps | 4079616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -0.148      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1993        |\n",
      "|    time_elapsed         | 3117        |\n",
      "|    total_timesteps      | 4081664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008559526 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.53       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 24810       |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    std                  | 10.6        |\n",
      "|    value_loss           | 0.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.438      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 3119        |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010643575 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.52       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 24820       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 10.7        |\n",
      "|    value_loss           | 0.555       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.4         |\n",
      "|    ep_rew_mean          | 0.19         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1995         |\n",
      "|    time_elapsed         | 3120         |\n",
      "|    total_timesteps      | 4085760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076293973 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.54        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0933       |\n",
      "|    n_updates            | 24830        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 10.8         |\n",
      "|    value_loss           | 0.656        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.737      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1996        |\n",
      "|    time_elapsed         | 3122        |\n",
      "|    total_timesteps      | 4087808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011028387 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.55       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 24840       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 10.8        |\n",
      "|    value_loss           | 0.303       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4088528, episode_reward=0.17 +/- 4.88\n",
      "Episode length: 29.00 +/- 8.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29           |\n",
      "|    mean_reward          | 0.168        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4088528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063647353 |\n",
      "|    clip_fraction        | 0.0544       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.54        |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.286        |\n",
      "|    n_updates            | 24850        |\n",
      "|    policy_gradient_loss | -0.00886     |\n",
      "|    std                  | 10.9         |\n",
      "|    value_loss           | 0.85         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.367   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 1997     |\n",
      "|    time_elapsed    | 3123     |\n",
      "|    total_timesteps | 4089856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.262       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 1998        |\n",
      "|    time_elapsed         | 3125        |\n",
      "|    total_timesteps      | 4091904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009360975 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.58       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0652      |\n",
      "|    n_updates            | 24860       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 0.414       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29           |\n",
      "|    ep_rew_mean          | 0.791        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 1999         |\n",
      "|    time_elapsed         | 3126         |\n",
      "|    total_timesteps      | 4093952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069552064 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.59        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.035       |\n",
      "|    n_updates            | 24870        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 11           |\n",
      "|    value_loss           | 0.141        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.772       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2000         |\n",
      "|    time_elapsed         | 3128         |\n",
      "|    total_timesteps      | 4096000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076239314 |\n",
      "|    clip_fraction        | 0.0874       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.58        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0452       |\n",
      "|    n_updates            | 24880        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 11.1         |\n",
      "|    value_loss           | 0.383        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.43       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2001        |\n",
      "|    time_elapsed         | 3129        |\n",
      "|    total_timesteps      | 4098048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009982018 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.6        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 24890       |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    std                  | 11.1        |\n",
      "|    value_loss           | 0.822       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4098528, episode_reward=-1.21 +/- 4.73\n",
      "Episode length: 31.80 +/- 5.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.8        |\n",
      "|    mean_reward          | -1.21       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4098528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007436668 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.6        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.363       |\n",
      "|    n_updates            | 24900       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 0.787       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -1.37    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2002     |\n",
      "|    time_elapsed    | 3131     |\n",
      "|    total_timesteps | 4100096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.39       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2003        |\n",
      "|    time_elapsed         | 3133        |\n",
      "|    total_timesteps      | 4102144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009684831 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.62       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 24910       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 11.2        |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.6       |\n",
      "|    ep_rew_mean          | -0.968     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 2004       |\n",
      "|    time_elapsed         | 3134       |\n",
      "|    total_timesteps      | 4104192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00828921 |\n",
      "|    clip_fraction        | 0.0707     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.62      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.219      |\n",
      "|    n_updates            | 24920      |\n",
      "|    policy_gradient_loss | -0.00937   |\n",
      "|    std                  | 11.2       |\n",
      "|    value_loss           | 0.669      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 0.0981       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2005         |\n",
      "|    time_elapsed         | 3136         |\n",
      "|    total_timesteps      | 4106240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063376725 |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.63        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0512       |\n",
      "|    n_updates            | 24930        |\n",
      "|    policy_gradient_loss | -0.0084      |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 0.45         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33           |\n",
      "|    ep_rew_mean          | -1.21        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2006         |\n",
      "|    time_elapsed         | 3137         |\n",
      "|    total_timesteps      | 4108288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041470258 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.64        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.212        |\n",
      "|    n_updates            | 24940        |\n",
      "|    policy_gradient_loss | -0.00873     |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 0.804        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4108528, episode_reward=-3.70 +/- 6.19\n",
      "Episode length: 34.50 +/- 7.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 34.5         |\n",
      "|    mean_reward          | -3.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4108528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055324254 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.64        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.295        |\n",
      "|    n_updates            | 24950        |\n",
      "|    policy_gradient_loss | -0.00946     |\n",
      "|    std                  | 11.3         |\n",
      "|    value_loss           | 0.827        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.627   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2007     |\n",
      "|    time_elapsed    | 3139     |\n",
      "|    total_timesteps | 4110336  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.296        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2008         |\n",
      "|    time_elapsed         | 3140         |\n",
      "|    total_timesteps      | 4112384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063400413 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.65        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.124        |\n",
      "|    n_updates            | 24960        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 0.584        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.321       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 3142         |\n",
      "|    total_timesteps      | 4114432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062911436 |\n",
      "|    clip_fraction        | 0.0552       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.67        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0755       |\n",
      "|    n_updates            | 24970        |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    std                  | 11.4         |\n",
      "|    value_loss           | 0.525        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -1.36        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2010         |\n",
      "|    time_elapsed         | 3143         |\n",
      "|    total_timesteps      | 4116480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050721983 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.67        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.288        |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.00873     |\n",
      "|    std                  | 11.5         |\n",
      "|    value_loss           | 0.68         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4118528, episode_reward=2.06 +/- 4.16\n",
      "Episode length: 25.50 +/- 8.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25.5         |\n",
      "|    mean_reward          | 2.06         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4118528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048377947 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.69        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.297        |\n",
      "|    n_updates            | 24990        |\n",
      "|    policy_gradient_loss | -0.00971     |\n",
      "|    std                  | 11.6         |\n",
      "|    value_loss           | 0.852        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -1.28    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2011     |\n",
      "|    time_elapsed    | 3145     |\n",
      "|    total_timesteps | 4118528  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.557        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2012         |\n",
      "|    time_elapsed         | 3146         |\n",
      "|    total_timesteps      | 4120576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091100065 |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.71        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0161       |\n",
      "|    n_updates            | 25000        |\n",
      "|    policy_gradient_loss | -0.0098      |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 0.299        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.145       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2013         |\n",
      "|    time_elapsed         | 3148         |\n",
      "|    total_timesteps      | 4122624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069753397 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.72        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.234        |\n",
      "|    n_updates            | 25010        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 0.549        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.3       |\n",
      "|    ep_rew_mean          | -0.865     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 2014       |\n",
      "|    time_elapsed         | 3150       |\n",
      "|    total_timesteps      | 4124672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00628172 |\n",
      "|    clip_fraction        | 0.0515     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.74      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.145      |\n",
      "|    n_updates            | 25020      |\n",
      "|    policy_gradient_loss | -0.00822   |\n",
      "|    std                  | 11.9       |\n",
      "|    value_loss           | 0.668      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.615      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2015        |\n",
      "|    time_elapsed         | 3151        |\n",
      "|    total_timesteps      | 4126720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014287099 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.74       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.385       |\n",
      "|    n_updates            | 25030       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4128528, episode_reward=-0.82 +/- 4.57\n",
      "Episode length: 29.20 +/- 7.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.2         |\n",
      "|    mean_reward          | -0.817       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4128528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054915054 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.74        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.00478     |\n",
      "|    n_updates            | 25040        |\n",
      "|    policy_gradient_loss | -0.00866     |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 0.309        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.1     |\n",
      "|    ep_rew_mean     | 0.108    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2016     |\n",
      "|    time_elapsed    | 3153     |\n",
      "|    total_timesteps | 4128768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.00134    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2017        |\n",
      "|    time_elapsed         | 3154        |\n",
      "|    total_timesteps      | 4130816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008959359 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.71       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0557     |\n",
      "|    n_updates            | 25050       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 11.5        |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.543      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2018        |\n",
      "|    time_elapsed         | 3156        |\n",
      "|    total_timesteps      | 4132864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007224831 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.68       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 25060       |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.221      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2019        |\n",
      "|    time_elapsed         | 3157        |\n",
      "|    total_timesteps      | 4134912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008420034 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.69       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0853      |\n",
      "|    n_updates            | 25070       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.462       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 3158         |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073730987 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.7         |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0636       |\n",
      "|    n_updates            | 25080        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 11.7         |\n",
      "|    value_loss           | 0.415        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4138528, episode_reward=0.06 +/- 5.43\n",
      "Episode length: 29.00 +/- 8.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 0.0571      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4138528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007067879 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.71       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.305       |\n",
      "|    n_updates            | 25090       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 11.7        |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.139   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2021     |\n",
      "|    time_elapsed    | 3160     |\n",
      "|    total_timesteps | 4139008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.135      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2022        |\n",
      "|    time_elapsed         | 3162        |\n",
      "|    total_timesteps      | 4141056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004660993 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.7        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 25100       |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 0.507       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.34       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2023        |\n",
      "|    time_elapsed         | 3163        |\n",
      "|    total_timesteps      | 4143104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006643623 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.7        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 25110       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 11.6        |\n",
      "|    value_loss           | 0.411       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2024         |\n",
      "|    time_elapsed         | 3165         |\n",
      "|    total_timesteps      | 4145152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070236297 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.7         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.225        |\n",
      "|    n_updates            | 25120        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 0.571        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.5         |\n",
      "|    ep_rew_mean          | -0.199       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2025         |\n",
      "|    time_elapsed         | 3166         |\n",
      "|    total_timesteps      | 4147200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035761618 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.74        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.249        |\n",
      "|    n_updates            | 25130        |\n",
      "|    policy_gradient_loss | -0.00821     |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 0.973        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4148528, episode_reward=-1.31 +/- 5.10\n",
      "Episode length: 30.40 +/- 7.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.4         |\n",
      "|    mean_reward          | -1.31        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4148528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069331317 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.75        |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.112        |\n",
      "|    n_updates            | 25140        |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 0.543        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.341    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2026     |\n",
      "|    time_elapsed    | 3168     |\n",
      "|    total_timesteps | 4149248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.373      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2027        |\n",
      "|    time_elapsed         | 3169        |\n",
      "|    total_timesteps      | 4151296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009871734 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.76       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.288       |\n",
      "|    n_updates            | 25150       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 0.998       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | -0.14        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2028         |\n",
      "|    time_elapsed         | 3171         |\n",
      "|    total_timesteps      | 4153344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071308264 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.76        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.00575      |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.00779     |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 0.282        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.115      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2029        |\n",
      "|    time_elapsed         | 3172        |\n",
      "|    total_timesteps      | 4155392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008178048 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.76       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 25170       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 0.596       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -1.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2030        |\n",
      "|    time_elapsed         | 3174        |\n",
      "|    total_timesteps      | 4157440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004637751 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.78       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 25180       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 12.1        |\n",
      "|    value_loss           | 0.667       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4158528, episode_reward=-1.33 +/- 5.64\n",
      "Episode length: 29.80 +/- 10.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.8         |\n",
      "|    mean_reward          | -1.33        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4158528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048657428 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.78        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.144        |\n",
      "|    n_updates            | 25190        |\n",
      "|    policy_gradient_loss | -0.00979     |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 0.494        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -1.29    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2031     |\n",
      "|    time_elapsed    | 3175     |\n",
      "|    total_timesteps | 4159488  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.465       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2032         |\n",
      "|    time_elapsed         | 3177         |\n",
      "|    total_timesteps      | 4161536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068744393 |\n",
      "|    clip_fraction        | 0.0623       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.77        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0937       |\n",
      "|    n_updates            | 25200        |\n",
      "|    policy_gradient_loss | -0.00997     |\n",
      "|    std                  | 12           |\n",
      "|    value_loss           | 0.602        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.936       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2033        |\n",
      "|    time_elapsed         | 3179        |\n",
      "|    total_timesteps      | 4163584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008963694 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.77       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 25210       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 0.678       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.423       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2034        |\n",
      "|    time_elapsed         | 3180        |\n",
      "|    total_timesteps      | 4165632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013365436 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.77       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0487     |\n",
      "|    n_updates            | 25220       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.733       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2035        |\n",
      "|    time_elapsed         | 3182        |\n",
      "|    total_timesteps      | 4167680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008808413 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.76       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0578      |\n",
      "|    n_updates            | 25230       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4168528, episode_reward=2.53 +/- 4.22\n",
      "Episode length: 25.60 +/- 9.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25.6         |\n",
      "|    mean_reward          | 2.53         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4168528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055743568 |\n",
      "|    clip_fraction        | 0.0671       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.75        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.255        |\n",
      "|    n_updates            | 25240        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 11.9         |\n",
      "|    value_loss           | 0.653        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -0.887   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2036     |\n",
      "|    time_elapsed    | 3183     |\n",
      "|    total_timesteps | 4169728  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2037        |\n",
      "|    time_elapsed         | 3185        |\n",
      "|    total_timesteps      | 4171776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009785488 |\n",
      "|    clip_fraction        | 0.0745      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.76       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.581       |\n",
      "|    n_updates            | 25250       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 11.9        |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.806       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2038         |\n",
      "|    time_elapsed         | 3187         |\n",
      "|    total_timesteps      | 4173824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064427494 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.75        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.026        |\n",
      "|    n_updates            | 25260        |\n",
      "|    policy_gradient_loss | -0.00985     |\n",
      "|    std                  | 11.8         |\n",
      "|    value_loss           | 0.48         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.548      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2039        |\n",
      "|    time_elapsed         | 3188        |\n",
      "|    total_timesteps      | 4175872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006921869 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.74       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.409       |\n",
      "|    n_updates            | 25270       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 0.943       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | -0.00859    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2040        |\n",
      "|    time_elapsed         | 3190        |\n",
      "|    total_timesteps      | 4177920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007478121 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.74       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0679      |\n",
      "|    n_updates            | 25280       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    std                  | 11.8        |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4178528, episode_reward=1.15 +/- 3.92\n",
      "Episode length: 27.20 +/- 5.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.2        |\n",
      "|    mean_reward          | 1.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4178528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008014774 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.75       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0385     |\n",
      "|    n_updates            | 25290       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 12          |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.942   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2041     |\n",
      "|    time_elapsed    | 3191     |\n",
      "|    total_timesteps | 4179968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.181      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2042        |\n",
      "|    time_elapsed         | 3193        |\n",
      "|    total_timesteps      | 4182016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005361215 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.79       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 25300       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 0.481       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.7         |\n",
      "|    ep_rew_mean          | 0.66         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2043         |\n",
      "|    time_elapsed         | 3194         |\n",
      "|    total_timesteps      | 4184064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059268763 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.8         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.266        |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    std                  | 12.2         |\n",
      "|    value_loss           | 0.854        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.7       |\n",
      "|    ep_rew_mean          | -0.405     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 2044       |\n",
      "|    time_elapsed         | 3196       |\n",
      "|    total_timesteps      | 4186112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00705156 |\n",
      "|    clip_fraction        | 0.0508     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.81      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0462     |\n",
      "|    n_updates            | 25320      |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    std                  | 12.2       |\n",
      "|    value_loss           | 0.381      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -1.48       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2045        |\n",
      "|    time_elapsed         | 3197        |\n",
      "|    total_timesteps      | 4188160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008873228 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.82       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.000108    |\n",
      "|    n_updates            | 25330       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 12.2        |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4188528, episode_reward=0.24 +/- 5.89\n",
      "Episode length: 28.20 +/- 9.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.2        |\n",
      "|    mean_reward          | 0.236       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4188528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008821617 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.82       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 25340       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 12.4        |\n",
      "|    value_loss           | 0.584       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | -0.251   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2046     |\n",
      "|    time_elapsed    | 3199     |\n",
      "|    total_timesteps | 4190208  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.048       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2047        |\n",
      "|    time_elapsed         | 3200        |\n",
      "|    total_timesteps      | 4192256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008765326 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.86       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0337     |\n",
      "|    n_updates            | 25350       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 12.7        |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.0177     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2048        |\n",
      "|    time_elapsed         | 3202        |\n",
      "|    total_timesteps      | 4194304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005869842 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.9        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00944    |\n",
      "|    n_updates            | 25360       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 12.9        |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.235      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2049        |\n",
      "|    time_elapsed         | 3203        |\n",
      "|    total_timesteps      | 4196352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011661153 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.91       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 25370       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 12.8        |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.103       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2050        |\n",
      "|    time_elapsed         | 3205        |\n",
      "|    total_timesteps      | 4198400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006514242 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.91       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 25380       |\n",
      "|    policy_gradient_loss | -0.00979    |\n",
      "|    std                  | 13          |\n",
      "|    value_loss           | 0.438       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4198528, episode_reward=4.45 +/- 3.85\n",
      "Episode length: 23.70 +/- 6.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 23.7        |\n",
      "|    mean_reward          | 4.45        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4198528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005135463 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.95       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.036       |\n",
      "|    n_updates            | 25390       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    std                  | 13.2        |\n",
      "|    value_loss           | 0.407       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.344    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2051     |\n",
      "|    time_elapsed    | 3206     |\n",
      "|    total_timesteps | 4200448  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -1.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2052        |\n",
      "|    time_elapsed         | 3208        |\n",
      "|    total_timesteps      | 4202496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004317234 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.96       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 25400       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    std                  | 13.3        |\n",
      "|    value_loss           | 0.825       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.579       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2053         |\n",
      "|    time_elapsed         | 3210         |\n",
      "|    total_timesteps      | 4204544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040950375 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.98        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.103        |\n",
      "|    n_updates            | 25410        |\n",
      "|    policy_gradient_loss | -0.00832     |\n",
      "|    std                  | 13.2         |\n",
      "|    value_loss           | 0.385        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.327       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2054        |\n",
      "|    time_elapsed         | 3211        |\n",
      "|    total_timesteps      | 4206592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007255031 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.98       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0447      |\n",
      "|    n_updates            | 25420       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    std                  | 13.4        |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4208528, episode_reward=-1.74 +/- 5.06\n",
      "Episode length: 32.60 +/- 6.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.6        |\n",
      "|    mean_reward          | -1.74       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4208528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006671832 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.01       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0216      |\n",
      "|    n_updates            | 25430       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | 0.114    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2055     |\n",
      "|    time_elapsed    | 3213     |\n",
      "|    total_timesteps | 4208640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.916      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2056        |\n",
      "|    time_elapsed         | 3214        |\n",
      "|    total_timesteps      | 4210688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007273669 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.03       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.391       |\n",
      "|    n_updates            | 25440       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.297       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2057        |\n",
      "|    time_elapsed         | 3216        |\n",
      "|    total_timesteps      | 4212736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006711705 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0569     |\n",
      "|    n_updates            | 25450       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -0.623      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2058        |\n",
      "|    time_elapsed         | 3217        |\n",
      "|    total_timesteps      | 4214784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009971904 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.03       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00792     |\n",
      "|    n_updates            | 25460       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34           |\n",
      "|    ep_rew_mean          | -1.24        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2059         |\n",
      "|    time_elapsed         | 3219         |\n",
      "|    total_timesteps      | 4216832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070301536 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.04        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.272        |\n",
      "|    n_updates            | 25470        |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 0.687        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4218528, episode_reward=2.74 +/- 4.20\n",
      "Episode length: 26.40 +/- 5.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.4        |\n",
      "|    mean_reward          | 2.74        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4218528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004655969 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.05       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.401       |\n",
      "|    n_updates            | 25480       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.473   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2060     |\n",
      "|    time_elapsed    | 3220     |\n",
      "|    total_timesteps | 4218880  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.5       |\n",
      "|    ep_rew_mean          | 1.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 2061       |\n",
      "|    time_elapsed         | 3222       |\n",
      "|    total_timesteps      | 4220928    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00830655 |\n",
      "|    clip_fraction        | 0.0601     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.04      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.108      |\n",
      "|    n_updates            | 25490      |\n",
      "|    policy_gradient_loss | -0.0082    |\n",
      "|    std                  | 13.8       |\n",
      "|    value_loss           | 0.49       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 0.779       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2062        |\n",
      "|    time_elapsed         | 3223        |\n",
      "|    total_timesteps      | 4222976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008702774 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.05       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0935     |\n",
      "|    n_updates            | 25500       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 0.0474      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.9        |\n",
      "|    ep_rew_mean          | 0.698       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2063        |\n",
      "|    time_elapsed         | 3225        |\n",
      "|    total_timesteps      | 4225024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005029434 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.279       |\n",
      "|    n_updates            | 25510       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 0.804       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.659      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2064        |\n",
      "|    time_elapsed         | 3226        |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004269721 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 25520       |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 0.511       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4228528, episode_reward=-2.29 +/- 4.95\n",
      "Episode length: 32.80 +/- 6.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -2.29       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4228528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007106264 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.03       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0829      |\n",
      "|    n_updates            | 25530       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 13.6        |\n",
      "|    value_loss           | 0.487       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -0.0862  |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2065     |\n",
      "|    time_elapsed    | 3228     |\n",
      "|    total_timesteps | 4229120  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.0991      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2066         |\n",
      "|    time_elapsed         | 3230         |\n",
      "|    total_timesteps      | 4231168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072250683 |\n",
      "|    clip_fraction        | 0.0558       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.02        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.168        |\n",
      "|    n_updates            | 25540        |\n",
      "|    policy_gradient_loss | -0.00916     |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 0.706        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.714      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2067        |\n",
      "|    time_elapsed         | 3231        |\n",
      "|    total_timesteps      | 4233216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004469296 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.03       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 25550       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 0.518       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.546      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2068        |\n",
      "|    time_elapsed         | 3233        |\n",
      "|    total_timesteps      | 4235264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005856313 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 25560       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 0.389       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.364      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2069        |\n",
      "|    time_elapsed         | 3234        |\n",
      "|    total_timesteps      | 4237312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008851373 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.05       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.354       |\n",
      "|    n_updates            | 25570       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4238528, episode_reward=-1.15 +/- 5.61\n",
      "Episode length: 30.20 +/- 9.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.2        |\n",
      "|    mean_reward          | -1.15       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4238528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007727134 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0189      |\n",
      "|    n_updates            | 25580       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 0.235       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.661   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2070     |\n",
      "|    time_elapsed    | 3236     |\n",
      "|    total_timesteps | 4239360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.102      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2071        |\n",
      "|    time_elapsed         | 3238        |\n",
      "|    total_timesteps      | 4241408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007058253 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.03       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 25590       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    std                  | 13.5        |\n",
      "|    value_loss           | 0.396       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 0.201        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2072         |\n",
      "|    time_elapsed         | 3239         |\n",
      "|    total_timesteps      | 4243456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076808827 |\n",
      "|    clip_fraction        | 0.0664       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.03        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.288        |\n",
      "|    n_updates            | 25600        |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    std                  | 13.6         |\n",
      "|    value_loss           | 0.679        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.257      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2073        |\n",
      "|    time_elapsed         | 3241        |\n",
      "|    total_timesteps      | 4245504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007967247 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.05       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 25610       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -0.764      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2074        |\n",
      "|    time_elapsed         | 3243        |\n",
      "|    total_timesteps      | 4247552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004357282 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.07       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 25620       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 0.701       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4248528, episode_reward=0.77 +/- 6.14\n",
      "Episode length: 27.70 +/- 11.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27.7         |\n",
      "|    mean_reward          | 0.771        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4248528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057982462 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.08        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.335        |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.00875     |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 0.815        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.8     |\n",
      "|    ep_rew_mean     | -1.13    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2075     |\n",
      "|    time_elapsed    | 3245     |\n",
      "|    total_timesteps | 4249600  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.622      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2076        |\n",
      "|    time_elapsed         | 3246        |\n",
      "|    total_timesteps      | 4251648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007969371 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0815      |\n",
      "|    n_updates            | 25640       |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 0.461       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.818      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2077        |\n",
      "|    time_elapsed         | 3248        |\n",
      "|    total_timesteps      | 4253696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004813592 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.08       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0638      |\n",
      "|    n_updates            | 25650       |\n",
      "|    policy_gradient_loss | -0.00775    |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 0.4         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | -0.315       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2078         |\n",
      "|    time_elapsed         | 3249         |\n",
      "|    total_timesteps      | 4255744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062760916 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.06        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0865      |\n",
      "|    n_updates            | 25660        |\n",
      "|    policy_gradient_loss | -0.00762     |\n",
      "|    std                  | 13.7         |\n",
      "|    value_loss           | 0.064        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.267      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2079        |\n",
      "|    time_elapsed         | 3250        |\n",
      "|    total_timesteps      | 4257792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005595874 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.06       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.159       |\n",
      "|    n_updates            | 25670       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 0.449       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4258528, episode_reward=1.05 +/- 5.37\n",
      "Episode length: 28.00 +/- 8.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28           |\n",
      "|    mean_reward          | 1.05         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4258528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055278186 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.08        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.146        |\n",
      "|    n_updates            | 25680        |\n",
      "|    policy_gradient_loss | -0.00844     |\n",
      "|    std                  | 13.8         |\n",
      "|    value_loss           | 0.376        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.1     |\n",
      "|    ep_rew_mean     | -0.79    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2080     |\n",
      "|    time_elapsed    | 3252     |\n",
      "|    total_timesteps | 4259840  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | -0.915       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2081         |\n",
      "|    time_elapsed         | 3254         |\n",
      "|    total_timesteps      | 4261888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053977985 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.09        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.805        |\n",
      "|    n_updates            | 25690        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 1.36         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.8        |\n",
      "|    ep_rew_mean          | -1.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2082        |\n",
      "|    time_elapsed         | 3255        |\n",
      "|    total_timesteps      | 4263936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004601032 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.11       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 25700       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 0.746       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.378       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2083        |\n",
      "|    time_elapsed         | 3257        |\n",
      "|    total_timesteps      | 4265984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005303368 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.11       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0717     |\n",
      "|    n_updates            | 25710       |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 0.092       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.0342     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2084        |\n",
      "|    time_elapsed         | 3258        |\n",
      "|    total_timesteps      | 4268032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008964077 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.08       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0902     |\n",
      "|    n_updates            | 25720       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4268528, episode_reward=-2.02 +/- 5.00\n",
      "Episode length: 32.70 +/- 7.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.7         |\n",
      "|    mean_reward          | -2.02        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4268528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075413096 |\n",
      "|    clip_fraction        | 0.0665       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.09        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0974       |\n",
      "|    n_updates            | 25730        |\n",
      "|    policy_gradient_loss | -0.0098      |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 0.345        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.108   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2085     |\n",
      "|    time_elapsed    | 3260     |\n",
      "|    total_timesteps | 4270080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.145      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2086        |\n",
      "|    time_elapsed         | 3261        |\n",
      "|    total_timesteps      | 4272128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007832281 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.11       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0344      |\n",
      "|    n_updates            | 25740       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 14.1        |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.471      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2087        |\n",
      "|    time_elapsed         | 3263        |\n",
      "|    total_timesteps      | 4274176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007321515 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.11       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 25750       |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.259      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2088        |\n",
      "|    time_elapsed         | 3264        |\n",
      "|    total_timesteps      | 4276224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008540312 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0535     |\n",
      "|    n_updates            | 25760       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2089        |\n",
      "|    time_elapsed         | 3266        |\n",
      "|    total_timesteps      | 4278272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008951968 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 25770       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 0.615       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4278528, episode_reward=-2.23 +/- 5.33\n",
      "Episode length: 31.70 +/- 7.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.7        |\n",
      "|    mean_reward          | -2.23       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4278528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006267184 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.08       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0292      |\n",
      "|    n_updates            | 25780       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    std                  | 13.8        |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.214   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2090     |\n",
      "|    time_elapsed    | 3267     |\n",
      "|    total_timesteps | 4280320  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.396       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2091         |\n",
      "|    time_elapsed         | 3269         |\n",
      "|    total_timesteps      | 4282368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070354245 |\n",
      "|    clip_fraction        | 0.0714       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.09        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.037        |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 0.276        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | 0.0469       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2092         |\n",
      "|    time_elapsed         | 3270         |\n",
      "|    total_timesteps      | 4284416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075636143 |\n",
      "|    clip_fraction        | 0.0819       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.12        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.271        |\n",
      "|    n_updates            | 25800        |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 0.741        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.0352      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2093         |\n",
      "|    time_elapsed         | 3272         |\n",
      "|    total_timesteps      | 4286464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062510446 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.13        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0272      |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.00917     |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 0.137        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.791      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 3273        |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008537131 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00342    |\n",
      "|    n_updates            | 25820       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4288528, episode_reward=3.12 +/- 2.44\n",
      "Episode length: 24.90 +/- 3.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.9        |\n",
      "|    mean_reward          | 3.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4288528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007530762 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0914     |\n",
      "|    n_updates            | 25830       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.0385      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.00685 |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2095     |\n",
      "|    time_elapsed    | 3275     |\n",
      "|    total_timesteps | 4290560  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.45         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2096         |\n",
      "|    time_elapsed         | 3277         |\n",
      "|    total_timesteps      | 4292608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056074467 |\n",
      "|    clip_fraction        | 0.0397       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.14        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0329       |\n",
      "|    n_updates            | 25840        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 0.287        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.195      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2097        |\n",
      "|    time_elapsed         | 3278        |\n",
      "|    total_timesteps      | 4294656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005594524 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 25850       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.554       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 0.454        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2098         |\n",
      "|    time_elapsed         | 3280         |\n",
      "|    total_timesteps      | 4296704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048272493 |\n",
      "|    clip_fraction        | 0.0523       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.13        |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.289        |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00911     |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 0.997        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4298528, episode_reward=-3.41 +/- 5.32\n",
      "Episode length: 34.40 +/- 6.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 34.4         |\n",
      "|    mean_reward          | -3.41        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4298528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058621312 |\n",
      "|    clip_fraction        | 0.0443       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.14        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.00654      |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -0.00791     |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 0.449        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.059   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2099     |\n",
      "|    time_elapsed    | 3281     |\n",
      "|    total_timesteps | 4298752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.326      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2100        |\n",
      "|    time_elapsed         | 3283        |\n",
      "|    total_timesteps      | 4300800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005413068 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 25880       |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 0.629       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.663      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2101        |\n",
      "|    time_elapsed         | 3285        |\n",
      "|    total_timesteps      | 4302848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009375911 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0982      |\n",
      "|    n_updates            | 25890       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.496       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.121      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2102        |\n",
      "|    time_elapsed         | 3286        |\n",
      "|    total_timesteps      | 4304896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005240277 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.205       |\n",
      "|    n_updates            | 25900       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.671       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.537      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2103        |\n",
      "|    time_elapsed         | 3288        |\n",
      "|    total_timesteps      | 4306944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007629322 |\n",
      "|    clip_fraction        | 0.0478      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0229      |\n",
      "|    n_updates            | 25910       |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4308528, episode_reward=0.38 +/- 3.38\n",
      "Episode length: 30.10 +/- 5.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | 0.383       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4308528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005348229 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00379     |\n",
      "|    n_updates            | 25920       |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | -0.937   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2104     |\n",
      "|    time_elapsed    | 3291     |\n",
      "|    total_timesteps | 4308992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.0253      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2105        |\n",
      "|    time_elapsed         | 3293        |\n",
      "|    total_timesteps      | 4311040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004271491 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 25930       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.0579      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2106        |\n",
      "|    time_elapsed         | 3295        |\n",
      "|    total_timesteps      | 4313088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004941443 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0646      |\n",
      "|    n_updates            | 25940       |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.589       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.328       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2107         |\n",
      "|    time_elapsed         | 3297         |\n",
      "|    total_timesteps      | 4315136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053126365 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.19        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0827       |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.522        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.811       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2108         |\n",
      "|    time_elapsed         | 3298         |\n",
      "|    total_timesteps      | 4317184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052126506 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.18        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0797       |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.00945     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 0.401        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4318528, episode_reward=-0.98 +/- 5.28\n",
      "Episode length: 30.90 +/- 8.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.9        |\n",
      "|    mean_reward          | -0.985      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4318528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007541093 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0657     |\n",
      "|    n_updates            | 25970       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 0.0878      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.4     |\n",
      "|    ep_rew_mean     | 0.133    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2109     |\n",
      "|    time_elapsed    | 3300     |\n",
      "|    total_timesteps | 4319232  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.351       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2110        |\n",
      "|    time_elapsed         | 3303        |\n",
      "|    total_timesteps      | 4321280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005478722 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.11       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.198       |\n",
      "|    n_updates            | 25980       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 0.987       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.5         |\n",
      "|    ep_rew_mean          | 0.152        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2111         |\n",
      "|    time_elapsed         | 3304         |\n",
      "|    total_timesteps      | 4323328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071998285 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.11        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.201        |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 0.501        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.5         |\n",
      "|    ep_rew_mean          | 0.00667      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 2112         |\n",
      "|    time_elapsed         | 3306         |\n",
      "|    total_timesteps      | 4325376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068119364 |\n",
      "|    clip_fraction        | 0.0638       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.1         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0469       |\n",
      "|    n_updates            | 26000        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 0.323        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.8      |\n",
      "|    ep_rew_mean          | -0.389    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1307      |\n",
      "|    iterations           | 2113      |\n",
      "|    time_elapsed         | 3308      |\n",
      "|    total_timesteps      | 4327424   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0065937 |\n",
      "|    clip_fraction        | 0.0616    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -8.1      |\n",
      "|    explained_variance   | 0.956     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.119     |\n",
      "|    n_updates            | 26010     |\n",
      "|    policy_gradient_loss | -0.0117   |\n",
      "|    std                  | 14.1      |\n",
      "|    value_loss           | 0.723     |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4328528, episode_reward=-0.31 +/- 4.94\n",
      "Episode length: 30.60 +/- 6.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.6        |\n",
      "|    mean_reward          | -0.315      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4328528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005470678 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.12       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 26020       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.723       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.0396  |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 2114     |\n",
      "|    time_elapsed    | 3310     |\n",
      "|    total_timesteps | 4329472  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.789       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 2115         |\n",
      "|    time_elapsed         | 3311         |\n",
      "|    total_timesteps      | 4331520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068971184 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.13        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0506       |\n",
      "|    n_updates            | 26030        |\n",
      "|    policy_gradient_loss | -0.00743     |\n",
      "|    std                  | 14.3         |\n",
      "|    value_loss           | 0.309        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -1.55       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 3313        |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007400743 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.13       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 26040       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.803       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.0221      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1307        |\n",
      "|    iterations           | 2117        |\n",
      "|    time_elapsed         | 3314        |\n",
      "|    total_timesteps      | 4335616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006597936 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 26050       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.92        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.0438      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2118         |\n",
      "|    time_elapsed         | 3316         |\n",
      "|    total_timesteps      | 4337664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061780773 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0746       |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00859     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 0.382        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4338528, episode_reward=-1.81 +/- 3.26\n",
      "Episode length: 33.30 +/- 6.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 33.3         |\n",
      "|    mean_reward          | -1.81        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4338528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073921243 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.14        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.036        |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 0.356        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.508    |\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 2119     |\n",
      "|    time_elapsed    | 3317     |\n",
      "|    total_timesteps | 4339712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.478       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2120        |\n",
      "|    time_elapsed         | 3319        |\n",
      "|    total_timesteps      | 4341760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004580355 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.12       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 26080       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.3        |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2121        |\n",
      "|    time_elapsed         | 3320        |\n",
      "|    total_timesteps      | 4343808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009373185 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 26090       |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 0.574       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.225       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2122         |\n",
      "|    time_elapsed         | 3322         |\n",
      "|    total_timesteps      | 4345856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038761045 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.18        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.439        |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 1.25         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 0.027        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2123         |\n",
      "|    time_elapsed         | 3323         |\n",
      "|    total_timesteps      | 4347904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062964465 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.17        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.12         |\n",
      "|    n_updates            | 26110        |\n",
      "|    policy_gradient_loss | -0.00841     |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.517        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4348528, episode_reward=1.80 +/- 5.26\n",
      "Episode length: 25.30 +/- 8.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25.3         |\n",
      "|    mean_reward          | 1.8          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4348528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064994222 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.19        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0281      |\n",
      "|    n_updates            | 26120        |\n",
      "|    policy_gradient_loss | -0.00851     |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 0.218        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.3     |\n",
      "|    ep_rew_mean     | -0.938   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2124     |\n",
      "|    time_elapsed    | 3325     |\n",
      "|    total_timesteps | 4349952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.784      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2125        |\n",
      "|    time_elapsed         | 3327        |\n",
      "|    total_timesteps      | 4352000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005837506 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.18       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 26130       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 0.616       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.417      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2126        |\n",
      "|    time_elapsed         | 3328        |\n",
      "|    total_timesteps      | 4354048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007885024 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 26140       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 0.602       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.103      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2127        |\n",
      "|    time_elapsed         | 3330        |\n",
      "|    total_timesteps      | 4356096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005010806 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.46        |\n",
      "|    n_updates            | 26150       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.978       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.271       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2128        |\n",
      "|    time_elapsed         | 3331        |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004473951 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.13       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 26160       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.48        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4358528, episode_reward=1.56 +/- 5.44\n",
      "Episode length: 27.50 +/- 8.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.5        |\n",
      "|    mean_reward          | 1.56        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4358528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005471806 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 26170       |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -0.348   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2129     |\n",
      "|    time_elapsed    | 3333     |\n",
      "|    total_timesteps | 4360192  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.6         |\n",
      "|    ep_rew_mean          | 0.117        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2130         |\n",
      "|    time_elapsed         | 3334         |\n",
      "|    total_timesteps      | 4362240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074605923 |\n",
      "|    clip_fraction        | 0.055        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.12        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0233      |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.00974     |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | 0.213        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2131         |\n",
      "|    time_elapsed         | 3336         |\n",
      "|    total_timesteps      | 4364288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073483973 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.11        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0223       |\n",
      "|    n_updates            | 26190        |\n",
      "|    policy_gradient_loss | -0.00937     |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 0.393        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.662       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2132         |\n",
      "|    time_elapsed         | 3337         |\n",
      "|    total_timesteps      | 4366336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132221235 |\n",
      "|    clip_fraction        | 0.0801       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.1         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.173        |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 0.497        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.956       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2133        |\n",
      "|    time_elapsed         | 3339        |\n",
      "|    total_timesteps      | 4368384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004407327 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0141      |\n",
      "|    n_updates            | 26210       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4368528, episode_reward=0.27 +/- 5.59\n",
      "Episode length: 29.40 +/- 9.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.4        |\n",
      "|    mean_reward          | 0.272       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4368528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008918431 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.07       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0698     |\n",
      "|    n_updates            | 26220       |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 0.0517      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.5     |\n",
      "|    ep_rew_mean     | 0.697    |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2134     |\n",
      "|    time_elapsed    | 3340     |\n",
      "|    total_timesteps | 4370432  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.0552      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2135         |\n",
      "|    time_elapsed         | 3342         |\n",
      "|    total_timesteps      | 4372480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066612903 |\n",
      "|    clip_fraction        | 0.0648       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.07        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.185        |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -0.00981     |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 0.633        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.194       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2136        |\n",
      "|    time_elapsed         | 3343        |\n",
      "|    total_timesteps      | 4374528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006564781 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0391     |\n",
      "|    n_updates            | 26240       |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.067      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2137        |\n",
      "|    time_elapsed         | 3345        |\n",
      "|    total_timesteps      | 4376576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007209854 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.08       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.255       |\n",
      "|    n_updates            | 26250       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 0.572       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4378528, episode_reward=-2.58 +/- 5.12\n",
      "Episode length: 32.30 +/- 8.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.3         |\n",
      "|    mean_reward          | -2.58        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4378528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074856365 |\n",
      "|    clip_fraction        | 0.0534       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.09        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0301      |\n",
      "|    n_updates            | 26260        |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    std                  | 14           |\n",
      "|    value_loss           | 0.116        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | -0.719   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2138     |\n",
      "|    time_elapsed    | 3347     |\n",
      "|    total_timesteps | 4378624  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | -0.246       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2139         |\n",
      "|    time_elapsed         | 3348         |\n",
      "|    total_timesteps      | 4380672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064746444 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.09        |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.871        |\n",
      "|    n_updates            | 26270        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    std                  | 14.1         |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.0412     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2140        |\n",
      "|    time_elapsed         | 3350        |\n",
      "|    total_timesteps      | 4382720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007026407 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0886     |\n",
      "|    n_updates            | 26280       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 13.9        |\n",
      "|    value_loss           | 0.0532      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.7       |\n",
      "|    ep_rew_mean          | 0.312      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 2141       |\n",
      "|    time_elapsed         | 3351       |\n",
      "|    total_timesteps      | 4384768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01107712 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.07      |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.223      |\n",
      "|    n_updates            | 26290      |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    std                  | 14         |\n",
      "|    value_loss           | 0.78       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.286      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2142        |\n",
      "|    time_elapsed         | 3353        |\n",
      "|    total_timesteps      | 4386816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005515763 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.06       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 26300       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 0.348       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4388528, episode_reward=-2.60 +/- 3.64\n",
      "Episode length: 35.40 +/- 9.17\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 35.4       |\n",
      "|    mean_reward          | -2.6       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4388528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00781868 |\n",
      "|    clip_fraction        | 0.0676     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.03      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.132      |\n",
      "|    n_updates            | 26310      |\n",
      "|    policy_gradient_loss | -0.00899   |\n",
      "|    std                  | 13.5       |\n",
      "|    value_loss           | 0.412      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -0.889   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2143     |\n",
      "|    time_elapsed    | 3354     |\n",
      "|    total_timesteps | 4388864  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.7         |\n",
      "|    ep_rew_mean          | -0.541       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2144         |\n",
      "|    time_elapsed         | 3356         |\n",
      "|    total_timesteps      | 4390912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056064916 |\n",
      "|    clip_fraction        | 0.0339       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.02        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.35         |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    std                  | 13.5         |\n",
      "|    value_loss           | 0.877        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2145        |\n",
      "|    time_elapsed         | 3357        |\n",
      "|    total_timesteps      | 4392960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008435246 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.03       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00332    |\n",
      "|    n_updates            | 26330       |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    std                  | 13.7        |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.727      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2146        |\n",
      "|    time_elapsed         | 3359        |\n",
      "|    total_timesteps      | 4395008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006147514 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.06       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0688     |\n",
      "|    n_updates            | 26340       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 0.0833      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.595      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2147        |\n",
      "|    time_elapsed         | 3361        |\n",
      "|    total_timesteps      | 4397056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009987328 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 26350       |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 0.313       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4398528, episode_reward=0.93 +/- 3.85\n",
      "Episode length: 30.00 +/- 4.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.925       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4398528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006934476 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.12       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0333     |\n",
      "|    n_updates            | 26360       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 14.2        |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.845   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2148     |\n",
      "|    time_elapsed    | 3362     |\n",
      "|    total_timesteps | 4399104  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.712       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2149         |\n",
      "|    time_elapsed         | 3363         |\n",
      "|    total_timesteps      | 4401152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060141617 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.12        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.00282     |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | -0.00851     |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 0.403        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | 0.122        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2150         |\n",
      "|    time_elapsed         | 3365         |\n",
      "|    total_timesteps      | 4403200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077595767 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.12        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0556       |\n",
      "|    n_updates            | 26380        |\n",
      "|    policy_gradient_loss | -0.00954     |\n",
      "|    std                  | 14.2         |\n",
      "|    value_loss           | 0.348        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.3         |\n",
      "|    ep_rew_mean          | 0.281        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2151         |\n",
      "|    time_elapsed         | 3366         |\n",
      "|    total_timesteps      | 4405248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059528355 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.13        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0913       |\n",
      "|    n_updates            | 26390        |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 0.507        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 0.242        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2152         |\n",
      "|    time_elapsed         | 3368         |\n",
      "|    total_timesteps      | 4407296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073806536 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0372      |\n",
      "|    n_updates            | 26400        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 0.212        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4408528, episode_reward=-2.33 +/- 4.78\n",
      "Episode length: 32.80 +/- 6.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.8        |\n",
      "|    mean_reward          | -2.33       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4408528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005612565 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0695      |\n",
      "|    n_updates            | 26410       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.405       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.603   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2153     |\n",
      "|    time_elapsed    | 3369     |\n",
      "|    total_timesteps | 4409344  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.6         |\n",
      "|    ep_rew_mean          | -1.09        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2154         |\n",
      "|    time_elapsed         | 3371         |\n",
      "|    total_timesteps      | 4411392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072723124 |\n",
      "|    clip_fraction        | 0.0749       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.13        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.37         |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00906     |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 0.908        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.232       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2155        |\n",
      "|    time_elapsed         | 3372        |\n",
      "|    total_timesteps      | 4413440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005083031 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.000103    |\n",
      "|    n_updates            | 26430       |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.457      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2156        |\n",
      "|    time_elapsed         | 3374        |\n",
      "|    total_timesteps      | 4415488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008702197 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0569     |\n",
      "|    n_updates            | 26440       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.3         |\n",
      "|    ep_rew_mean          | -0.885       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2157         |\n",
      "|    time_elapsed         | 3375         |\n",
      "|    total_timesteps      | 4417536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052439794 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.19        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 26450        |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.604        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4418528, episode_reward=0.09 +/- 4.86\n",
      "Episode length: 29.20 +/- 7.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.2         |\n",
      "|    mean_reward          | 0.0917       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4418528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064308355 |\n",
      "|    clip_fraction        | 0.065        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.18        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0235       |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.00882     |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.334        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.304   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2158     |\n",
      "|    time_elapsed    | 3377     |\n",
      "|    total_timesteps | 4419584  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.227       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2159         |\n",
      "|    time_elapsed         | 3379         |\n",
      "|    total_timesteps      | 4421632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041824635 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.19        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.53         |\n",
      "|    n_updates            | 26470        |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -1.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2160        |\n",
      "|    time_elapsed         | 3380        |\n",
      "|    total_timesteps      | 4423680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005966131 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0488      |\n",
      "|    n_updates            | 26480       |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 0.338       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | -0.0944      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2161         |\n",
      "|    time_elapsed         | 3382         |\n",
      "|    total_timesteps      | 4425728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063629476 |\n",
      "|    clip_fraction        | 0.0583       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.24        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0872       |\n",
      "|    n_updates            | 26490        |\n",
      "|    policy_gradient_loss | -0.00914     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 0.31         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.157       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2162         |\n",
      "|    time_elapsed         | 3383         |\n",
      "|    total_timesteps      | 4427776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065282737 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.24        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0273      |\n",
      "|    n_updates            | 26500        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.171        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4428528, episode_reward=1.13 +/- 5.62\n",
      "Episode length: 28.10 +/- 8.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.1        |\n",
      "|    mean_reward          | 1.13        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4428528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003973836 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 26510       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.975       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.242   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2163     |\n",
      "|    time_elapsed    | 3385     |\n",
      "|    total_timesteps | 4429824  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.268       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2164         |\n",
      "|    time_elapsed         | 3386         |\n",
      "|    total_timesteps      | 4431872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053045377 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.22        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.206        |\n",
      "|    n_updates            | 26520        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.453        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.6         |\n",
      "|    ep_rew_mean          | 0.508        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2165         |\n",
      "|    time_elapsed         | 3388         |\n",
      "|    total_timesteps      | 4433920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059271553 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0805      |\n",
      "|    n_updates            | 26530        |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.0665       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2166        |\n",
      "|    time_elapsed         | 3389        |\n",
      "|    total_timesteps      | 4435968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005930521 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.18       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 26540       |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 0.613       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.0854     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2167        |\n",
      "|    time_elapsed         | 3391        |\n",
      "|    total_timesteps      | 4438016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004382657 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00841     |\n",
      "|    n_updates            | 26550       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4438528, episode_reward=1.37 +/- 3.95\n",
      "Episode length: 28.40 +/- 6.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.4        |\n",
      "|    mean_reward          | 1.37        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4438528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008608813 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 26560       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.419       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.432   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2168     |\n",
      "|    time_elapsed    | 3392     |\n",
      "|    total_timesteps | 4440064  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.193       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2169         |\n",
      "|    time_elapsed         | 3394         |\n",
      "|    total_timesteps      | 4442112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059954394 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.23        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.317        |\n",
      "|    n_updates            | 26570        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 0.761        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | 0.106        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2170         |\n",
      "|    time_elapsed         | 3395         |\n",
      "|    total_timesteps      | 4444160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062757106 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.25        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.00442     |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 0.325        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.132      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2171        |\n",
      "|    time_elapsed         | 3397        |\n",
      "|    total_timesteps      | 4446208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006873435 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.24       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0525      |\n",
      "|    n_updates            | 26590       |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.191      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2172        |\n",
      "|    time_elapsed         | 3398        |\n",
      "|    total_timesteps      | 4448256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010549691 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00139    |\n",
      "|    n_updates            | 26600       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4448528, episode_reward=1.16 +/- 4.38\n",
      "Episode length: 28.10 +/- 7.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.1        |\n",
      "|    mean_reward          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4448528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008235608 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 26610       |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.353       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 0.0645   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2173     |\n",
      "|    time_elapsed    | 3400     |\n",
      "|    total_timesteps | 4450304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.464       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2174        |\n",
      "|    time_elapsed         | 3402        |\n",
      "|    total_timesteps      | 4452352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010560735 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.274       |\n",
      "|    n_updates            | 26620       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 0.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2175        |\n",
      "|    time_elapsed         | 3403        |\n",
      "|    total_timesteps      | 4454400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009157313 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.064       |\n",
      "|    n_updates            | 26630       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 0.359       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.191      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 3404        |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010213982 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0312      |\n",
      "|    n_updates            | 26640       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.619       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2177         |\n",
      "|    time_elapsed         | 3406         |\n",
      "|    total_timesteps      | 4458496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069151893 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.25        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0432      |\n",
      "|    n_updates            | 26650        |\n",
      "|    policy_gradient_loss | -0.00965     |\n",
      "|    std                  | 15.3         |\n",
      "|    value_loss           | 0.107        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4458528, episode_reward=0.24 +/- 4.03\n",
      "Episode length: 29.60 +/- 6.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.6         |\n",
      "|    mean_reward          | 0.243        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4458528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069046225 |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.29        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0734      |\n",
      "|    n_updates            | 26660        |\n",
      "|    policy_gradient_loss | -0.00967     |\n",
      "|    std                  | 15.6         |\n",
      "|    value_loss           | 0.0979       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.191   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2178     |\n",
      "|    time_elapsed    | 3407     |\n",
      "|    total_timesteps | 4460544  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.951       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2179         |\n",
      "|    time_elapsed         | 3409         |\n",
      "|    total_timesteps      | 4462592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069540455 |\n",
      "|    clip_fraction        | 0.052        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.29        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0656       |\n",
      "|    n_updates            | 26670        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 0.309        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | -1.81       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2180        |\n",
      "|    time_elapsed         | 3410        |\n",
      "|    total_timesteps      | 4464640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007490687 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.28       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0717     |\n",
      "|    n_updates            | 26680       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.3         |\n",
      "|    ep_rew_mean          | -1.24        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2181         |\n",
      "|    time_elapsed         | 3412         |\n",
      "|    total_timesteps      | 4466688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038155639 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.27        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.523        |\n",
      "|    n_updates            | 26690        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 1.5          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4468528, episode_reward=-2.88 +/- 4.33\n",
      "Episode length: 35.10 +/- 10.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 35.1         |\n",
      "|    mean_reward          | -2.88        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4468528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063703456 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.25        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0732      |\n",
      "|    n_updates            | 26700        |\n",
      "|    policy_gradient_loss | -0.00865     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 0.12         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.198   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2182     |\n",
      "|    time_elapsed    | 3414     |\n",
      "|    total_timesteps | 4468736  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.2       |\n",
      "|    ep_rew_mean          | 0.536      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1308       |\n",
      "|    iterations           | 2183       |\n",
      "|    time_elapsed         | 3415       |\n",
      "|    total_timesteps      | 4470784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00620049 |\n",
      "|    clip_fraction        | 0.0609     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.23      |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.209      |\n",
      "|    n_updates            | 26710      |\n",
      "|    policy_gradient_loss | -0.00979   |\n",
      "|    std                  | 15.1       |\n",
      "|    value_loss           | 0.977      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | 0.239        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2184         |\n",
      "|    time_elapsed         | 3417         |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028760298 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.23        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.559        |\n",
      "|    n_updates            | 26720        |\n",
      "|    policy_gradient_loss | -0.00753     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 1.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | -1.49        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2185         |\n",
      "|    time_elapsed         | 3418         |\n",
      "|    total_timesteps      | 4474880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072498564 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.23        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.433        |\n",
      "|    n_updates            | 26730        |\n",
      "|    policy_gradient_loss | -0.00909     |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 0.887        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.744       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1308         |\n",
      "|    iterations           | 2186         |\n",
      "|    time_elapsed         | 3420         |\n",
      "|    total_timesteps      | 4476928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057875672 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.24        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.387        |\n",
      "|    n_updates            | 26740        |\n",
      "|    policy_gradient_loss | -0.00916     |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4478528, episode_reward=0.68 +/- 4.69\n",
      "Episode length: 28.20 +/- 8.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.2        |\n",
      "|    mean_reward          | 0.682       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4478528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005471657 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.24       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 26750       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.178   |\n",
      "| time/              |          |\n",
      "|    fps             | 1308     |\n",
      "|    iterations      | 2187     |\n",
      "|    time_elapsed    | 3421     |\n",
      "|    total_timesteps | 4478976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.429       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2188        |\n",
      "|    time_elapsed         | 3423        |\n",
      "|    total_timesteps      | 4481024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005373989 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.445       |\n",
      "|    n_updates            | 26760       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.278      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1308        |\n",
      "|    iterations           | 2189        |\n",
      "|    time_elapsed         | 3424        |\n",
      "|    total_timesteps      | 4483072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006603114 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.299       |\n",
      "|    n_updates            | 26770       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 0.89        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.2         |\n",
      "|    ep_rew_mean          | -0.367       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2190         |\n",
      "|    time_elapsed         | 3426         |\n",
      "|    total_timesteps      | 4485120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062685506 |\n",
      "|    clip_fraction        | 0.0826       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.24        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.209        |\n",
      "|    n_updates            | 26780        |\n",
      "|    policy_gradient_loss | -0.00821     |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.622        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.688       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2191         |\n",
      "|    time_elapsed         | 3427         |\n",
      "|    total_timesteps      | 4487168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067732604 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.23        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.101        |\n",
      "|    n_updates            | 26790        |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.415        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4488528, episode_reward=-0.83 +/- 7.13\n",
      "Episode length: 30.10 +/- 9.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.1         |\n",
      "|    mean_reward          | -0.83        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4488528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060887043 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.23        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0389      |\n",
      "|    n_updates            | 26800        |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    std                  | 15.2         |\n",
      "|    value_loss           | 0.195        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.4     |\n",
      "|    ep_rew_mean     | -0.344   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2192     |\n",
      "|    time_elapsed    | 3429     |\n",
      "|    total_timesteps | 4489216  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.842       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2193         |\n",
      "|    time_elapsed         | 3430         |\n",
      "|    total_timesteps      | 4491264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078602135 |\n",
      "|    clip_fraction        | 0.0591       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.23        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0872      |\n",
      "|    n_updates            | 26810        |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.0553       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.6         |\n",
      "|    ep_rew_mean          | -1.52        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2194         |\n",
      "|    time_elapsed         | 3432         |\n",
      "|    total_timesteps      | 4493312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053745788 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.22        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 26820        |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.437        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.8         |\n",
      "|    ep_rew_mean          | -0.899       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2195         |\n",
      "|    time_elapsed         | 3433         |\n",
      "|    total_timesteps      | 4495360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064888373 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.322        |\n",
      "|    n_updates            | 26830        |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.747        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.573       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2196         |\n",
      "|    time_elapsed         | 3435         |\n",
      "|    total_timesteps      | 4497408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054428587 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.133        |\n",
      "|    n_updates            | 26840        |\n",
      "|    policy_gradient_loss | -0.00821     |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.551        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4498528, episode_reward=2.14 +/- 3.69\n",
      "Episode length: 25.60 +/- 7.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 25.6         |\n",
      "|    mean_reward          | 2.14         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4498528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058031287 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.00635      |\n",
      "|    n_updates            | 26850        |\n",
      "|    policy_gradient_loss | -0.00933     |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 0.217        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.677   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2197     |\n",
      "|    time_elapsed    | 3437     |\n",
      "|    total_timesteps | 4499456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -0.0653     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2198        |\n",
      "|    time_elapsed         | 3438        |\n",
      "|    total_timesteps      | 4501504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008950693 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0365      |\n",
      "|    n_updates            | 26860       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -1.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2199        |\n",
      "|    time_elapsed         | 3440        |\n",
      "|    total_timesteps      | 4503552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006923159 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.252       |\n",
      "|    n_updates            | 26870       |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 0.848       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.5        |\n",
      "|    ep_rew_mean          | -0.523      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2200        |\n",
      "|    time_elapsed         | 3441        |\n",
      "|    total_timesteps      | 4505600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006061146 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00338    |\n",
      "|    n_updates            | 26880       |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.179      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 3443        |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004682163 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 26890       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.718       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4508528, episode_reward=-0.32 +/- 4.58\n",
      "Episode length: 31.40 +/- 6.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.4         |\n",
      "|    mean_reward          | -0.318       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4508528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072964877 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0609       |\n",
      "|    n_updates            | 26900        |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.392        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | 0.154    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2202     |\n",
      "|    time_elapsed    | 3444     |\n",
      "|    total_timesteps | 4509696  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31           |\n",
      "|    ep_rew_mean          | -0.139       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2203         |\n",
      "|    time_elapsed         | 3446         |\n",
      "|    total_timesteps      | 4511744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055886637 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.22        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.424        |\n",
      "|    n_updates            | 26910        |\n",
      "|    policy_gradient_loss | -0.0086      |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 1.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.306      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2204        |\n",
      "|    time_elapsed         | 3447        |\n",
      "|    total_timesteps      | 4513792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006462955 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 26920       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.505       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2205        |\n",
      "|    time_elapsed         | 3449        |\n",
      "|    total_timesteps      | 4515840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003775684 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0839      |\n",
      "|    n_updates            | 26930       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.373       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.976      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2206        |\n",
      "|    time_elapsed         | 3450        |\n",
      "|    total_timesteps      | 4517888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007459602 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0491     |\n",
      "|    n_updates            | 26940       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4518528, episode_reward=0.07 +/- 4.69\n",
      "Episode length: 29.70 +/- 6.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.7         |\n",
      "|    mean_reward          | 0.0674       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4518528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047917194 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.2         |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.216        |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.0087      |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.625        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.1     |\n",
      "|    ep_rew_mean     | -1.47    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2207     |\n",
      "|    time_elapsed    | 3452     |\n",
      "|    total_timesteps | 4519936  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.8         |\n",
      "|    ep_rew_mean          | -1.37        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2208         |\n",
      "|    time_elapsed         | 3453         |\n",
      "|    total_timesteps      | 4521984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054007806 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.418        |\n",
      "|    n_updates            | 26960        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.445      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2209        |\n",
      "|    time_elapsed         | 3455        |\n",
      "|    total_timesteps      | 4524032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008178502 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 26970       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.288       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.281       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2210        |\n",
      "|    time_elapsed         | 3456        |\n",
      "|    total_timesteps      | 4526080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006060302 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.18       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.044      |\n",
      "|    n_updates            | 26980       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -0.253      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2211        |\n",
      "|    time_elapsed         | 3458        |\n",
      "|    total_timesteps      | 4528128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010386412 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0719      |\n",
      "|    n_updates            | 26990       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4528528, episode_reward=-0.46 +/- 4.19\n",
      "Episode length: 31.00 +/- 6.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31          |\n",
      "|    mean_reward          | -0.458      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4528528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005725057 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 27000       |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.765       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.6     |\n",
      "|    ep_rew_mean     | -1.01    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2212     |\n",
      "|    time_elapsed    | 3459     |\n",
      "|    total_timesteps | 4530176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 0.0429      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 3461        |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006596906 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.2        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.213       |\n",
      "|    n_updates            | 27010       |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.1         |\n",
      "|    ep_rew_mean          | 0.343        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 3462         |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064124856 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0146      |\n",
      "|    n_updates            | 27020        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.259        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -0.36       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2215        |\n",
      "|    time_elapsed         | 3464        |\n",
      "|    total_timesteps      | 4536320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005275343 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.2        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 27030       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.435       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.229      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2216        |\n",
      "|    time_elapsed         | 3465        |\n",
      "|    total_timesteps      | 4538368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008640064 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.05       |\n",
      "|    n_updates            | 27040       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 15          |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4538528, episode_reward=-1.67 +/- 3.69\n",
      "Episode length: 32.50 +/- 6.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.5         |\n",
      "|    mean_reward          | -1.67        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4538528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053799977 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0254      |\n",
      "|    n_updates            | 27050        |\n",
      "|    policy_gradient_loss | -0.00825     |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.252        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -0.0283  |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2217     |\n",
      "|    time_elapsed    | 3467     |\n",
      "|    total_timesteps | 4540416  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | -0.468       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2218         |\n",
      "|    time_elapsed         | 3469         |\n",
      "|    total_timesteps      | 4542464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048111947 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.19        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.117        |\n",
      "|    n_updates            | 27060        |\n",
      "|    policy_gradient_loss | -0.009       |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.551        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.612      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2219        |\n",
      "|    time_elapsed         | 3470        |\n",
      "|    total_timesteps      | 4544512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009541007 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.18       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 27070       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.468       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.1       |\n",
      "|    ep_rew_mean          | -0.552     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 2220       |\n",
      "|    time_elapsed         | 3472       |\n",
      "|    total_timesteps      | 4546560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00608705 |\n",
      "|    clip_fraction        | 0.0678     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.19      |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.233      |\n",
      "|    n_updates            | 27080      |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    std                  | 14.8       |\n",
      "|    value_loss           | 0.679      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4548528, episode_reward=1.67 +/- 5.81\n",
      "Episode length: 28.40 +/- 8.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28.4         |\n",
      "|    mean_reward          | 1.67         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4548528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059654065 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.18        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.232        |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.00894     |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 0.601        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.247   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2221     |\n",
      "|    time_elapsed    | 3473     |\n",
      "|    total_timesteps | 4548608  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.6       |\n",
      "|    ep_rew_mean          | 0.886      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 2222       |\n",
      "|    time_elapsed         | 3475       |\n",
      "|    total_timesteps      | 4550656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00851467 |\n",
      "|    clip_fraction        | 0.0618     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.19      |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0427     |\n",
      "|    n_updates            | 27100      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 14.9       |\n",
      "|    value_loss           | 0.286      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2223        |\n",
      "|    time_elapsed         | 3476        |\n",
      "|    total_timesteps      | 4552704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010033702 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0588     |\n",
      "|    n_updates            | 27110       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.585       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2224         |\n",
      "|    time_elapsed         | 3478         |\n",
      "|    total_timesteps      | 4554752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061046104 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0156      |\n",
      "|    n_updates            | 27120        |\n",
      "|    policy_gradient_loss | -0.00787     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 0.337        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.589       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2225         |\n",
      "|    time_elapsed         | 3480         |\n",
      "|    total_timesteps      | 4556800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051399884 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0392       |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.00918     |\n",
      "|    std                  | 14.4         |\n",
      "|    value_loss           | 0.357        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4558528, episode_reward=0.42 +/- 4.87\n",
      "Episode length: 29.50 +/- 7.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.5         |\n",
      "|    mean_reward          | 0.424        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4558528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074136215 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0058      |\n",
      "|    n_updates            | 27140        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 0.298        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.439   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2226     |\n",
      "|    time_elapsed    | 3481     |\n",
      "|    total_timesteps | 4558848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.0337      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2227        |\n",
      "|    time_elapsed         | 3483        |\n",
      "|    total_timesteps      | 4560896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010333448 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0918      |\n",
      "|    n_updates            | 27150       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.426       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2228        |\n",
      "|    time_elapsed         | 3484        |\n",
      "|    total_timesteps      | 4562944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008459851 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00652     |\n",
      "|    n_updates            | 27160       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.234       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2229        |\n",
      "|    time_elapsed         | 3486        |\n",
      "|    total_timesteps      | 4564992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009074687 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0836     |\n",
      "|    n_updates            | 27170       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.0599      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.9         |\n",
      "|    ep_rew_mean          | 0.688        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2230         |\n",
      "|    time_elapsed         | 3487         |\n",
      "|    total_timesteps      | 4567040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069007613 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.13        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.151        |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -0.00987     |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 0.673        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4568528, episode_reward=-1.81 +/- 4.67\n",
      "Episode length: 33.60 +/- 7.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.6        |\n",
      "|    mean_reward          | -1.81       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4568528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007854661 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0501     |\n",
      "|    n_updates            | 27190       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 14.5        |\n",
      "|    value_loss           | 0.0933      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -1.11    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2231     |\n",
      "|    time_elapsed    | 3489     |\n",
      "|    total_timesteps | 4569088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.649      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2232        |\n",
      "|    time_elapsed         | 3491        |\n",
      "|    total_timesteps      | 4571136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006623381 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.14       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00208    |\n",
      "|    n_updates            | 27200       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.267       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | -0.731       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2233         |\n",
      "|    time_elapsed         | 3492         |\n",
      "|    total_timesteps      | 4573184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068276296 |\n",
      "|    clip_fraction        | 0.0448       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.14        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.274        |\n",
      "|    n_updates            | 27210        |\n",
      "|    policy_gradient_loss | -0.00794     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 0.765        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.658      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2234        |\n",
      "|    time_elapsed         | 3494        |\n",
      "|    total_timesteps      | 4575232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006608461 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.15       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 27220       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.378       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.493      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2235        |\n",
      "|    time_elapsed         | 3495        |\n",
      "|    total_timesteps      | 4577280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008197345 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.13       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.072      |\n",
      "|    n_updates            | 27230       |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4578528, episode_reward=-1.42 +/- 5.93\n",
      "Episode length: 32.50 +/- 8.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.5        |\n",
      "|    mean_reward          | -1.42       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4578528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007152018 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.12       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 27240       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    std                  | 14.4        |\n",
      "|    value_loss           | 0.355       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.783   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2236     |\n",
      "|    time_elapsed    | 3497     |\n",
      "|    total_timesteps | 4579328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | -0.0112     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2237        |\n",
      "|    time_elapsed         | 3499        |\n",
      "|    total_timesteps      | 4581376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007582592 |\n",
      "|    clip_fraction        | 0.0747      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.11       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0486      |\n",
      "|    n_updates            | 27250       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.162      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2238        |\n",
      "|    time_elapsed         | 3500        |\n",
      "|    total_timesteps      | 4583424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009730445 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0881     |\n",
      "|    n_updates            | 27260       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 14          |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | 0.0489      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2239        |\n",
      "|    time_elapsed         | 3502        |\n",
      "|    total_timesteps      | 4585472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008855767 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.09       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 27270       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 14.3        |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | 0.467        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2240         |\n",
      "|    time_elapsed         | 3504         |\n",
      "|    total_timesteps      | 4587520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063066483 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.12        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0742       |\n",
      "|    n_updates            | 27280        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 0.472        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4588528, episode_reward=-0.93 +/- 4.68\n",
      "Episode length: 33.90 +/- 8.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 33.9         |\n",
      "|    mean_reward          | -0.928       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4588528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062031206 |\n",
      "|    clip_fraction        | 0.055        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 27290        |\n",
      "|    policy_gradient_loss | -0.00929     |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 0.976        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.223   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2241     |\n",
      "|    time_elapsed    | 3505     |\n",
      "|    total_timesteps | 4589568  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.797       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2242         |\n",
      "|    time_elapsed         | 3507         |\n",
      "|    total_timesteps      | 4591616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062828553 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.16        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.328        |\n",
      "|    n_updates            | 27300        |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 0.856        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -0.928       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2243         |\n",
      "|    time_elapsed         | 3508         |\n",
      "|    total_timesteps      | 4593664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073556444 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 27310        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 0.451        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | -0.739       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2244         |\n",
      "|    time_elapsed         | 3510         |\n",
      "|    total_timesteps      | 4595712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038051736 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.14        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.122        |\n",
      "|    n_updates            | 27320        |\n",
      "|    policy_gradient_loss | -0.00729     |\n",
      "|    std                  | 14.5         |\n",
      "|    value_loss           | 0.456        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | -1.17        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2245         |\n",
      "|    time_elapsed         | 3511         |\n",
      "|    total_timesteps      | 4597760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073317233 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.15        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0537       |\n",
      "|    n_updates            | 27330        |\n",
      "|    policy_gradient_loss | -0.0095      |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.469        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4598528, episode_reward=-0.08 +/- 4.18\n",
      "Episode length: 30.90 +/- 11.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.9         |\n",
      "|    mean_reward          | -0.0772      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4598528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075453008 |\n",
      "|    clip_fraction        | 0.0609       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.18        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.319        |\n",
      "|    n_updates            | 27340        |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.645        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.653   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2246     |\n",
      "|    time_elapsed    | 3513     |\n",
      "|    total_timesteps | 4599808  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.517       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2247         |\n",
      "|    time_elapsed         | 3515         |\n",
      "|    total_timesteps      | 4601856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051983655 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.2         |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.312        |\n",
      "|    n_updates            | 27350        |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.737        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.299       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2248         |\n",
      "|    time_elapsed         | 3516         |\n",
      "|    total_timesteps      | 4603904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049060355 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.2         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.137        |\n",
      "|    n_updates            | 27360        |\n",
      "|    policy_gradient_loss | -0.0087      |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.388        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29           |\n",
      "|    ep_rew_mean          | 0.241        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2249         |\n",
      "|    time_elapsed         | 3518         |\n",
      "|    total_timesteps      | 4605952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075408886 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.19        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.08        |\n",
      "|    n_updates            | 27370        |\n",
      "|    policy_gradient_loss | -0.0089      |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.0384       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.0675      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2250        |\n",
      "|    time_elapsed         | 3519        |\n",
      "|    total_timesteps      | 4608000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011812578 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0863     |\n",
      "|    n_updates            | 27380       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 14.6        |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4608528, episode_reward=3.90 +/- 5.00\n",
      "Episode length: 23.50 +/- 9.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 23.5        |\n",
      "|    mean_reward          | 3.9         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4608528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008390149 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.16       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00173    |\n",
      "|    n_updates            | 27390       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 0.327       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.8     |\n",
      "|    ep_rew_mean     | 0.0284   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2251     |\n",
      "|    time_elapsed    | 3521     |\n",
      "|    total_timesteps | 4610048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2252        |\n",
      "|    time_elapsed         | 3522        |\n",
      "|    total_timesteps      | 4612096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006109033 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.884       |\n",
      "|    n_updates            | 27400       |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | -0.026       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2253         |\n",
      "|    time_elapsed         | 3524         |\n",
      "|    total_timesteps      | 4614144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041182875 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.17        |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.492        |\n",
      "|    n_updates            | 27410        |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.196      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2254        |\n",
      "|    time_elapsed         | 3525        |\n",
      "|    total_timesteps      | 4616192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005992232 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00858     |\n",
      "|    n_updates            | 27420       |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.282       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -0.543      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 3527        |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007419437 |\n",
      "|    clip_fraction        | 0.0406      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.255       |\n",
      "|    n_updates            | 27430       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4618528, episode_reward=0.57 +/- 4.59\n",
      "Episode length: 31.00 +/- 9.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31           |\n",
      "|    mean_reward          | 0.572        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4618528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060038976 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.16        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0457       |\n",
      "|    n_updates            | 27440        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.447        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.88    |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2256     |\n",
      "|    time_elapsed    | 3529     |\n",
      "|    total_timesteps | 4620288  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.548       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2257         |\n",
      "|    time_elapsed         | 3530         |\n",
      "|    total_timesteps      | 4622336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056015225 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.17        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 27450        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 0.695        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 0.244        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2258         |\n",
      "|    time_elapsed         | 3532         |\n",
      "|    total_timesteps      | 4624384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071785836 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.2         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.212        |\n",
      "|    n_updates            | 27460        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    std                  | 15           |\n",
      "|    value_loss           | 0.838        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.2         |\n",
      "|    ep_rew_mean          | 0.587        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2259         |\n",
      "|    time_elapsed         | 3533         |\n",
      "|    total_timesteps      | 4626432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065006427 |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.2         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0351       |\n",
      "|    n_updates            | 27470        |\n",
      "|    policy_gradient_loss | -0.00891     |\n",
      "|    std                  | 15.1         |\n",
      "|    value_loss           | 0.348        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.4        |\n",
      "|    ep_rew_mean          | -0.596      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2260        |\n",
      "|    time_elapsed         | 3535        |\n",
      "|    total_timesteps      | 4628480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007028134 |\n",
      "|    clip_fraction        | 0.056       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0144      |\n",
      "|    n_updates            | 27480       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 0.321       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4628528, episode_reward=-0.42 +/- 4.42\n",
      "Episode length: 30.10 +/- 7.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30.1        |\n",
      "|    mean_reward          | -0.421      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4628528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009994946 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 27490       |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    std                  | 15.3        |\n",
      "|    value_loss           | 0.51        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.564   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2261     |\n",
      "|    time_elapsed    | 3537     |\n",
      "|    total_timesteps | 4630528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.252      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2262        |\n",
      "|    time_elapsed         | 3538        |\n",
      "|    total_timesteps      | 4632576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005024712 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.23       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 27500       |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    std                  | 15.2        |\n",
      "|    value_loss           | 0.504       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.0893      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2263        |\n",
      "|    time_elapsed         | 3540        |\n",
      "|    total_timesteps      | 4634624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008499149 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0036      |\n",
      "|    n_updates            | 27510       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.395       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2264        |\n",
      "|    time_elapsed         | 3541        |\n",
      "|    total_timesteps      | 4636672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007211295 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 27520       |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 0.978       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4638528, episode_reward=0.12 +/- 5.47\n",
      "Episode length: 29.50 +/- 9.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 29.5       |\n",
      "|    mean_reward          | 0.12       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4638528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00670153 |\n",
      "|    clip_fraction        | 0.0467     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.22      |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.065      |\n",
      "|    n_updates            | 27530      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    std                  | 15         |\n",
      "|    value_loss           | 0.396      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -0.419   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2265     |\n",
      "|    time_elapsed    | 3542     |\n",
      "|    total_timesteps | 4638720  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | -0.216       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2266         |\n",
      "|    time_elapsed         | 3544         |\n",
      "|    total_timesteps      | 4640768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063414793 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.21        |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.22         |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.00718     |\n",
      "|    std                  | 14.9         |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.5        |\n",
      "|    ep_rew_mean          | -0.159      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2267        |\n",
      "|    time_elapsed         | 3545        |\n",
      "|    total_timesteps      | 4642816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008647411 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 27550       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 14.8        |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.383       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2268         |\n",
      "|    time_elapsed         | 3547         |\n",
      "|    total_timesteps      | 4644864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073207566 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.17        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0255       |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    std                  | 14.6         |\n",
      "|    value_loss           | 0.363        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.191       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2269        |\n",
      "|    time_elapsed         | 3548        |\n",
      "|    total_timesteps      | 4646912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007003281 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.17       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 27570       |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    std                  | 14.7        |\n",
      "|    value_loss           | 0.439       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4648528, episode_reward=2.01 +/- 3.47\n",
      "Episode length: 26.50 +/- 5.64\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 26.5         |\n",
      "|    mean_reward          | 2.01         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4648528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042866278 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.18        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.1          |\n",
      "|    n_updates            | 27580        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 14.7         |\n",
      "|    value_loss           | 0.353        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.2     |\n",
      "|    ep_rew_mean     | -0.941   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2270     |\n",
      "|    time_elapsed    | 3550     |\n",
      "|    total_timesteps | 4648960  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 0.0676       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2271         |\n",
      "|    time_elapsed         | 3551         |\n",
      "|    total_timesteps      | 4651008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039422135 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.18        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.103        |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | -0.00817     |\n",
      "|    std                  | 14.8         |\n",
      "|    value_loss           | 0.419        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 3553        |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006463575 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.19       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 27600       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.102      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2273        |\n",
      "|    time_elapsed         | 3554        |\n",
      "|    total_timesteps      | 4655104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010860136 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.21       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0666      |\n",
      "|    n_updates            | 27610       |\n",
      "|    policy_gradient_loss | -0.00919    |\n",
      "|    std                  | 14.9        |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.192      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2274        |\n",
      "|    time_elapsed         | 3556        |\n",
      "|    total_timesteps      | 4657152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011083266 |\n",
      "|    clip_fraction        | 0.0839      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.22       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 27620       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 15.1        |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4658528, episode_reward=-0.44 +/- 3.55\n",
      "Episode length: 33.10 +/- 9.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.1        |\n",
      "|    mean_reward          | -0.443      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4658528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007913042 |\n",
      "|    clip_fraction        | 0.0547      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.25       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 27630       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 15.4        |\n",
      "|    value_loss           | 0.698       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -0.384   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2275     |\n",
      "|    time_elapsed    | 3557     |\n",
      "|    total_timesteps | 4659200  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.485        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2276         |\n",
      "|    time_elapsed         | 3559         |\n",
      "|    total_timesteps      | 4661248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048357146 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.28        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.221        |\n",
      "|    n_updates            | 27640        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.4         |\n",
      "|    ep_rew_mean          | 0.948        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1309         |\n",
      "|    iterations           | 2277         |\n",
      "|    time_elapsed         | 3560         |\n",
      "|    total_timesteps      | 4663296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067785997 |\n",
      "|    clip_fraction        | 0.0583       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.28        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0897       |\n",
      "|    n_updates            | 27650        |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    std                  | 15.5         |\n",
      "|    value_loss           | 0.541        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | -0.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2278        |\n",
      "|    time_elapsed         | 3561        |\n",
      "|    total_timesteps      | 4665344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007063847 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.31       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0458     |\n",
      "|    n_updates            | 27660       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 0.22        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.6       |\n",
      "|    ep_rew_mean          | 0.548      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1309       |\n",
      "|    iterations           | 2279       |\n",
      "|    time_elapsed         | 3563       |\n",
      "|    total_timesteps      | 4667392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00659654 |\n",
      "|    clip_fraction        | 0.0561     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.34      |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.217      |\n",
      "|    n_updates            | 27670      |\n",
      "|    policy_gradient_loss | -0.00978   |\n",
      "|    std                  | 16         |\n",
      "|    value_loss           | 0.619      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4668528, episode_reward=0.92 +/- 4.50\n",
      "Episode length: 27.20 +/- 7.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.2        |\n",
      "|    mean_reward          | 0.923       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4668528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009852601 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.33       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0277     |\n",
      "|    n_updates            | 27680       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.348   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2280     |\n",
      "|    time_elapsed    | 3565     |\n",
      "|    total_timesteps | 4669440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.264      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2281        |\n",
      "|    time_elapsed         | 3566        |\n",
      "|    total_timesteps      | 4671488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005220172 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.33       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0936      |\n",
      "|    n_updates            | 27690       |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.264       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2282        |\n",
      "|    time_elapsed         | 3567        |\n",
      "|    total_timesteps      | 4673536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006593708 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.33       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.000973   |\n",
      "|    n_updates            | 27700       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 15.9        |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.161      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2283        |\n",
      "|    time_elapsed         | 3569        |\n",
      "|    total_timesteps      | 4675584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005782393 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.34       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0913      |\n",
      "|    n_updates            | 27710       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 0.473       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.983      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2284        |\n",
      "|    time_elapsed         | 3570        |\n",
      "|    total_timesteps      | 4677632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006429366 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.35       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0469     |\n",
      "|    n_updates            | 27720       |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    std                  | 16          |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4678528, episode_reward=2.07 +/- 5.62\n",
      "Episode length: 24.50 +/- 9.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 24.5        |\n",
      "|    mean_reward          | 2.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4678528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006894079 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.34       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 27730       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 0.602       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.264   |\n",
      "| time/              |          |\n",
      "|    fps             | 1309     |\n",
      "|    iterations      | 2285     |\n",
      "|    time_elapsed    | 3572     |\n",
      "|    total_timesteps | 4679680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.00622     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 2286        |\n",
      "|    time_elapsed         | 3573        |\n",
      "|    total_timesteps      | 4681728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008941864 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.36       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0712      |\n",
      "|    n_updates            | 27740       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 0.477       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.6         |\n",
      "|    ep_rew_mean          | 0.314        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2287         |\n",
      "|    time_elapsed         | 3575         |\n",
      "|    total_timesteps      | 4683776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057093464 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.36        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0848       |\n",
      "|    n_updates            | 27750        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    std                  | 16.2         |\n",
      "|    value_loss           | 0.294        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.9         |\n",
      "|    ep_rew_mean          | 0.745        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2288         |\n",
      "|    time_elapsed         | 3576         |\n",
      "|    total_timesteps      | 4685824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054185884 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.37        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.00661      |\n",
      "|    n_updates            | 27760        |\n",
      "|    policy_gradient_loss | -0.00918     |\n",
      "|    std                  | 16.1         |\n",
      "|    value_loss           | 0.208        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.175      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2289        |\n",
      "|    time_elapsed         | 3578        |\n",
      "|    total_timesteps      | 4687872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009578583 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.36       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0949      |\n",
      "|    n_updates            | 27770       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 16.1        |\n",
      "|    value_loss           | 0.338       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4688528, episode_reward=0.04 +/- 5.36\n",
      "Episode length: 29.70 +/- 6.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.7        |\n",
      "|    mean_reward          | 0.035       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4688528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013303734 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.37       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 27780       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 16.4        |\n",
      "|    value_loss           | 0.615       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -1.05    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2290     |\n",
      "|    time_elapsed    | 3579     |\n",
      "|    total_timesteps | 4689920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -1.27       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2291        |\n",
      "|    time_elapsed         | 3581        |\n",
      "|    total_timesteps      | 4691968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006236448 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.4        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0453     |\n",
      "|    n_updates            | 27790       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 16.6        |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.3         |\n",
      "|    ep_rew_mean          | -1.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2292         |\n",
      "|    time_elapsed         | 3582         |\n",
      "|    total_timesteps      | 4694016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069474652 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.42        |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.403        |\n",
      "|    n_updates            | 27800        |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    std                  | 16.6         |\n",
      "|    value_loss           | 0.868        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.2       |\n",
      "|    ep_rew_mean          | -1.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 2293       |\n",
      "|    time_elapsed         | 3584       |\n",
      "|    total_timesteps      | 4696064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00803892 |\n",
      "|    clip_fraction        | 0.049      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.41      |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.000928  |\n",
      "|    n_updates            | 27810      |\n",
      "|    policy_gradient_loss | -0.00923   |\n",
      "|    std                  | 16.4       |\n",
      "|    value_loss           | 0.255      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 32.2       |\n",
      "|    ep_rew_mean          | -0.727     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1310       |\n",
      "|    iterations           | 2294       |\n",
      "|    time_elapsed         | 3585       |\n",
      "|    total_timesteps      | 4698112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00663726 |\n",
      "|    clip_fraction        | 0.073      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.41      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.144      |\n",
      "|    n_updates            | 27820      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    std                  | 16.6       |\n",
      "|    value_loss           | 0.499      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4698528, episode_reward=0.57 +/- 3.38\n",
      "Episode length: 30.00 +/- 4.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30           |\n",
      "|    mean_reward          | 0.573        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4698528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034455645 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.44        |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.275        |\n",
      "|    n_updates            | 27830        |\n",
      "|    policy_gradient_loss | -0.00832     |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.47    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2295     |\n",
      "|    time_elapsed    | 3587     |\n",
      "|    total_timesteps | 4700160  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.352       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2296         |\n",
      "|    time_elapsed         | 3588         |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058667464 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.45        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.537        |\n",
      "|    n_updates            | 27840        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 0.98         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.939      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2297        |\n",
      "|    time_elapsed         | 3590        |\n",
      "|    total_timesteps      | 4704256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008916415 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.416       |\n",
      "|    n_updates            | 27850       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 0.987       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.471      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2298        |\n",
      "|    time_elapsed         | 3591        |\n",
      "|    total_timesteps      | 4706304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005892623 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 27860       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 0.395       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2299        |\n",
      "|    time_elapsed         | 3593        |\n",
      "|    total_timesteps      | 4708352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004786106 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.025      |\n",
      "|    n_updates            | 27870       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4708528, episode_reward=-2.01 +/- 6.74\n",
      "Episode length: 32.20 +/- 9.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.2        |\n",
      "|    mean_reward          | -2.01       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4708528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007194047 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.45       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 27880       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 16.8        |\n",
      "|    value_loss           | 0.676       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.412    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2300     |\n",
      "|    time_elapsed    | 3594     |\n",
      "|    total_timesteps | 4710400  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.7         |\n",
      "|    ep_rew_mean          | 0.27         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2301         |\n",
      "|    time_elapsed         | 3596         |\n",
      "|    total_timesteps      | 4712448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037846756 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.46        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.00657      |\n",
      "|    n_updates            | 27890        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 0.315        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.5        |\n",
      "|    ep_rew_mean          | -0.0483     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2302        |\n",
      "|    time_elapsed         | 3597        |\n",
      "|    total_timesteps      | 4714496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012451791 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.44       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0217      |\n",
      "|    n_updates            | 27900       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 16.7        |\n",
      "|    value_loss           | 0.253       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.2        |\n",
      "|    ep_rew_mean          | -0.0533     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2303        |\n",
      "|    time_elapsed         | 3599        |\n",
      "|    total_timesteps      | 4716544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009976569 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.44       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 27910       |\n",
      "|    policy_gradient_loss | -0.00873    |\n",
      "|    std                  | 16.9        |\n",
      "|    value_loss           | 0.501       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4718528, episode_reward=1.99 +/- 3.57\n",
      "Episode length: 26.00 +/- 6.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26          |\n",
      "|    mean_reward          | 1.99        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4718528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009050855 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.46       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 27920       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 0.853       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.494   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2304     |\n",
      "|    time_elapsed    | 3600     |\n",
      "|    total_timesteps | 4718592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.8        |\n",
      "|    ep_rew_mean          | -1.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2305        |\n",
      "|    time_elapsed         | 3602        |\n",
      "|    total_timesteps      | 4720640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005775955 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.47       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 27930       |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    std                  | 17          |\n",
      "|    value_loss           | 0.874       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.9         |\n",
      "|    ep_rew_mean          | -1.47        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2306         |\n",
      "|    time_elapsed         | 3603         |\n",
      "|    total_timesteps      | 4722688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048316848 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.47        |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.24         |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 1.06         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.4         |\n",
      "|    ep_rew_mean          | 0.808        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2307         |\n",
      "|    time_elapsed         | 3605         |\n",
      "|    total_timesteps      | 4724736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065285657 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.45        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0652      |\n",
      "|    n_updates            | 27950        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    std                  | 16.8         |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | 0.308        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2308         |\n",
      "|    time_elapsed         | 3606         |\n",
      "|    total_timesteps      | 4726784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038063708 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.45        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0663       |\n",
      "|    n_updates            | 27960        |\n",
      "|    policy_gradient_loss | -0.00827     |\n",
      "|    std                  | 16.9         |\n",
      "|    value_loss           | 0.518        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4728528, episode_reward=1.68 +/- 5.09\n",
      "Episode length: 27.70 +/- 9.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.7        |\n",
      "|    mean_reward          | 1.68        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4728528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008321219 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.47       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 27970       |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    std                  | 17.1        |\n",
      "|    value_loss           | 0.527       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.284   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2309     |\n",
      "|    time_elapsed    | 3608     |\n",
      "|    total_timesteps | 4728832  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.641       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2310         |\n",
      "|    time_elapsed         | 3609         |\n",
      "|    total_timesteps      | 4730880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056838947 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.48        |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.991        |\n",
      "|    n_updates            | 27980        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    std                  | 17.3         |\n",
      "|    value_loss           | 1.94         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | -0.00136    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2311        |\n",
      "|    time_elapsed         | 3611        |\n",
      "|    total_timesteps      | 4732928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005607414 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.51       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.394       |\n",
      "|    n_updates            | 27990       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    std                  | 17.4        |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.8         |\n",
      "|    ep_rew_mean          | -0.0511      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 3612         |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039983746 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.53        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0291      |\n",
      "|    n_updates            | 28000        |\n",
      "|    policy_gradient_loss | -0.00829     |\n",
      "|    std                  | 17.6         |\n",
      "|    value_loss           | 0.24         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.5         |\n",
      "|    ep_rew_mean          | -1.44        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2313         |\n",
      "|    time_elapsed         | 3613         |\n",
      "|    total_timesteps      | 4737024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059494637 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.55        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.075        |\n",
      "|    n_updates            | 28010        |\n",
      "|    policy_gradient_loss | -0.0075      |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 0.333        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4738528, episode_reward=-1.79 +/- 4.59\n",
      "Episode length: 29.90 +/- 7.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.9         |\n",
      "|    mean_reward          | -1.79        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4738528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041299784 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.58        |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.674        |\n",
      "|    n_updates            | 28020        |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 1.62         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.9     |\n",
      "|    ep_rew_mean     | -1.24    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2314     |\n",
      "|    time_elapsed    | 3615     |\n",
      "|    total_timesteps | 4739072  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.9         |\n",
      "|    ep_rew_mean          | -0.784       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2315         |\n",
      "|    time_elapsed         | 3617         |\n",
      "|    total_timesteps      | 4741120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050291223 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.58        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.176        |\n",
      "|    n_updates            | 28030        |\n",
      "|    policy_gradient_loss | -0.008       |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 0.593        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.5         |\n",
      "|    ep_rew_mean          | -0.887       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2316         |\n",
      "|    time_elapsed         | 3618         |\n",
      "|    total_timesteps      | 4743168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035805916 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.57        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.15         |\n",
      "|    n_updates            | 28040        |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 0.713        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -0.352      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2317        |\n",
      "|    time_elapsed         | 3619        |\n",
      "|    total_timesteps      | 4745216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005933731 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.56       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.395       |\n",
      "|    n_updates            | 28050       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    std                  | 17.8        |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 33.3      |\n",
      "|    ep_rew_mean          | -0.392    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1310      |\n",
      "|    iterations           | 2318      |\n",
      "|    time_elapsed         | 3621      |\n",
      "|    total_timesteps      | 4747264   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0060797 |\n",
      "|    clip_fraction        | 0.0416    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -8.55     |\n",
      "|    explained_variance   | 0.923     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.395     |\n",
      "|    n_updates            | 28060     |\n",
      "|    policy_gradient_loss | -0.00867  |\n",
      "|    std                  | 17.7      |\n",
      "|    value_loss           | 1.26      |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4748528, episode_reward=-1.08 +/- 4.47\n",
      "Episode length: 31.30 +/- 6.63\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 31.3       |\n",
      "|    mean_reward          | -1.08      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4748528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00903363 |\n",
      "|    clip_fraction        | 0.0628     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.55      |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.502      |\n",
      "|    n_updates            | 28070      |\n",
      "|    policy_gradient_loss | -0.00927   |\n",
      "|    std                  | 17.8       |\n",
      "|    value_loss           | 1.3        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -0.44    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2319     |\n",
      "|    time_elapsed    | 3623     |\n",
      "|    total_timesteps | 4749312  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.2         |\n",
      "|    ep_rew_mean          | 0.932        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2320         |\n",
      "|    time_elapsed         | 3625         |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043894257 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.56        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.234        |\n",
      "|    n_updates            | 28080        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    std                  | 17.8         |\n",
      "|    value_loss           | 0.799        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | 0.554        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2321         |\n",
      "|    time_elapsed         | 3626         |\n",
      "|    total_timesteps      | 4753408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039002188 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.57        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0602       |\n",
      "|    n_updates            | 28090        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 0.455        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.7         |\n",
      "|    ep_rew_mean          | -0.144       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2322         |\n",
      "|    time_elapsed         | 3628         |\n",
      "|    total_timesteps      | 4755456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059582107 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.6         |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.279        |\n",
      "|    n_updates            | 28100        |\n",
      "|    policy_gradient_loss | -0.00961     |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 0.886        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -0.917       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2323         |\n",
      "|    time_elapsed         | 3629         |\n",
      "|    total_timesteps      | 4757504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066018263 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.59        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.237        |\n",
      "|    n_updates            | 28110        |\n",
      "|    policy_gradient_loss | -0.00973     |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 1.01         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4758528, episode_reward=-0.47 +/- 6.67\n",
      "Episode length: 28.20 +/- 10.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28.2         |\n",
      "|    mean_reward          | -0.474       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4758528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058842837 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.57        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0153      |\n",
      "|    n_updates            | 28120        |\n",
      "|    policy_gradient_loss | -0.00823     |\n",
      "|    std                  | 18           |\n",
      "|    value_loss           | 0.404        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -0.855   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2324     |\n",
      "|    time_elapsed    | 3631     |\n",
      "|    total_timesteps | 4759552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.947      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2325        |\n",
      "|    time_elapsed         | 3632        |\n",
      "|    total_timesteps      | 4761600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008728356 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.58       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 28130       |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 0.882       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.557       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2326         |\n",
      "|    time_elapsed         | 3634         |\n",
      "|    total_timesteps      | 4763648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052904706 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.58        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0391      |\n",
      "|    n_updates            | 28140        |\n",
      "|    policy_gradient_loss | -0.00852     |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 0.338        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | -0.432       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2327         |\n",
      "|    time_elapsed         | 3635         |\n",
      "|    total_timesteps      | 4765696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047913594 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.58        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.171        |\n",
      "|    n_updates            | 28150        |\n",
      "|    policy_gradient_loss | -0.00755     |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 0.588        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.38        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 3637         |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061048362 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.58        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0887       |\n",
      "|    n_updates            | 28160        |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    std                  | 18.1         |\n",
      "|    value_loss           | 0.472        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4768528, episode_reward=1.96 +/- 3.25\n",
      "Episode length: 26.60 +/- 4.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.6        |\n",
      "|    mean_reward          | 1.96        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4768528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007468582 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.58       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 28170       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 18          |\n",
      "|    value_loss           | 0.593       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | 0.217    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2329     |\n",
      "|    time_elapsed    | 3638     |\n",
      "|    total_timesteps | 4769792  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.109       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2330         |\n",
      "|    time_elapsed         | 3640         |\n",
      "|    total_timesteps      | 4771840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057244166 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.57        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.021        |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    std                  | 17.9         |\n",
      "|    value_loss           | 0.233        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.484      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2331        |\n",
      "|    time_elapsed         | 3641        |\n",
      "|    total_timesteps      | 4773888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009718033 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.56       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 28190       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    std                  | 17.9        |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.999      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2332        |\n",
      "|    time_elapsed         | 3643        |\n",
      "|    total_timesteps      | 4775936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005874113 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.57       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0045     |\n",
      "|    n_updates            | 28200       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    std                  | 18.1        |\n",
      "|    value_loss           | 0.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.2        |\n",
      "|    ep_rew_mean          | -1.21       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2333        |\n",
      "|    time_elapsed         | 3644        |\n",
      "|    total_timesteps      | 4777984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007930555 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.6        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0831      |\n",
      "|    n_updates            | 28210       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 18.3        |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4778528, episode_reward=-0.60 +/- 3.80\n",
      "Episode length: 30.00 +/- 5.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | -0.597      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4778528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007182142 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.63       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.402       |\n",
      "|    n_updates            | 28220       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 1.12        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.3     |\n",
      "|    ep_rew_mean     | -0.885   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2334     |\n",
      "|    time_elapsed    | 3646     |\n",
      "|    total_timesteps | 4780032  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | -1.13        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2335         |\n",
      "|    time_elapsed         | 3647         |\n",
      "|    total_timesteps      | 4782080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069702417 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.65        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.154        |\n",
      "|    n_updates            | 28230        |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 0.669        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.463       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2336         |\n",
      "|    time_elapsed         | 3649         |\n",
      "|    total_timesteps      | 4784128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056164735 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.66        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0125       |\n",
      "|    n_updates            | 28240        |\n",
      "|    policy_gradient_loss | -0.00864     |\n",
      "|    std                  | 18.6         |\n",
      "|    value_loss           | 0.331        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -1.14       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2337        |\n",
      "|    time_elapsed         | 3650        |\n",
      "|    total_timesteps      | 4786176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007975254 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.64       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.119       |\n",
      "|    n_updates            | 28250       |\n",
      "|    policy_gradient_loss | -0.00946    |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 0.621       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.551       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 3652         |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060862843 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.64        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.208        |\n",
      "|    n_updates            | 28260        |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    std                  | 18.5         |\n",
      "|    value_loss           | 0.527        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4788528, episode_reward=-6.69 +/- 3.69\n",
      "Episode length: 37.90 +/- 4.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 37.9        |\n",
      "|    mean_reward          | -6.69       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4788528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007551105 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.66       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 28270       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 18.8        |\n",
      "|    value_loss           | 0.565       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.7     |\n",
      "|    ep_rew_mean     | 0.244    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2339     |\n",
      "|    time_elapsed    | 3654     |\n",
      "|    total_timesteps | 4790272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.5        |\n",
      "|    ep_rew_mean          | 0.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2340        |\n",
      "|    time_elapsed         | 3655        |\n",
      "|    total_timesteps      | 4792320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008517336 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0737     |\n",
      "|    n_updates            | 28280       |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 0.0643      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31          |\n",
      "|    ep_rew_mean          | -0.498      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2341        |\n",
      "|    time_elapsed         | 3657        |\n",
      "|    total_timesteps      | 4794368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005285467 |\n",
      "|    clip_fraction        | 0.0284      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 28290       |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.599      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2342        |\n",
      "|    time_elapsed         | 3658        |\n",
      "|    total_timesteps      | 4796416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008548684 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.00242     |\n",
      "|    n_updates            | 28300       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2343        |\n",
      "|    time_elapsed         | 3660        |\n",
      "|    total_timesteps      | 4798464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005145264 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.68       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.462       |\n",
      "|    n_updates            | 28310       |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4798528, episode_reward=1.91 +/- 4.45\n",
      "Episode length: 26.40 +/- 9.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.4        |\n",
      "|    mean_reward          | 1.91        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4798528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004607477 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.66       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 28320       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 18.6        |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.415   |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2344     |\n",
      "|    time_elapsed    | 3661     |\n",
      "|    total_timesteps | 4800512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.253       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2345        |\n",
      "|    time_elapsed         | 3663        |\n",
      "|    total_timesteps      | 4802560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006195799 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.65       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0636      |\n",
      "|    n_updates            | 28330       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 0.346       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.2         |\n",
      "|    ep_rew_mean          | 0.481        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1310         |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 3664         |\n",
      "|    total_timesteps      | 4804608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063136495 |\n",
      "|    clip_fraction        | 0.077        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.64        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.354        |\n",
      "|    n_updates            | 28340        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 0.774        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | -0.17       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2347        |\n",
      "|    time_elapsed         | 3666        |\n",
      "|    total_timesteps      | 4806656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004323202 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.67       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0331     |\n",
      "|    n_updates            | 28350       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4808528, episode_reward=-1.15 +/- 3.53\n",
      "Episode length: 31.10 +/- 5.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.1         |\n",
      "|    mean_reward          | -1.15        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4808528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049075503 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.7         |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0183       |\n",
      "|    n_updates            | 28360        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 0.417        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.6     |\n",
      "|    ep_rew_mean     | -1.31    |\n",
      "| time/              |          |\n",
      "|    fps             | 1310     |\n",
      "|    iterations      | 2348     |\n",
      "|    time_elapsed    | 3667     |\n",
      "|    total_timesteps | 4808704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1310        |\n",
      "|    iterations           | 2349        |\n",
      "|    time_elapsed         | 3669        |\n",
      "|    total_timesteps      | 4810752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005850864 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.7        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 28370       |\n",
      "|    policy_gradient_loss | -0.00851    |\n",
      "|    std                  | 19.1        |\n",
      "|    value_loss           | 0.985       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.9         |\n",
      "|    ep_rew_mean          | -1.15        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2350         |\n",
      "|    time_elapsed         | 3670         |\n",
      "|    total_timesteps      | 4812800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044091786 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.69        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.174        |\n",
      "|    n_updates            | 28380        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 0.878        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | -0.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2351         |\n",
      "|    time_elapsed         | 3672         |\n",
      "|    total_timesteps      | 4814848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046155793 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.69        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.301        |\n",
      "|    n_updates            | 28390        |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    std                  | 19           |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.1        |\n",
      "|    ep_rew_mean          | -0.106      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2352        |\n",
      "|    time_elapsed         | 3673        |\n",
      "|    total_timesteps      | 4816896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004539429 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.315       |\n",
      "|    n_updates            | 28400       |\n",
      "|    policy_gradient_loss | -0.00782    |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4818528, episode_reward=2.48 +/- 5.18\n",
      "Episode length: 26.40 +/- 14.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 26.4        |\n",
      "|    mean_reward          | 2.48        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4818528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003150222 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 28410       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 0.559       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | -0.816   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2353     |\n",
      "|    time_elapsed    | 3675     |\n",
      "|    total_timesteps | 4818944  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.469       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2354         |\n",
      "|    time_elapsed         | 3676         |\n",
      "|    total_timesteps      | 4820992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069039944 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.68        |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 28420        |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 0.629        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.708      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2355        |\n",
      "|    time_elapsed         | 3678        |\n",
      "|    total_timesteps      | 4823040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006420459 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.65       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0715      |\n",
      "|    n_updates            | 28430       |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    std                  | 18.5        |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.624       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2356        |\n",
      "|    time_elapsed         | 3679        |\n",
      "|    total_timesteps      | 4825088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005435122 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.65       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 28440       |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    std                  | 18.6        |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 0.652        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2357         |\n",
      "|    time_elapsed         | 3681         |\n",
      "|    total_timesteps      | 4827136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099828895 |\n",
      "|    clip_fraction        | 0.0845       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.67        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.124        |\n",
      "|    n_updates            | 28450        |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 0.55         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4828528, episode_reward=-2.74 +/- 4.30\n",
      "Episode length: 33.90 +/- 5.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.9        |\n",
      "|    mean_reward          | -2.74       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4828528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005386769 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.384       |\n",
      "|    n_updates            | 28460       |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    std                  | 19          |\n",
      "|    value_loss           | 0.81        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.406   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2358     |\n",
      "|    time_elapsed    | 3683     |\n",
      "|    total_timesteps | 4829184  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.6         |\n",
      "|    ep_rew_mean          | -0.85        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2359         |\n",
      "|    time_elapsed         | 3684         |\n",
      "|    total_timesteps      | 4831232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048743556 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.7         |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.338        |\n",
      "|    n_updates            | 28470        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    std                  | 18.9         |\n",
      "|    value_loss           | 1.1          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.3         |\n",
      "|    ep_rew_mean          | -1.09        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 3686         |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049628727 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.68        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.311        |\n",
      "|    n_updates            | 28480        |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    std                  | 18.7         |\n",
      "|    value_loss           | 0.955        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.3         |\n",
      "|    ep_rew_mean          | -0.286       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2361         |\n",
      "|    time_elapsed         | 3687         |\n",
      "|    total_timesteps      | 4835328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042319577 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.68        |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.3          |\n",
      "|    n_updates            | 28490        |\n",
      "|    policy_gradient_loss | -0.00917     |\n",
      "|    std                  | 18.8         |\n",
      "|    value_loss           | 0.784        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.6        |\n",
      "|    ep_rew_mean          | 1.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2362        |\n",
      "|    time_elapsed         | 3689        |\n",
      "|    total_timesteps      | 4837376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005253965 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.69       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 28500       |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    std                  | 18.9        |\n",
      "|    value_loss           | 0.484       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4838528, episode_reward=0.20 +/- 2.78\n",
      "Episode length: 32.60 +/- 6.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 32.6        |\n",
      "|    mean_reward          | 0.201       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4838528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004731254 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.71       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 28510       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 19.2        |\n",
      "|    value_loss           | 0.194       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -0.65    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2363     |\n",
      "|    time_elapsed    | 3690     |\n",
      "|    total_timesteps | 4839424  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -0.922       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2364         |\n",
      "|    time_elapsed         | 3692         |\n",
      "|    total_timesteps      | 4841472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059343386 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.73        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.279        |\n",
      "|    n_updates            | 28520        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    std                  | 19.3         |\n",
      "|    value_loss           | 0.896        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.8         |\n",
      "|    ep_rew_mean          | -0.224       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2365         |\n",
      "|    time_elapsed         | 3693         |\n",
      "|    total_timesteps      | 4843520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069542476 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.75        |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.183        |\n",
      "|    n_updates            | 28530        |\n",
      "|    policy_gradient_loss | -0.00799     |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 0.835        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | -0.636      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2366        |\n",
      "|    time_elapsed         | 3695        |\n",
      "|    total_timesteps      | 4845568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005868142 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.77       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.387       |\n",
      "|    n_updates            | 28540       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    std                  | 19.6        |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.473       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2367        |\n",
      "|    time_elapsed         | 3696        |\n",
      "|    total_timesteps      | 4847616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006089842 |\n",
      "|    clip_fraction        | 0.0347      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.77       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0865      |\n",
      "|    n_updates            | 28550       |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    std                  | 19.7        |\n",
      "|    value_loss           | 0.532       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4848528, episode_reward=0.78 +/- 5.17\n",
      "Episode length: 29.30 +/- 6.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 29.3         |\n",
      "|    mean_reward          | 0.78         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4848528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061424864 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.78        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.195        |\n",
      "|    n_updates            | 28560        |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 0.526        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | -0.548   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2368     |\n",
      "|    time_elapsed    | 3698     |\n",
      "|    total_timesteps | 4849664  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.401       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2369         |\n",
      "|    time_elapsed         | 3699         |\n",
      "|    total_timesteps      | 4851712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065956446 |\n",
      "|    clip_fraction        | 0.0401       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.79        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.133        |\n",
      "|    n_updates            | 28570        |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    std                  | 19.9         |\n",
      "|    value_loss           | 0.647        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31        |\n",
      "|    ep_rew_mean          | -0.48     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1311      |\n",
      "|    iterations           | 2370      |\n",
      "|    time_elapsed         | 3701      |\n",
      "|    total_timesteps      | 4853760   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0065643 |\n",
      "|    clip_fraction        | 0.0474    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -8.79     |\n",
      "|    explained_variance   | 0.974     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | 0.0899    |\n",
      "|    n_updates            | 28580     |\n",
      "|    policy_gradient_loss | -0.00933  |\n",
      "|    std                  | 19.8      |\n",
      "|    value_loss           | 0.401     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.5       |\n",
      "|    ep_rew_mean          | -0.284     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 2371       |\n",
      "|    time_elapsed         | 3702       |\n",
      "|    total_timesteps      | 4855808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00893944 |\n",
      "|    clip_fraction        | 0.0744     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.78      |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.189      |\n",
      "|    n_updates            | 28590      |\n",
      "|    policy_gradient_loss | -0.00975   |\n",
      "|    std                  | 19.8       |\n",
      "|    value_loss           | 0.55       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.6       |\n",
      "|    ep_rew_mean          | 0.0551     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 2372       |\n",
      "|    time_elapsed         | 3704       |\n",
      "|    total_timesteps      | 4857856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00579746 |\n",
      "|    clip_fraction        | 0.0327     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.79      |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.303      |\n",
      "|    n_updates            | 28600      |\n",
      "|    policy_gradient_loss | -0.00681   |\n",
      "|    std                  | 19.9       |\n",
      "|    value_loss           | 0.756      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4858528, episode_reward=-3.03 +/- 4.77\n",
      "Episode length: 32.50 +/- 7.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.5         |\n",
      "|    mean_reward          | -3.03        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4858528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054793437 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.8         |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.128        |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    std                  | 19.8         |\n",
      "|    value_loss           | 0.76         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | -0.184   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2373     |\n",
      "|    time_elapsed    | 3706     |\n",
      "|    total_timesteps | 4859904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | 0.177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2374        |\n",
      "|    time_elapsed         | 3707        |\n",
      "|    total_timesteps      | 4861952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008638842 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.8        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 28620       |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 0.577       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 31.1      |\n",
      "|    ep_rew_mean          | -0.462    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1311      |\n",
      "|    iterations           | 2375      |\n",
      "|    time_elapsed         | 3709      |\n",
      "|    total_timesteps      | 4864000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0039877 |\n",
      "|    clip_fraction        | 0.0243    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -8.82     |\n",
      "|    explained_variance   | 0.977     |\n",
      "|    learning_rate        | 0.001     |\n",
      "|    loss                 | -0.0055   |\n",
      "|    n_updates            | 28630     |\n",
      "|    policy_gradient_loss | -0.00573  |\n",
      "|    std                  | 20.1      |\n",
      "|    value_loss           | 0.269     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.7         |\n",
      "|    ep_rew_mean          | -1.25        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2376         |\n",
      "|    time_elapsed         | 3710         |\n",
      "|    total_timesteps      | 4866048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080318805 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.83        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.252        |\n",
      "|    n_updates            | 28640        |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 0.877        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0265      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2377        |\n",
      "|    time_elapsed         | 3712        |\n",
      "|    total_timesteps      | 4868096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003525388 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.84       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.263       |\n",
      "|    n_updates            | 28650       |\n",
      "|    policy_gradient_loss | -0.00748    |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.924       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4868528, episode_reward=-4.61 +/- 5.27\n",
      "Episode length: 34.90 +/- 7.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 34.9        |\n",
      "|    mean_reward          | -4.61       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4868528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007818468 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.83       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 28660       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.145    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2378     |\n",
      "|    time_elapsed    | 3713     |\n",
      "|    total_timesteps | 4870144  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | -0.0363      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2379         |\n",
      "|    time_elapsed         | 3715         |\n",
      "|    total_timesteps      | 4872192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058447476 |\n",
      "|    clip_fraction        | 0.0675       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.82        |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.246        |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | -0.00896     |\n",
      "|    std                  | 20           |\n",
      "|    value_loss           | 1.55         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.4       |\n",
      "|    ep_rew_mean          | -0.873     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 2380       |\n",
      "|    time_elapsed         | 3716       |\n",
      "|    total_timesteps      | 4874240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00591268 |\n",
      "|    clip_fraction        | 0.0408     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.82      |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | -0.0655    |\n",
      "|    n_updates            | 28680      |\n",
      "|    policy_gradient_loss | -0.00758   |\n",
      "|    std                  | 20.1       |\n",
      "|    value_loss           | 0.167      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.52       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2381        |\n",
      "|    time_elapsed         | 3718        |\n",
      "|    total_timesteps      | 4876288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010606386 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.81       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.389       |\n",
      "|    n_updates            | 28690       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 0.807       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | -0.322      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2382        |\n",
      "|    time_elapsed         | 3719        |\n",
      "|    total_timesteps      | 4878336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006059901 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.83       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.065      |\n",
      "|    n_updates            | 28700       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4878528, episode_reward=-3.43 +/- 7.07\n",
      "Episode length: 36.80 +/- 15.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 36.8        |\n",
      "|    mean_reward          | -3.43       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4878528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006838183 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.85       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0433      |\n",
      "|    n_updates            | 28710       |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.397       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.205    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2383     |\n",
      "|    time_elapsed    | 3721     |\n",
      "|    total_timesteps | 4880384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.0419      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2384        |\n",
      "|    time_elapsed         | 3723        |\n",
      "|    total_timesteps      | 4882432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006905335 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.85       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 28720       |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.566       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.7        |\n",
      "|    ep_rew_mean          | 0.142       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2385        |\n",
      "|    time_elapsed         | 3724        |\n",
      "|    total_timesteps      | 4884480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006955087 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.83       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.066      |\n",
      "|    n_updates            | 28730       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | -0.454       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2386         |\n",
      "|    time_elapsed         | 3726         |\n",
      "|    total_timesteps      | 4886528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050577484 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.78        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0612       |\n",
      "|    n_updates            | 28740        |\n",
      "|    policy_gradient_loss | -0.0091      |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 0.273        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4888528, episode_reward=-0.77 +/- 5.55\n",
      "Episode length: 31.30 +/- 9.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 31.3         |\n",
      "|    mean_reward          | -0.765       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4888528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065783225 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.76        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.153        |\n",
      "|    n_updates            | 28750        |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    std                  | 19.7         |\n",
      "|    value_loss           | 0.777        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | -0.867   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2387     |\n",
      "|    time_elapsed    | 3727     |\n",
      "|    total_timesteps | 4888576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -0.727      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2388        |\n",
      "|    time_elapsed         | 3729        |\n",
      "|    total_timesteps      | 4890624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006469085 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.77       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.284       |\n",
      "|    n_updates            | 28760       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 19.8        |\n",
      "|    value_loss           | 0.934       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2389         |\n",
      "|    time_elapsed         | 3730         |\n",
      "|    total_timesteps      | 4892672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047851726 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.78        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.031        |\n",
      "|    n_updates            | 28770        |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    std                  | 19.6         |\n",
      "|    value_loss           | 0.364        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.1        |\n",
      "|    ep_rew_mean          | -1.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2390        |\n",
      "|    time_elapsed         | 3732        |\n",
      "|    total_timesteps      | 4894720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007606594 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.76       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0625     |\n",
      "|    n_updates            | 28780       |\n",
      "|    policy_gradient_loss | -0.00768    |\n",
      "|    std                  | 19.8        |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.5        |\n",
      "|    ep_rew_mean          | -1.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2391        |\n",
      "|    time_elapsed         | 3733        |\n",
      "|    total_timesteps      | 4896768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008440948 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.79       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 28790       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 0.485       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4898528, episode_reward=1.80 +/- 3.53\n",
      "Episode length: 27.60 +/- 7.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27.6         |\n",
      "|    mean_reward          | 1.8          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4898528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049963435 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.81        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.337        |\n",
      "|    n_updates            | 28800        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 0.801        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.155    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2392     |\n",
      "|    time_elapsed    | 3735     |\n",
      "|    total_timesteps | 4898816  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | -0.197       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2393         |\n",
      "|    time_elapsed         | 3737         |\n",
      "|    total_timesteps      | 4900864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060979645 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.82        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0625       |\n",
      "|    n_updates            | 28810        |\n",
      "|    policy_gradient_loss | -0.00887     |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 0.384        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | -1.18       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2394        |\n",
      "|    time_elapsed         | 3738        |\n",
      "|    total_timesteps      | 4902912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007990446 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.83       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.296       |\n",
      "|    n_updates            | 28820       |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.788       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | -0.00146    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2395        |\n",
      "|    time_elapsed         | 3739        |\n",
      "|    total_timesteps      | 4904960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007089523 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.82       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.444       |\n",
      "|    n_updates            | 28830       |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.0454      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2396        |\n",
      "|    time_elapsed         | 3741        |\n",
      "|    total_timesteps      | 4907008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004672014 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.81       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.00241    |\n",
      "|    n_updates            | 28840       |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 0.363       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4908528, episode_reward=1.51 +/- 5.26\n",
      "Episode length: 27.70 +/- 7.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27.7        |\n",
      "|    mean_reward          | 1.51        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4908528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005455712 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.82       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0501     |\n",
      "|    n_updates            | 28850       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.823   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2397     |\n",
      "|    time_elapsed    | 3743     |\n",
      "|    total_timesteps | 4909056  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.293       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2398         |\n",
      "|    time_elapsed         | 3745         |\n",
      "|    total_timesteps      | 4911104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066867536 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.83        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0962       |\n",
      "|    n_updates            | 28860        |\n",
      "|    policy_gradient_loss | -0.00897     |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 0.437        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.9        |\n",
      "|    ep_rew_mean          | -0.324      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2399        |\n",
      "|    time_elapsed         | 3746        |\n",
      "|    total_timesteps      | 4913152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007082082 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.83       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 28870       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.57        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.454       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2400         |\n",
      "|    time_elapsed         | 3748         |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068537686 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.83        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.111        |\n",
      "|    n_updates            | 28880        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 0.609        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | -0.188       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 3749         |\n",
      "|    total_timesteps      | 4917248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056022494 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.82        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0357       |\n",
      "|    n_updates            | 28890        |\n",
      "|    policy_gradient_loss | -0.00817     |\n",
      "|    std                  | 20.2         |\n",
      "|    value_loss           | 0.287        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4918528, episode_reward=-2.33 +/- 5.65\n",
      "Episode length: 33.70 +/- 11.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 33.7        |\n",
      "|    mean_reward          | -2.33       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4918528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007251295 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.81       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.193       |\n",
      "|    n_updates            | 28900       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 0.57        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -1.34    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2402     |\n",
      "|    time_elapsed    | 3751     |\n",
      "|    total_timesteps | 4919296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.3        |\n",
      "|    ep_rew_mean          | 0.159       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2403        |\n",
      "|    time_elapsed         | 3753        |\n",
      "|    total_timesteps      | 4921344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004526835 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.8        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 28910       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 0.348       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | -0.185       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2404         |\n",
      "|    time_elapsed         | 3754         |\n",
      "|    total_timesteps      | 4923392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062457076 |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.81        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0361       |\n",
      "|    n_updates            | 28920        |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 0.239        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.243       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2405         |\n",
      "|    time_elapsed         | 3755         |\n",
      "|    total_timesteps      | 4925440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072266385 |\n",
      "|    clip_fraction        | 0.0633       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.86        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.118        |\n",
      "|    n_updates            | 28930        |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 0.559        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | -1.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2406        |\n",
      "|    time_elapsed         | 3757        |\n",
      "|    total_timesteps      | 4927488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008603448 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.89       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 28940       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 20.9        |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4928528, episode_reward=-0.71 +/- 4.48\n",
      "Episode length: 31.40 +/- 6.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.4        |\n",
      "|    mean_reward          | -0.709      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4928528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006979196 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.9        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 28950       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.4     |\n",
      "|    ep_rew_mean     | 0.194    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2407     |\n",
      "|    time_elapsed    | 3759     |\n",
      "|    total_timesteps | 4929536  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31.1       |\n",
      "|    ep_rew_mean          | -0.323     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 2408       |\n",
      "|    time_elapsed         | 3760       |\n",
      "|    total_timesteps      | 4931584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00763694 |\n",
      "|    clip_fraction        | 0.0583     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.94      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.891      |\n",
      "|    n_updates            | 28960      |\n",
      "|    policy_gradient_loss | -0.00767   |\n",
      "|    std                  | 21.6       |\n",
      "|    value_loss           | 1.05       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.35        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2409         |\n",
      "|    time_elapsed         | 3762         |\n",
      "|    total_timesteps      | 4933632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043861503 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.96        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.18         |\n",
      "|    n_updates            | 28970        |\n",
      "|    policy_gradient_loss | -0.00793     |\n",
      "|    std                  | 21.6         |\n",
      "|    value_loss           | 0.756        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.5       |\n",
      "|    ep_rew_mean          | 0.102      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1311       |\n",
      "|    iterations           | 2410       |\n",
      "|    time_elapsed         | 3763       |\n",
      "|    total_timesteps      | 4935680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00803077 |\n",
      "|    clip_fraction        | 0.0577     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.95      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 0.0318     |\n",
      "|    n_updates            | 28980      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 21.4       |\n",
      "|    value_loss           | 0.297      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.7         |\n",
      "|    ep_rew_mean          | -0.193       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2411         |\n",
      "|    time_elapsed         | 3765         |\n",
      "|    total_timesteps      | 4937728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054297904 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.94        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0633      |\n",
      "|    n_updates            | 28990        |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 0.12         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4938528, episode_reward=0.87 +/- 4.87\n",
      "Episode length: 28.40 +/- 7.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28.4        |\n",
      "|    mean_reward          | 0.868       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4938528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007051627 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.92       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 29000       |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 0.617       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | -0.0303  |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2412     |\n",
      "|    time_elapsed    | 3766     |\n",
      "|    total_timesteps | 4939776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.263       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2413        |\n",
      "|    time_elapsed         | 3768        |\n",
      "|    total_timesteps      | 4941824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015020959 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.92       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 29010       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 0.803       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.544       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2414         |\n",
      "|    time_elapsed         | 3769         |\n",
      "|    total_timesteps      | 4943872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035240976 |\n",
      "|    clip_fraction        | 0.0306       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.92        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0718       |\n",
      "|    n_updates            | 29020        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 0.5          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | -0.215       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2415         |\n",
      "|    time_elapsed         | 3771         |\n",
      "|    total_timesteps      | 4945920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043452466 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.91        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0813       |\n",
      "|    n_updates            | 29030        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    std                  | 21           |\n",
      "|    value_loss           | 0.445        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.4         |\n",
      "|    ep_rew_mean          | 0.277        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2416         |\n",
      "|    time_elapsed         | 3772         |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068104803 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.88        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0433      |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00846     |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 0.185        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4948528, episode_reward=0.87 +/- 5.06\n",
      "Episode length: 29.00 +/- 9.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29          |\n",
      "|    mean_reward          | 0.868       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4948528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498283 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.84       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 29050       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.702       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.0357  |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2417     |\n",
      "|    time_elapsed    | 3774     |\n",
      "|    total_timesteps | 4950016  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.329       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2418         |\n",
      "|    time_elapsed         | 3775         |\n",
      "|    total_timesteps      | 4952064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034171152 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.85        |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 1.19         |\n",
      "|    n_updates            | 29060        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 2.71         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | -0.647       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2419         |\n",
      "|    time_elapsed         | 3777         |\n",
      "|    total_timesteps      | 4954112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054239933 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.85        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.183        |\n",
      "|    n_updates            | 29070        |\n",
      "|    policy_gradient_loss | -0.00888     |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 0.845        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.7         |\n",
      "|    ep_rew_mean          | -0.85        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2420         |\n",
      "|    time_elapsed         | 3779         |\n",
      "|    total_timesteps      | 4956160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049560713 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.86        |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.387        |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | -0.00867     |\n",
      "|    std                  | 20.6         |\n",
      "|    value_loss           | 1.1          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | 0.125        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2421         |\n",
      "|    time_elapsed         | 3780         |\n",
      "|    total_timesteps      | 4958208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033848365 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.87        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.512        |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 1.16         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4958528, episode_reward=1.42 +/- 4.17\n",
      "Episode length: 27.00 +/- 5.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 1.42         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4958528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060145874 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.84        |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0126       |\n",
      "|    n_updates            | 29100        |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 0.284        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.9     |\n",
      "|    ep_rew_mean     | 0.499    |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2422     |\n",
      "|    time_elapsed    | 3782     |\n",
      "|    total_timesteps | 4960256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | -0.208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2423        |\n",
      "|    time_elapsed         | 3784        |\n",
      "|    total_timesteps      | 4962304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008034626 |\n",
      "|    clip_fraction        | 0.0897      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.81       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0982      |\n",
      "|    n_updates            | 29110       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 20          |\n",
      "|    value_loss           | 0.471       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -0.186      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2424        |\n",
      "|    time_elapsed         | 3785        |\n",
      "|    total_timesteps      | 4964352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007896411 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.82       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0573      |\n",
      "|    n_updates            | 29120       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 20.1        |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | -0.833      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2425        |\n",
      "|    time_elapsed         | 3787        |\n",
      "|    total_timesteps      | 4966400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005157459 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.81       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0411      |\n",
      "|    n_updates            | 29130       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    std                  | 20.2        |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | -0.623      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2426        |\n",
      "|    time_elapsed         | 3788        |\n",
      "|    total_timesteps      | 4968448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009613912 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.83       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 29140       |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    std                  | 20.3        |\n",
      "|    value_loss           | 0.82        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4968528, episode_reward=-0.52 +/- 4.45\n",
      "Episode length: 31.10 +/- 6.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 31.1        |\n",
      "|    mean_reward          | -0.52       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4968528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008346833 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.84       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.279       |\n",
      "|    n_updates            | 29150       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 20.4        |\n",
      "|    value_loss           | 0.688       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -0.213   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2427     |\n",
      "|    time_elapsed    | 3790     |\n",
      "|    total_timesteps | 4970496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.0801      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2428        |\n",
      "|    time_elapsed         | 3791        |\n",
      "|    total_timesteps      | 4972544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006614659 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.85       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0794      |\n",
      "|    n_updates            | 29160       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    std                  | 20.6        |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | -0.767       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 3793         |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037789727 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.86        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0703       |\n",
      "|    n_updates            | 29170        |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 0.37         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.3         |\n",
      "|    ep_rew_mean          | -0.773       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2430         |\n",
      "|    time_elapsed         | 3794         |\n",
      "|    total_timesteps      | 4976640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032879028 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.84        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.302        |\n",
      "|    n_updates            | 29180        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    std                  | 20.4         |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4978528, episode_reward=-0.84 +/- 4.95\n",
      "Episode length: 30.70 +/- 7.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30.7         |\n",
      "|    mean_reward          | -0.841       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4978528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054797083 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.85        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | -0.0686      |\n",
      "|    n_updates            | 29190        |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 0.132        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | -0.0967  |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2431     |\n",
      "|    time_elapsed    | 3796     |\n",
      "|    total_timesteps | 4978688  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.5         |\n",
      "|    ep_rew_mean          | 0.287        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2432         |\n",
      "|    time_elapsed         | 3797         |\n",
      "|    total_timesteps      | 4980736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068477774 |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.81        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.0514       |\n",
      "|    n_updates            | 29200        |\n",
      "|    policy_gradient_loss | -0.00823     |\n",
      "|    std                  | 20.1         |\n",
      "|    value_loss           | 0.513        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.772       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2433         |\n",
      "|    time_elapsed         | 3799         |\n",
      "|    total_timesteps      | 4982784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076275724 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.83        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.191        |\n",
      "|    n_updates            | 29210        |\n",
      "|    policy_gradient_loss | -0.00936     |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 0.664        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.1         |\n",
      "|    ep_rew_mean          | -0.398       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2434         |\n",
      "|    time_elapsed         | 3800         |\n",
      "|    total_timesteps      | 4984832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041388497 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.84        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 29220        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    std                  | 20.3         |\n",
      "|    value_loss           | 0.73         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | -0.51        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2435         |\n",
      "|    time_elapsed         | 3802         |\n",
      "|    total_timesteps      | 4986880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063105347 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.85        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.236        |\n",
      "|    n_updates            | 29230        |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    std                  | 20.5         |\n",
      "|    value_loss           | 0.534        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4988528, episode_reward=-1.60 +/- 4.34\n",
      "Episode length: 32.80 +/- 6.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 32.8         |\n",
      "|    mean_reward          | -1.6         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4988528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076963482 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.87        |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.12         |\n",
      "|    n_updates            | 29240        |\n",
      "|    policy_gradient_loss | -0.00927     |\n",
      "|    std                  | 20.8         |\n",
      "|    value_loss           | 0.774        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.6     |\n",
      "|    ep_rew_mean     | -0.769   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2436     |\n",
      "|    time_elapsed    | 3804     |\n",
      "|    total_timesteps | 4988928  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.6         |\n",
      "|    ep_rew_mean          | -0.341       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2437         |\n",
      "|    time_elapsed         | 3805         |\n",
      "|    total_timesteps      | 4990976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069841705 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.89        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.43         |\n",
      "|    n_updates            | 29250        |\n",
      "|    policy_gradient_loss | -0.00956     |\n",
      "|    std                  | 20.9         |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -0.305      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2438        |\n",
      "|    time_elapsed         | 3807        |\n",
      "|    total_timesteps      | 4993024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005782343 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.9        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 29260       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    std                  | 21.1        |\n",
      "|    value_loss           | 0.781       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.1         |\n",
      "|    ep_rew_mean          | -0.914       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2439         |\n",
      "|    time_elapsed         | 3808         |\n",
      "|    total_timesteps      | 4995072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039945575 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.92        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.239        |\n",
      "|    n_updates            | 29270        |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    std                  | 21.1         |\n",
      "|    value_loss           | 0.962        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | -0.0386     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1311        |\n",
      "|    iterations           | 2440        |\n",
      "|    time_elapsed         | 3810        |\n",
      "|    total_timesteps      | 4997120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005724452 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.92       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 29280       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 0.719       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4998528, episode_reward=-0.50 +/- 4.39\n",
      "Episode length: 29.90 +/- 7.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 29.9        |\n",
      "|    mean_reward          | -0.498      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4998528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004707004 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.93       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 0.0518      |\n",
      "|    n_updates            | 29290       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    std                  | 21.3        |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.8     |\n",
      "|    ep_rew_mean     | -0.196   |\n",
      "| time/              |          |\n",
      "|    fps             | 1311     |\n",
      "|    iterations      | 2441     |\n",
      "|    time_elapsed    | 3812     |\n",
      "|    total_timesteps | 4999168  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.6         |\n",
      "|    ep_rew_mean          | -0.208       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1311         |\n",
      "|    iterations           | 2442         |\n",
      "|    time_elapsed         | 3813         |\n",
      "|    total_timesteps      | 5001216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040848143 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.93        |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.001        |\n",
      "|    loss                 | 0.752        |\n",
      "|    n_updates            | 29300        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    std                  | 21.2         |\n",
      "|    value_loss           | 2.05         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.learn(\n",
    "    total_timesteps=5_000_000,\n",
    "    callback=eval_callback\n",
    ")\n",
    "# Save the model\n",
    "model.save(\"ppo_sb_docking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a87ab24a-9851-4bb0-b979-8164489b20a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, State: [-4.74196689 -3.98810408 -0.62822361 -0.55561479]\n",
      "Step: 0, Reward: -0.6743579335332548\n",
      "Step: 2, State: [-4.79478926 -4.03366556 -0.52822361 -0.45561479]\n",
      "Step: 1, Reward: -0.6756823158143077\n",
      "Step: 3, State: [-4.83761162 -4.06922704 -0.4282236  -0.35561478]\n",
      "Step: 2, Reward: -0.675602368298301\n",
      "Step: 4, State: [-4.87043398 -4.09478851 -0.3282236  -0.25561478]\n",
      "Step: 3, Reward: -0.674121536884568\n",
      "Step: 5, State: [-4.89325634 -4.11034999 -0.2282236  -0.15561478]\n",
      "Step: 4, Reward: -0.6712480719526749\n",
      "Step: 6, State: [-4.9060787  -4.11591147 -0.1282236  -0.05561478]\n",
      "Step: 5, Reward: -0.6670070181204821\n",
      "Step: 7, State: [-4.90890106 -4.11147295 -0.0282236   0.04438522]\n",
      "Step: 6, Reward: -0.6615235171962978\n",
      "Step: 8, State: [-4.90172342 -4.09703443  0.0717764   0.14438522]\n",
      "Step: 7, Reward: -0.6570963566211293\n",
      "Step: 9, State: [-4.88454578 -4.0725959   0.1717764   0.24438523]\n",
      "Step: 8, Reward: -0.6610515002641176\n",
      "Step: 10, State: [-4.85736814 -4.03815738  0.27177641  0.34438523]\n",
      "Step: 9, Reward: -0.6650403954867815\n",
      "Step: 11, State: [-4.82019049 -3.99371886  0.37177641  0.44438523]\n",
      "Step: 10, Reward: -0.6677477993397682\n",
      "Step: 12, State: [-4.77301285 -3.93928033  0.47177641  0.54438523]\n",
      "Step: 11, Reward: -0.669083230299646\n",
      "Step: 13, State: [-4.71583521 -3.87484181  0.57177641  0.64438523]\n",
      "Step: 12, Reward: -0.66902702772997\n",
      "Step: 14, State: [-4.64865757 -3.80040329  0.67177641  0.74438523]\n",
      "Step: 13, Reward: -0.6675729667265792\n",
      "Step: 15, State: [-4.57147993 -3.71596477  0.77177641  0.84438523]\n",
      "Step: 14, Reward: -0.6647189672861906\n",
      "Step: 16, State: [-4.48430229 -3.62152624  0.87177641  0.94438524]\n",
      "Step: 15, Reward: -0.6604646840095076\n",
      "Step: 17, State: [-4.38712465 -3.51708772  0.97177642  1.04438524]\n",
      "Step: 16, Reward: -0.6548107159514761\n",
      "Step: 18, State: [-4.27994701 -3.40264919  1.07177642  1.14438524]\n",
      "Step: 17, Reward: -0.6477583282734343\n",
      "Step: 19, State: [-4.16276936 -3.27821067  1.17177642  1.24438524]\n",
      "Step: 18, Reward: -0.6393093783975329\n",
      "Step: 20, State: [-4.03559172 -3.14377215  1.27177642  1.34438524]\n",
      "Step: 19, Reward: -0.6294663482836043\n",
      "Step: 21, State: [-3.89841408 -2.99933362  1.37177642  1.44438524]\n",
      "Step: 20, Reward: -0.6182324531441696\n",
      "Step: 22, State: [-3.75123644 -2.8448951   1.47177642  1.54438524]\n",
      "Step: 21, Reward: -0.6056118264209225\n",
      "Step: 23, State: [-3.59405879 -2.68045657  1.57177642  1.64438525]\n",
      "Step: 22, Reward: -0.5916097999699756\n",
      "Step: 24, State: [-3.42688115 -2.50601805  1.67177643  1.74438525]\n",
      "Step: 23, Reward: -0.5762333184365391\n",
      "Step: 25, State: [-3.24970351 -2.32157952  1.77177643  1.84438525]\n",
      "Step: 24, Reward: -0.55949155565652\n",
      "Step: 26, State: [-3.06252587 -2.147141    1.87177643  1.74438525]\n",
      "Step: 25, Reward: -0.5413968490307687\n",
      "Step: 27, State: [-2.86534822 -1.98270247  1.97177643  1.64438525]\n",
      "Step: 26, Reward: -0.5160945141270337\n",
      "Step: 28, State: [-2.65817058 -1.82250007  2.07177643  1.60202408]\n",
      "Step: 27, Reward: -0.487677869545059\n",
      "Step: 29, State: [-2.44099294 -1.65229766  2.17177643  1.70202408]\n",
      "Step: 28, Reward: -0.4673826487166317\n",
      "Step: 30, State: [-2.21381529 -1.49209525  2.27177644  1.60202408]\n",
      "Step: 29, Reward: -0.44686817646356114\n",
      "Step: 31, State: [-1.97663765 -1.34189284  2.37177644  1.50202408]\n",
      "Step: 30, Reward: -0.42010411577907125\n",
      "Step: 32, State: [-1.72946001 -1.20169043  2.47177644  1.40202408]\n",
      "Step: 31, Reward: -0.39342074526494497\n",
      "Step: 33, State: [-1.49228236 -1.05148803  2.37177644  1.50202408]\n",
      "Step: 32, Reward: -0.3668245159513831\n",
      "Step: 34, State: [-1.26510472 -0.91128562  2.27177644  1.40202408]\n",
      "Step: 33, Reward: -0.33706357582767676\n",
      "Step: 35, State: [-1.04792707 -0.78108321  2.17177643  1.30202408]\n",
      "Step: 34, Reward: -0.30353541501566794\n",
      "Step: 36, State: [-0.84074943 -0.6408808   2.07177643  1.40202408]\n",
      "Step: 35, Reward: -0.2714503201021694\n",
      "Step: 37, State: [-0.64357179 -0.4906784   1.97177643  1.50202408]\n",
      "Step: 36, Reward: -0.244937426990704\n",
      "Step: 38, State: [-0.45639415 -0.35047599  1.87177643  1.40202408]\n",
      "Step: 37, Reward: -0.21900636403654342\n",
      "Step: 39, State: [-0.2792165  -0.22027358  1.77177643  1.30202408]\n",
      "Step: 38, Reward: -0.1886177495764565\n",
      "Step: 40, State: [-0.11203886 -0.10007117  1.67177643  1.20202407]\n",
      "Step: 39, Reward: -0.15964349555061494\n",
      "Step: 41, State: [0.04513878 0.01013123 1.57177642 1.10202407]\n",
      "Step: 40, Reward: -0.1321170723773432\n",
      "Step: 42, State: [0.19231643 0.11033364 1.47177642 1.00202407]\n",
      "Step: 41, Reward: 9.885250723284296\n",
      "Step: 1, State: [ 0.23827231  2.44918729 -0.83863261 -0.46001952]\n",
      "Step: 42, Reward: -0.31599732043152784\n",
      "Step: 2, State: [ 0.16440905  2.39318533 -0.73863261 -0.56001953]\n",
      "Step: 43, Reward: -0.30804295950122423\n",
      "Step: 3, State: [ 0.10054579  2.32718338 -0.63863261 -0.66001953]\n",
      "Step: 44, Reward: -0.30037126045754897\n",
      "Step: 4, State: [ 0.04668253  2.25118143 -0.53863261 -0.76001953]\n",
      "Step: 45, Reward: -0.29299808830359775\n",
      "Step: 5, State: [ 0.00281927  2.16517947 -0.4386326  -0.86001953]\n",
      "Step: 46, Reward: -0.2858853534116388\n",
      "Step: 6, State: [-0.03104399  2.06917752 -0.3386326  -0.96001953]\n",
      "Step: 47, Reward: -0.2789311726386822\n",
      "Step: 7, State: [-0.05490725  1.96317557 -0.2386326  -1.06001953]\n",
      "Step: 48, Reward: -0.27198281891855636\n",
      "Step: 8, State: [-0.06877051  1.84717361 -0.1386326  -1.16001954]\n",
      "Step: 49, Reward: -0.2648638697236111\n",
      "Step: 9, State: [-0.07263377  1.72117166 -0.0386326  -1.26001954]\n",
      "Step: 50, Reward: -0.2574011731437059\n",
      "Step: 10, State: [-0.08649703  1.58516971 -0.1386326  -1.36001954]\n",
      "Step: 51, Reward: -0.24944307333527\n",
      "Step: 11, State: [-0.11036029  1.43916775 -0.2386326  -1.46001954]\n",
      "Step: 52, Reward: -0.2412482716134725\n",
      "Step: 12, State: [-0.12422355  1.2831658  -0.1386326  -1.56001954]\n",
      "Step: 53, Reward: -0.23245106250670872\n",
      "Step: 13, State: [-0.12808681  1.11716384 -0.0386326  -1.66001954]\n",
      "Step: 54, Reward: -0.2213669826568544\n",
      "Step: 14, State: [-0.12195007  0.96116189  0.0613674  -1.56001954]\n",
      "Step: 55, Reward: -0.20961385382707803\n",
      "Step: 15, State: [-0.10581333  0.79515994  0.1613674  -1.66001954]\n",
      "Step: 56, Reward: -0.18909017824377355\n",
      "Step: 16, State: [-0.09967659  0.62435891  0.0613674  -1.70801022]\n",
      "Step: 57, Reward: -0.17470108875846835\n",
      "Step: 17, State: [-0.08353985  0.46355789  0.1613674  -1.60801022]\n",
      "Step: 58, Reward: -0.16282428586164327\n",
      "Step: 18, State: [-0.05740311  0.31275687  0.26136741 -1.50801022]\n",
      "Step: 59, Reward: -0.14204900083811334\n",
      "Step: 19, State: [-0.02126637  0.17195585  0.36136741 -1.40801021]\n",
      "Step: 60, Reward: -0.12246487715669296\n",
      "Step: 20, State: [ 0.00487037  0.04115483  0.26136741 -1.30801021]\n",
      "Step: 61, Reward: -0.10415089610907823\n",
      "Step: 21, State: [ 0.02100711 -0.07964619  0.1613674  -1.20801021]\n",
      "Step: 62, Reward: 9.91502026714108\n",
      "Step: 1, State: [ 4.44847641  3.15110915  0.04938545 -0.02727137]\n",
      "Step: 63, Reward: -0.5673506005261354\n",
      "Step: 2, State: [ 4.44341495  3.13838201 -0.05061456 -0.12727137]\n",
      "Step: 64, Reward: -0.5621090226021541\n",
      "Step: 3, State: [ 4.4283535   3.11565487 -0.15061456 -0.22727138]\n",
      "Step: 65, Reward: -0.5649884230785234\n",
      "Step: 4, State: [ 4.40329204  3.08292773 -0.25061456 -0.32727138]\n",
      "Step: 66, Reward: -0.5692320209473577\n",
      "Step: 5, State: [ 4.36823058  3.0402006  -0.35061456 -0.42727138]\n",
      "Step: 67, Reward: -0.5722784995973996\n",
      "Step: 6, State: [ 4.32316913  2.98747346 -0.45061456 -0.52727138]\n",
      "Step: 68, Reward: -0.5739831672394626\n",
      "Step: 7, State: [ 4.26810767  2.92474632 -0.55061456 -0.62727138]\n",
      "Step: 69, Reward: -0.5743194437836137\n",
      "Step: 8, State: [ 4.20304621  2.85201918 -0.65061456 -0.72727138]\n",
      "Step: 70, Reward: -0.5732806667082128\n",
      "Step: 9, State: [ 4.12798476  2.76929204 -0.75061457 -0.82727139]\n",
      "Step: 71, Reward: -0.5708662656409121\n",
      "Step: 10, State: [ 4.0429233   2.6765649  -0.85061457 -0.92727139]\n",
      "Step: 72, Reward: -0.5670784854512081\n",
      "Step: 11, State: [ 3.94786184  2.57383777 -0.95061457 -1.02727139]\n",
      "Step: 73, Reward: -0.5619214583745482\n",
      "Step: 12, State: [ 3.84280039  2.46111063 -1.05061457 -1.12727139]\n",
      "Step: 74, Reward: -0.5554010257577398\n",
      "Step: 13, State: [ 3.72773893  2.33838349 -1.15061457 -1.22727139]\n",
      "Step: 75, Reward: -0.5475249016893374\n",
      "Step: 14, State: [ 3.60267747  2.20565635 -1.25061457 -1.32727139]\n",
      "Step: 76, Reward: -0.5383030766846454\n",
      "Step: 15, State: [ 3.46761602  2.06292921 -1.35061457 -1.42727139]\n",
      "Step: 77, Reward: -0.5277484705942488\n",
      "Step: 16, State: [ 3.32255456  1.91020207 -1.45061458 -1.5272714 ]\n",
      "Step: 78, Reward: -0.5158779112853904\n",
      "Step: 17, State: [ 3.1674931   1.76747493 -1.55061458 -1.42727139]\n",
      "Step: 79, Reward: -0.5027135880275391\n",
      "Step: 18, State: [ 3.00243164  1.61474779 -1.65061458 -1.5272714 ]\n",
      "Step: 80, Reward: -0.48224209560674103\n",
      "Step: 19, State: [ 2.82737018  1.45202065 -1.75061458 -1.6272714 ]\n",
      "Step: 81, Reward: -0.4674926044852984\n",
      "Step: 20, State: [ 2.64230873  1.29929351 -1.85061458 -1.5272714 ]\n",
      "Step: 82, Reward: -0.45149054089439933\n",
      "Step: 21, State: [ 2.44724727  1.15656637 -1.95061458 -1.42727139]\n",
      "Step: 83, Reward: -0.4285622846423091\n",
      "Step: 22, State: [ 2.24218581  1.02383923 -2.05061459 -1.32727139]\n",
      "Step: 84, Reward: -0.40567142179280663\n",
      "Step: 23, State: [ 2.02712435  0.90111209 -2.15061459 -1.22727139]\n",
      "Step: 85, Reward: -0.38276418526519757\n",
      "Step: 24, State: [ 1.80206289  0.78838495 -2.25061459 -1.12727139]\n",
      "Step: 86, Reward: -0.3597884237111924\n",
      "Step: 25, State: [ 1.56700143  0.66565782 -2.35061459 -1.22727139]\n",
      "Step: 87, Reward: -0.3366965321920352\n",
      "Step: 26, State: [ 1.32193997  0.55293068 -2.45061459 -1.12727139]\n",
      "Step: 88, Reward: -0.3169803776065492\n",
      "Step: 27, State: [ 1.08687851  0.43020354 -2.35061459 -1.22727139]\n",
      "Step: 89, Reward: -0.2923067118082374\n",
      "Step: 28, State: [ 0.86181706  0.3174764  -2.25061459 -1.12727139]\n",
      "Step: 90, Reward: -0.2636200635133866\n",
      "Step: 29, State: [ 0.6467556   0.21474926 -2.15061459 -1.02727139]\n",
      "Step: 91, Reward: -0.23184260424967967\n",
      "Step: 30, State: [ 0.44169414  0.12202212 -2.05061459 -0.92727139]\n",
      "Step: 92, Reward: -0.20145803186932498\n",
      "Step: 31, State: [ 0.24663268  0.03929498 -1.95061458 -0.82727139]\n",
      "Step: 93, Reward: -0.1724921841486273\n",
      "Step: 32, State: [ 0.06157122 -0.03343216 -1.85061458 -0.72727138]\n",
      "Step: 94, Reward: -0.14505602586012573\n",
      "Step: 33, State: [-0.11349024 -0.09615929 -1.75061458 -0.62727138]\n",
      "Step: 95, Reward: 9.879432095389483\n",
      "Step: 1, State: [-3.28928055 -2.00944905  0.08374618 -0.69486735]\n",
      "Step: 96, Reward: -0.43648998722393784\n",
      "Step: 2, State: [-3.27090593 -2.06893578  0.18374618 -0.59486735]\n",
      "Step: 97, Reward: -0.43458798343832206\n",
      "Step: 3, State: [-3.24253132 -2.11842252  0.28374618 -0.49486735]\n",
      "Step: 98, Reward: -0.4323033741554694\n",
      "Step: 4, State: [-3.2041567  -2.15790925  0.38374618 -0.39486735]\n",
      "Step: 99, Reward: -0.4299848831966006\n",
      "Step: 5, State: [-3.15578208 -2.18739599  0.48374618 -0.29486735]\n",
      "Step: 100, Reward: -0.4279785697259152\n",
      "Step: 6, State: [-3.09740746 -2.20688272  0.58374618 -0.19486735]\n",
      "Step: 101, Reward: -0.4264434354683972\n",
      "Step: 7, State: [-3.02903284 -2.21636945  0.68374619 -0.09486734]\n",
      "Step: 102, Reward: -0.42523190768552255\n",
      "Step: 8, State: [-2.95065822 -2.21585619  0.78374619  0.00513266]\n",
      "Step: 103, Reward: -0.42398790619144994\n",
      "Step: 9, State: [-2.8622836  -2.20534292  0.88374619  0.10513266]\n",
      "Step: 104, Reward: -0.4223343852918693\n",
      "Step: 10, State: [-2.76390899 -2.18482966  0.98374619  0.20513266]\n",
      "Step: 105, Reward: -0.41997472523759966\n",
      "Step: 11, State: [-2.65553437 -2.15431639  1.08374619  0.30513266]\n",
      "Step: 106, Reward: -0.41670367604951275\n",
      "Step: 12, State: [-2.53715975 -2.11380312  1.18374619  0.40513266]\n",
      "Step: 107, Reward: -0.4123857070162444\n",
      "Step: 13, State: [-2.40878513 -2.06328986  1.28374619  0.50513267]\n",
      "Step: 108, Reward: -0.40693225056457566\n",
      "Step: 14, State: [-2.27041051 -2.00277659  1.3837462   0.60513267]\n",
      "Step: 109, Reward: -0.400285470373422\n",
      "Step: 15, State: [-2.12203589 -1.93226332  1.4837462   0.70513267]\n",
      "Step: 110, Reward: -0.39240803601405055\n",
      "Step: 16, State: [-1.96366127 -1.85175006  1.5837462   0.80513267]\n",
      "Step: 111, Reward: -0.383277093895117\n",
      "Step: 17, State: [-1.79528665 -1.76123679  1.6837462   0.90513267]\n",
      "Step: 112, Reward: -0.372881062965913\n",
      "Step: 18, State: [-1.61691203 -1.66072352  1.7837462   1.00513267]\n",
      "Step: 113, Reward: -0.361218522921283\n",
      "Step: 19, State: [-1.44853741 -1.55021026  1.6837462   1.10513267]\n",
      "Step: 114, Reward: -0.3482990581096628\n",
      "Step: 20, State: [-1.29016279 -1.42969699  1.5837462   1.20513268]\n",
      "Step: 115, Reward: -0.32700899204103073\n",
      "Step: 21, State: [-1.14178817 -1.29918372  1.4837462   1.30513268]\n",
      "Step: 116, Reward: -0.3062244260891427\n",
      "Step: 22, State: [-1.00341355 -1.15867045  1.3837462   1.40513268]\n",
      "Step: 117, Reward: -0.28590713233240894\n",
      "Step: 23, State: [-0.87503893 -1.00815718  1.28374619  1.50513268]\n",
      "Step: 118, Reward: -0.2660228824113196\n",
      "Step: 24, State: [-0.75666431 -0.84764392  1.18374619  1.60513268]\n",
      "Step: 119, Reward: -0.24654842026633317\n",
      "Step: 25, State: [-0.62828969 -0.69713065  1.28374619  1.50513268]\n",
      "Step: 120, Reward: -0.22748705965018268\n",
      "Step: 26, State: [-0.48991507 -0.55661738  1.3837462   1.40513268]\n",
      "Step: 121, Reward: -0.20690177426981382\n",
      "Step: 27, State: [-0.36154045 -0.42610411  1.28374619  1.30513268]\n",
      "Step: 122, Reward: -0.18689796836108188\n",
      "Step: 28, State: [-0.24316583 -0.30559084  1.18374619  1.20513268]\n",
      "Step: 123, Reward: -0.16155762849000438\n",
      "Step: 29, State: [-0.13479121 -0.19507758  1.08374619  1.10513267]\n",
      "Step: 124, Reward: -0.1376583606815632\n",
      "Step: 30, State: [-0.03641659 -0.09456431  0.98374619  1.00513267]\n",
      "Step: 125, Reward: -0.11524596990841639\n",
      "Step: 31, State: [ 0.05195802 -0.00405104  0.88374619  0.90513267]\n",
      "Step: 126, Reward: -0.0945970859164272\n",
      "Step: 32, State: [0.13033264 0.07646222 0.78374619 0.80513267]\n",
      "Step: 127, Reward: 9.91739535530662\n",
      "Step: 1, State: [ 3.44861474 -2.35343567 -0.70401404  0.44381373]\n",
      "Step: 128, Reward: -0.47472132332507216\n",
      "Step: 2, State: [ 3.36821334 -2.2990543  -0.80401404  0.54381373]\n",
      "Step: 129, Reward: -0.4732653375984184\n",
      "Step: 3, State: [ 3.27781193 -2.23467293 -0.90401404  0.64381374]\n",
      "Step: 130, Reward: -0.4704801512531187\n",
      "Step: 4, State: [ 3.17741053 -2.16029155 -1.00401404  0.74381374]\n",
      "Step: 131, Reward: -0.46634311038976983\n",
      "Step: 5, State: [ 3.06700913 -2.07591018 -1.10401404  0.84381374]\n",
      "Step: 132, Reward: -0.460842049685448\n",
      "Step: 6, State: [ 2.94660772 -1.98152881 -1.20401404  0.94381374]\n",
      "Step: 133, Reward: -0.45397046821132675\n",
      "Step: 7, State: [ 2.81620632 -1.87714743 -1.30401404  1.04381374]\n",
      "Step: 134, Reward: -0.44572540605899985\n",
      "Step: 8, State: [ 2.67580491 -1.76276606 -1.40401405  1.14381374]\n",
      "Step: 135, Reward: -0.4361065325555998\n",
      "Step: 9, State: [ 2.52540351 -1.63838468 -1.50401405  1.24381374]\n",
      "Step: 136, Reward: -0.4251158918915318\n",
      "Step: 10, State: [ 2.3650021  -1.52400331 -1.60401405  1.14381374]\n",
      "Step: 137, Reward: -0.41275812544012824\n",
      "Step: 11, State: [ 2.1946007  -1.39962193 -1.70401405  1.24381374]\n",
      "Step: 138, Reward: -0.3939962628912977\n",
      "Step: 12, State: [ 2.01419929 -1.28524056 -1.80401405  1.14381374]\n",
      "Step: 139, Reward: -0.3799183873474294\n",
      "Step: 13, State: [ 1.82379789 -1.16085918 -1.90401405  1.24381374]\n",
      "Step: 140, Reward: -0.35987725230162554\n",
      "Step: 14, State: [ 1.62339648 -1.02647781 -2.00401406  1.34381375]\n",
      "Step: 141, Reward: -0.3440465439507511\n",
      "Step: 15, State: [ 1.41299508 -0.90209644 -2.10401406  1.24381374]\n",
      "Step: 142, Reward: -0.32685487628387566\n",
      "Step: 16, State: [ 1.19259367 -0.78771506 -2.20401406  1.14381374]\n",
      "Step: 143, Reward: -0.3039909192142449\n",
      "Step: 17, State: [ 0.98219226 -0.68333369 -2.10401406  1.04381374]\n",
      "Step: 144, Reward: -0.2812248402744302\n",
      "Step: 18, State: [ 0.78179086 -0.58895231 -2.00401406  0.94381374]\n",
      "Step: 145, Reward: -0.2512288952207076\n",
      "Step: 19, State: [ 0.59138945 -0.48457094 -1.90401405  1.04381374]\n",
      "Step: 146, Reward: -0.2227798951093497\n",
      "Step: 20, State: [ 0.41098805 -0.39018956 -1.80401405  0.94381374]\n",
      "Step: 147, Reward: -0.19916617912985657\n",
      "Step: 21, State: [ 0.24058664 -0.28580819 -1.70401405  1.04381374]\n",
      "Step: 148, Reward: -0.17261248214966815\n",
      "Step: 22, State: [ 0.08018524 -0.17142682 -1.60401405  1.14381374]\n",
      "Step: 149, Reward: -0.15141607193115314\n",
      "Step: 23, State: [-0.07021617 -0.06704544 -1.50401405  1.04381374]\n",
      "Step: 150, Reward: -0.13157090753046474\n",
      "Step: 24, State: [-0.21061757  0.02733593 -1.40401405  0.94381374]\n",
      "Step: 151, Reward: 9.884612462672072\n",
      "Step: 1, State: [ 4.97527405 -0.22604769  0.55985216  0.62382785]\n",
      "Step: 152, Reward: -0.5558886022146863\n",
      "Step: 2, State: [ 5.02125927 -0.1736649   0.45985216  0.52382784]\n",
      "Step: 153, Reward: -0.5540932794247471\n",
      "Step: 3, State: [ 5.05724448 -0.13128212  0.35985216  0.42382784]\n",
      "Step: 154, Reward: -0.5514201060293495\n",
      "Step: 4, State: [ 5.0832297  -0.07889933  0.25985216  0.52382784]\n",
      "Step: 155, Reward: -0.5478363972941819\n",
      "Step: 5, State: [ 5.09921491 -0.03651655  0.15985216  0.42382784]\n",
      "Step: 156, Reward: -0.5517632430561057\n",
      "Step: 6, State: [ 5.10520013e+00 -4.13376379e-03  5.98521573e-02  3.23827841e-01]\n",
      "Step: 157, Reward: -0.5467252532489495\n",
      "Step: 7, State: [ 5.10118535  0.01824902 -0.04014784  0.22382784]\n",
      "Step: 158, Reward: -0.5411279429633572\n",
      "Step: 8, State: [ 5.08717056  0.0506318  -0.14014785  0.32382784]\n",
      "Step: 159, Reward: -0.5356339332090532\n",
      "Step: 9, State: [ 5.06315578  0.07301459 -0.24014785  0.22382784]\n",
      "Step: 160, Reward: -0.5405270834496172\n",
      "Step: 10, State: [ 5.02914099  0.08539737 -0.34014785  0.12382784]\n",
      "Step: 161, Reward: -0.5369245189860478\n",
      "Step: 11, State: [ 4.98512621  0.08778016 -0.44014785  0.02382784]\n",
      "Step: 162, Reward: -0.5352280358356672\n",
      "Step: 12, State: [ 4.93111142  0.09576278 -0.54014785  0.07982626]\n",
      "Step: 163, Reward: -0.5320906770299489\n",
      "Step: 13, State: [ 4.86709664  0.11374541 -0.64014785  0.17982626]\n",
      "Step: 164, Reward: -0.534646984563397\n",
      "Step: 14, State: [ 4.79308185  0.12172803 -0.74014785  0.07982626]\n",
      "Step: 165, Reward: -0.5342310004532769\n",
      "Step: 15, State: [ 4.70906707  0.13971066 -0.84014786  0.17982626]\n",
      "Step: 166, Reward: -0.5308268750646774\n",
      "Step: 16, State: [ 4.61505228  0.14769329 -0.94014786  0.07982626]\n",
      "Step: 167, Reward: -0.5282149190648902\n",
      "Step: 17, State: [ 4.51103749  0.16567591 -1.04014786  0.17982626]\n",
      "Step: 168, Reward: -0.5230601668629419\n",
      "Step: 18, State: [ 4.39702271  0.17365854 -1.14014786  0.07982626]\n",
      "Step: 169, Reward: -0.5183289226990673\n",
      "Step: 19, State: [ 4.27300792  0.17164116 -1.24014786 -0.02017374]\n",
      "Step: 170, Reward: -0.5113341470318357\n",
      "Step: 20, State: [ 4.13899314  0.15962379 -1.34014786 -0.12017374]\n",
      "Step: 171, Reward: -0.5038031154990408\n",
      "Step: 21, State: [ 3.99497835  0.15760641 -1.44014787 -0.02017374]\n",
      "Step: 172, Reward: -0.49562539515661064\n",
      "Step: 22, State: [ 3.84096356  0.16558904 -1.54014787  0.07982626]\n",
      "Step: 173, Reward: -0.485965194734927\n",
      "Step: 23, State: [ 3.67694878  0.16357167 -1.64014787 -0.02017374]\n",
      "Step: 174, Reward: -0.4757060233876518\n",
      "Step: 24, State: [ 3.50293399  0.17155429 -1.74014787  0.07982626]\n",
      "Step: 175, Reward: -0.4642142596967936\n",
      "Step: 25, State: [ 3.3189192   0.16953692 -1.84014787 -0.02017374]\n",
      "Step: 176, Reward: -0.4519542641577888\n",
      "Step: 26, State: [ 3.12490441  0.17751954 -1.94014787  0.07982626]\n",
      "Step: 177, Reward: -0.43847970989204976\n",
      "Step: 27, State: [ 2.92088963  0.19550217 -2.04014787  0.17982626]\n",
      "Step: 178, Reward: -0.4242258660809223\n",
      "Step: 28, State: [ 2.70687484  0.2234848  -2.14014788  0.27982626]\n",
      "Step: 179, Reward: -0.4092875293787559\n",
      "Step: 29, State: [ 2.48286005  0.24146742 -2.24014788  0.17982626]\n",
      "Step: 180, Reward: -0.3936688250761968\n",
      "Step: 30, State: [ 2.24884526  0.24945005 -2.34014788  0.07982626]\n",
      "Step: 181, Reward: -0.3759672575110483\n",
      "Step: 31, State: [ 2.00483048  0.24743267 -2.44014788 -0.02017374]\n",
      "Step: 182, Reward: -0.35748137633085875\n",
      "Step: 32, State: [ 1.75081569  0.2354153  -2.54014788 -0.12017374]\n",
      "Step: 183, Reward: -0.33815786132617687\n",
      "Step: 33, State: [ 1.4868009   0.21339792 -2.64014788 -0.22017375]\n",
      "Step: 184, Reward: -0.31794876498335384\n",
      "Step: 34, State: [ 1.23278611  0.18138055 -2.54014788 -0.32017375]\n",
      "Step: 185, Reward: -0.2968114806034694\n",
      "Step: 35, State: [ 0.98877132  0.15936317 -2.44014788 -0.22017375]\n",
      "Step: 186, Reward: -0.2667602621337144\n",
      "Step: 36, State: [ 0.75475653  0.1473458  -2.34014788 -0.12017374]\n",
      "Step: 187, Reward: -0.23679832796825065\n",
      "Step: 37, State: [ 0.53074175  0.12532843 -2.24014788 -0.22017375]\n",
      "Step: 188, Reward: -0.2082041788567056\n",
      "Step: 38, State: [ 0.31672696  0.09331105 -2.14014788 -0.32017375]\n",
      "Step: 189, Reward: -0.18122306962259538\n",
      "Step: 39, State: [ 0.11271217  0.05129368 -2.04014787 -0.42017375]\n",
      "Step: 190, Reward: -0.15535900004846115\n",
      "Step: 40, State: [-8.13026150e-02 -7.23698973e-04 -1.94014787e+00 -5.20173750e-01]\n",
      "Step: 191, Reward: -0.13067394600442478\n",
      "Step: 41, State: [-0.2653174  -0.04274107 -1.84014787 -0.42017375]\n",
      "Step: 192, Reward: 9.877293789390142\n",
      "Step: 1, State: [-1.619177   -0.45953571  0.37673096  0.87585952]\n",
      "Step: 193, Reward: -0.23934383577470952\n",
      "Step: 2, State: [-1.5715039  -0.38194976  0.47673096  0.77585952]\n",
      "Step: 194, Reward: -0.23012677673910903\n",
      "Step: 3, State: [-1.51383081 -0.31436381  0.57673096  0.67585951]\n",
      "Step: 195, Reward: -0.22139856824222942\n",
      "Step: 4, State: [-1.44615771 -0.25677786  0.67673096  0.57585951]\n",
      "Step: 196, Reward: -0.2131790472104668\n",
      "Step: 5, State: [-1.36848461 -0.20919191  0.77673097  0.47585951]\n",
      "Step: 197, Reward: -0.20544900148944373\n",
      "Step: 6, State: [-1.28081152 -0.17160595  0.87673097  0.37585951]\n",
      "Step: 198, Reward: -0.19812565508596452\n",
      "Step: 7, State: [-1.18313842 -0.14402     0.97673097  0.27585951]\n",
      "Step: 199, Reward: -0.19106284234849621\n",
      "Step: 8, State: [-1.07546532 -0.12643405  1.07673097  0.17585951]\n",
      "Step: 200, Reward: -0.18407627759991033\n",
      "Step: 9, State: [-0.95779223 -0.1188481   1.17673097  0.0758595 ]\n",
      "Step: 201, Reward: -0.1769791992766598\n",
      "Step: 10, State: [-0.83011913 -0.10126215  1.27673097  0.17585951]\n",
      "Step: 202, Reward: -0.16961458870941554\n",
      "Step: 11, State: [-0.69244603 -0.0936762   1.37673097  0.0758595 ]\n",
      "Step: 203, Reward: -0.16220867536084355\n",
      "Step: 12, State: [-0.54477293 -0.07609025  1.47673098  0.17585951]\n",
      "Step: 204, Reward: -0.15295847378406416\n",
      "Step: 13, State: [-0.40709984 -0.0685043   1.37673097  0.0758595 ]\n",
      "Step: 205, Reward: -0.14350652114842882\n",
      "Step: 14, State: [-0.27942674 -0.05091835  1.27673097  0.17585951]\n",
      "Step: 206, Reward: -0.12436543822792717\n",
      "Step: 15, State: [-0.16175364 -0.0233324   1.17673097  0.27585951]\n",
      "Step: 207, Reward: -0.10698423295141621\n",
      "Step: 16, State: [-0.05408054 -0.00574645  1.07673097  0.17585951]\n",
      "Step: 208, Reward: -0.09091657470071625\n",
      "Step: 17, State: [0.04359255 0.0218395  0.97673097 0.27585951]\n",
      "Step: 209, Reward: 9.925869477017098\n",
      "Step: 1, State: [3.01724689 2.26215678 0.04154834 0.55458674]\n",
      "Step: 210, Reward: -0.42110137323318053\n",
      "Step: 2, State: [ 3.01140172  2.30761546 -0.05845166  0.45458674]\n",
      "Step: 211, Reward: -0.41905834442769024\n",
      "Step: 3, State: [ 2.99555656  2.34307413 -0.15845166  0.35458674]\n",
      "Step: 212, Reward: -0.4164479682231342\n",
      "Step: 4, State: [ 2.96971139  2.38063814 -0.25845166  0.37564006]\n",
      "Step: 213, Reward: -0.4099453802734048\n",
      "Step: 5, State: [ 2.93386622  2.40820214 -0.35845166  0.27564005]\n",
      "Step: 214, Reward: -0.4175532853411846\n",
      "Step: 6, State: [ 2.88802106  2.42576615 -0.45845166  0.17564005]\n",
      "Step: 215, Reward: -0.41631669440702573\n",
      "Step: 7, State: [ 2.83217589  2.43333015 -0.55845167  0.07564005]\n",
      "Step: 216, Reward: -0.41584994034232375\n",
      "Step: 8, State: [ 2.76633072  2.43089416 -0.65845167 -0.02435995]\n",
      "Step: 217, Reward: -0.41571379004855713\n",
      "Step: 9, State: [ 2.69048556  2.41845816 -0.75845167 -0.12435995]\n",
      "Step: 218, Reward: -0.4153511695586523\n",
      "Step: 10, State: [ 2.60464039  2.39602217 -0.85845167 -0.22435995]\n",
      "Step: 219, Reward: -0.4143397123578383\n",
      "Step: 11, State: [ 2.50879522  2.36358617 -0.95845167 -0.32435996]\n",
      "Step: 220, Reward: -0.4124142511524325\n",
      "Step: 12, State: [ 2.40295006  2.32115017 -1.05845167 -0.42435996]\n",
      "Step: 221, Reward: -0.4094169617503508\n",
      "Step: 13, State: [ 2.28710489  2.26871418 -1.15845168 -0.52435996]\n",
      "Step: 222, Reward: -0.4052541097868086\n",
      "Step: 14, State: [ 2.16125972  2.20627818 -1.25845168 -0.62435996]\n",
      "Step: 223, Reward: -0.3998697584647717\n",
      "Step: 15, State: [ 2.02541455  2.13384219 -1.35845168 -0.72435996]\n",
      "Step: 224, Reward: -0.39323122776252656\n",
      "Step: 16, State: [ 1.87956938  2.05140619 -1.45845168 -0.82435996]\n",
      "Step: 225, Reward: -0.3853213740131215\n",
      "Step: 17, State: [ 1.72372422  1.95897019 -1.55845168 -0.92435996]\n",
      "Step: 226, Reward: -0.37613483890590815\n",
      "Step: 18, State: [ 1.57787905  1.8565342  -1.45845168 -1.02435997]\n",
      "Step: 227, Reward: -0.3656768984975215\n",
      "Step: 19, State: [ 1.42784565  1.7440982  -1.500334   -1.12435997]\n",
      "Step: 228, Reward: -0.34360158734445284\n",
      "Step: 20, State: [ 1.26781225  1.6216622  -1.60033401 -1.22435997]\n",
      "Step: 229, Reward: -0.3332886466602697\n",
      "Step: 21, State: [ 1.11777885  1.48922621 -1.500334   -1.32435997]\n",
      "Step: 230, Reward: -0.32073396215005484\n",
      "Step: 22, State: [ 0.97774545  1.34679021 -1.400334   -1.42435997]\n",
      "Step: 231, Reward: -0.3004085996154107\n",
      "Step: 23, State: [ 0.84771205  1.19435421 -1.300334   -1.52435997]\n",
      "Step: 232, Reward: -0.28044182442427606\n",
      "Step: 24, State: [ 0.70767865  1.05191821 -1.400334   -1.42435997]\n",
      "Step: 233, Reward: -0.2607852639745211\n",
      "Step: 25, State: [ 0.57764525  0.89948222 -1.300334   -1.52435997]\n",
      "Step: 234, Reward: -0.24079471380102108\n",
      "Step: 26, State: [ 0.45761185  0.73704622 -1.200334   -1.62435997]\n",
      "Step: 235, Reward: -0.22122286838780217\n",
      "Step: 27, State: [ 0.34757845  0.58461022 -1.100334   -1.52435997]\n",
      "Step: 236, Reward: -0.20188426015813224\n",
      "Step: 28, State: [ 0.24754505  0.44217423 -1.000334   -1.42435997]\n",
      "Step: 237, Reward: -0.1761554707291766\n",
      "Step: 29, State: [ 0.15751165  0.30973823 -0.900334   -1.32435997]\n",
      "Step: 238, Reward: -0.15184409287444217\n",
      "Step: 30, State: [ 0.07747825  0.18730223 -0.80033399 -1.22435997]\n",
      "Step: 239, Reward: -0.12896166343781554\n",
      "Step: 31, State: [ 0.00744485  0.07486623 -0.70033399 -1.12435997]\n",
      "Step: 240, Reward: -0.10754829014051172\n",
      "Step: 32, State: [-0.05258855 -0.02756976 -0.60033399 -1.02435997]\n",
      "Step: 241, Reward: 9.91210265714224\n",
      "Step: 1, State: [-3.82080507 -4.51122854 -0.28529345  0.65789551]\n",
      "Step: 242, Reward: -0.6424368956394582\n",
      "Step: 2, State: [-3.83933441 -4.43543899 -0.18529345  0.75789552]\n",
      "Step: 243, Reward: -0.6411796660956036\n",
      "Step: 3, State: [-3.84786376 -4.34964944 -0.08529345  0.85789552]\n",
      "Step: 244, Reward: -0.6397841337330988\n",
      "Step: 4, State: [-3.8463931  -4.25385988  0.01470656  0.95789552]\n",
      "Step: 245, Reward: -0.6379850409749154\n",
      "Step: 5, State: [-3.83492245 -4.14807033  0.11470656  1.05789552]\n",
      "Step: 246, Reward: -0.6355411505057433\n",
      "Step: 6, State: [-3.81345179 -4.03228078  0.21470656  1.15789552]\n",
      "Step: 247, Reward: -0.6322639051070023\n",
      "Step: 7, State: [-3.78198113 -3.90649123  0.31470656  1.25789552]\n",
      "Step: 248, Reward: -0.6280166349250058\n",
      "Step: 8, State: [-3.74051048 -3.77070168  0.41470656  1.35789553]\n",
      "Step: 249, Reward: -0.6227037884592844\n",
      "Step: 9, State: [-3.68903982 -3.62491212  0.51470656  1.45789553]\n",
      "Step: 250, Reward: -0.6162598546015473\n",
      "Step: 10, State: [-3.62756917 -3.46912257  0.61470656  1.55789553]\n",
      "Step: 251, Reward: -0.6086408205136651\n",
      "Step: 11, State: [-3.55609851 -3.30333302  0.71470657  1.65789553]\n",
      "Step: 252, Reward: -0.5998182960085582\n",
      "Step: 12, State: [-3.47462785 -3.12754346  0.81470657  1.75789553]\n",
      "Step: 253, Reward: -0.5897757482140038\n",
      "Step: 13, State: [-3.3831572  -2.94175391  0.91470657  1.85789553]\n",
      "Step: 254, Reward: -0.5785062984622639\n",
      "Step: 14, State: [-3.28168654 -2.76596436  1.01470657  1.75789553]\n",
      "Step: 255, Reward: -0.5660117093090673\n",
      "Step: 15, State: [-3.17021588 -2.5801748   1.11470657  1.85789553]\n",
      "Step: 256, Reward: -0.544814479610693\n",
      "Step: 16, State: [-3.04874522 -2.38438525  1.21470657  1.95789553]\n",
      "Step: 257, Reward: -0.5312232933730736\n",
      "Step: 17, State: [-2.91727457 -2.1985957   1.31470658  1.85789553]\n",
      "Step: 258, Reward: -0.5163888929653698\n",
      "Step: 18, State: [-2.77580391 -2.02280614  1.41470658  1.75789553]\n",
      "Step: 259, Reward: -0.4932414184599634\n",
      "Step: 19, State: [-2.62433325 -1.85701659  1.51470658  1.65789553]\n",
      "Step: 260, Reward: -0.4704300762660197\n",
      "Step: 20, State: [-2.46286259 -1.70122704  1.61470658  1.55789553]\n",
      "Step: 261, Reward: -0.44791557715374586\n",
      "Step: 21, State: [-2.29139193 -1.55543749  1.71470658  1.45789553]\n",
      "Step: 262, Reward: -0.4256588864540242\n",
      "Step: 22, State: [-2.10992128 -1.41964793  1.81470658  1.35789553]\n",
      "Step: 263, Reward: -0.40362261220770085\n",
      "Step: 23, State: [-1.91845062 -1.27385838  1.91470658  1.45789553]\n",
      "Step: 264, Reward: -0.38177360679321265\n",
      "Step: 24, State: [-1.71697996 -1.13806883  2.01470659  1.35789553]\n",
      "Step: 265, Reward: -0.36475652508913187\n",
      "Step: 25, State: [-1.5055093  -1.01227928  2.11470659  1.25789552]\n",
      "Step: 266, Reward: -0.3416125898469431\n",
      "Step: 26, State: [-1.28403864 -0.87648972  2.21470659  1.35789553]\n",
      "Step: 267, Reward: -0.3185879302270473\n",
      "Step: 27, State: [-1.07256798 -0.73070017  2.11470659  1.45789553]\n",
      "Step: 268, Reward: -0.2995011512894217\n",
      "Step: 28, State: [-0.87109732 -0.59491062  2.01470659  1.35789553]\n",
      "Step: 269, Reward: -0.27235111928993616\n",
      "Step: 29, State: [-0.67962667 -0.46912107  1.91470658  1.25789552]\n",
      "Step: 270, Reward: -0.24110777274599976\n",
      "Step: 30, State: [-0.49815601 -0.34332413  1.81470658  1.25796934]\n",
      "Step: 271, Reward: -0.20712825482341826\n",
      "Step: 31, State: [-0.32668535 -0.2275272   1.71470658  1.15796934]\n",
      "Step: 272, Reward: -0.1850469549080664\n",
      "Step: 32, State: [-0.16521469 -0.12173026  1.61470658  1.05796934]\n",
      "Step: 273, Reward: -0.15740741886357132\n",
      "Step: 33, State: [-0.01374403 -0.02593333  1.51470658  0.95796933]\n",
      "Step: 274, Reward: -0.1311855814724381\n",
      "Step: 34, State: [0.12772662 0.0598636  1.41470658 0.85796933]\n",
      "Step: 275, Reward: 9.893311998501039\n",
      "Step: 1, State: [-0.67545598 -0.21418399 -0.40813559  0.21922276]\n",
      "Step: 276, Reward: -0.11186040364335338\n",
      "Step: 2, State: [-0.70626953 -0.18226171 -0.30813558  0.31922277]\n",
      "Step: 277, Reward: -0.1081665134743907\n",
      "Step: 3, State: [-0.72708309 -0.16033944 -0.20813558  0.21922276]\n",
      "Step: 278, Reward: -0.1092668631115219\n",
      "Step: 4, State: [-0.73789665 -0.14841716 -0.10813558  0.11922276]\n",
      "Step: 279, Reward: -0.10371187753952633\n",
      "Step: 5, State: [-0.73871021 -0.14649489 -0.00813558  0.01922276]\n",
      "Step: 280, Reward: -0.09745748326146818\n",
      "Step: 6, State: [-0.72952377 -0.15457261  0.09186442 -0.08077724]\n",
      "Step: 281, Reward: -0.09049540532195001\n",
      "Step: 7, State: [-0.71033732 -0.15265033  0.19186442  0.01922276]\n",
      "Step: 282, Reward: -0.09483046694876496\n",
      "Step: 8, State: [-0.68115088 -0.14072806  0.29186443  0.11922276]\n",
      "Step: 283, Reward: -0.09643882023316176\n",
      "Step: 9, State: [-0.64196444 -0.13880578  0.39186443  0.01922276]\n",
      "Step: 284, Reward: -0.09945957355572548\n",
      "Step: 10, State: [-0.592778   -0.12688351  0.49186443  0.11922276]\n",
      "Step: 285, Reward: -0.09943885164721765\n",
      "Step: 11, State: [-0.53359155 -0.12496123  0.59186443  0.01922276]\n",
      "Step: 286, Reward: -0.10006806014025764\n",
      "Step: 12, State: [-0.46440511 -0.13303895  0.69186443 -0.08077724]\n",
      "Step: 287, Reward: -0.09855381241775603\n",
      "Step: 13, State: [-0.38521867 -0.13111668  0.79186443  0.01922276]\n",
      "Step: 288, Reward: -0.09727886993290807\n",
      "Step: 14, State: [-0.29603222 -0.1191944   0.89186443  0.11922276]\n",
      "Step: 289, Reward: -0.0944391586073577\n",
      "Step: 15, State: [-0.21684578 -0.09727212  0.79186443  0.21922276]\n",
      "Step: 290, Reward: -0.09104478300442591\n",
      "Step: 16, State: [-0.14765934 -0.06534985  0.69186443  0.31922277]\n",
      "Step: 291, Reward: -0.07899096440685578\n",
      "Step: 17, State: [-0.08847289 -0.04342757  0.59186443  0.21922276]\n",
      "Step: 292, Reward: -0.06838743051558241\n",
      "Step: 18, State: [-0.03928645 -0.0315053   0.49186443  0.11922276]\n",
      "Step: 293, Reward: 9.944444235400274\n",
      "Step: 1, State: [ 3.41408692  4.43809598 -0.3956273  -0.43001001]\n",
      "Step: 294, Reward: -0.6020506095117802\n",
      "Step: 2, State: [ 3.36452419  4.38509498 -0.4956273  -0.53001001]\n",
      "Step: 295, Reward: -0.6032928100658325\n",
      "Step: 3, State: [ 3.30496146  4.32209398 -0.5956273  -0.63001001]\n",
      "Step: 296, Reward: -0.6031364907658339\n",
      "Step: 4, State: [ 3.23539873  4.24909298 -0.6956273  -0.73001001]\n",
      "Step: 297, Reward: -0.601580845660089\n",
      "Step: 5, State: [ 3.155836    4.16609198 -0.7956273  -0.83001001]\n",
      "Step: 298, Reward: -0.5986261847890161\n",
      "Step: 6, State: [ 3.06627327  4.07309097 -0.89562731 -0.93001001]\n",
      "Step: 299, Reward: -0.5942734515247514\n",
      "Step: 7, State: [ 2.96671054  3.97008997 -0.99562731 -1.03001001]\n",
      "Step: 300, Reward: -0.5885241054724836\n",
      "Step: 8, State: [ 2.85714781  3.85708897 -1.09562731 -1.13001002]\n",
      "Step: 301, Reward: -0.58138013695843\n",
      "Step: 9, State: [ 2.73758508  3.73408797 -1.19562731 -1.23001002]\n",
      "Step: 302, Reward: -0.5728441547405259\n",
      "Step: 10, State: [ 2.60802235  3.60108697 -1.29562731 -1.33001002]\n",
      "Step: 303, Reward: -0.5629195379290547\n",
      "Step: 11, State: [ 2.46845961  3.45808597 -1.39562731 -1.43001002]\n",
      "Step: 304, Reward: -0.5516106646593153\n",
      "Step: 12, State: [ 2.31889688  3.30508496 -1.49562731 -1.53001002]\n",
      "Step: 305, Reward: -0.5389232473965306\n",
      "Step: 13, State: [ 2.15933415  3.14208396 -1.59562732 -1.63001002]\n",
      "Step: 306, Reward: -0.5248648273572458\n",
      "Step: 14, State: [ 2.00977142  2.96908296 -1.49562731 -1.73001002]\n",
      "Step: 307, Reward: -0.5094455170375345\n",
      "Step: 15, State: [ 1.87020869  2.78608196 -1.39562731 -1.83001003]\n",
      "Step: 308, Reward: -0.48701991371890485\n",
      "Step: 16, State: [ 1.72064596  2.59308095 -1.49562731 -1.93001003]\n",
      "Step: 309, Reward: -0.4647733114538695\n",
      "Step: 17, State: [ 1.58108323  2.39007995 -1.39562731 -2.03001003]\n",
      "Step: 310, Reward: -0.44742889742847547\n",
      "Step: 18, State: [ 1.4515205   2.17707895 -1.29562731 -2.13001003]\n",
      "Step: 311, Reward: -0.4238871775884459\n",
      "Step: 19, State: [ 1.33195776  1.95407794 -1.19562731 -2.23001003]\n",
      "Step: 312, Reward: -0.40045737768194767\n",
      "Step: 20, State: [ 1.20239503  1.72107694 -1.29562731 -2.33001003]\n",
      "Step: 313, Reward: -0.377142992915645\n",
      "Step: 21, State: [ 1.0628323   1.49807594 -1.39562731 -2.23001003]\n",
      "Step: 314, Reward: -0.3573915519951054\n",
      "Step: 22, State: [ 0.91326957  1.26507494 -1.49562731 -2.33001003]\n",
      "Step: 315, Reward: -0.3293587115804823\n",
      "Step: 23, State: [ 0.77370684  1.04207393 -1.39562731 -2.23001003]\n",
      "Step: 316, Reward: -0.30860654409472665\n",
      "Step: 24, State: [ 0.64414411  0.82907293 -1.29562731 -2.13001003]\n",
      "Step: 317, Reward: -0.2754682890720975\n",
      "Step: 25, State: [ 0.52458138  0.62607193 -1.19562731 -2.03001003]\n",
      "Step: 318, Reward: -0.24378728164474744\n",
      "Step: 26, State: [ 0.41501865  0.43307092 -1.09562731 -1.93001003]\n",
      "Step: 319, Reward: -0.21361861719789074\n",
      "Step: 27, State: [ 0.29545592  0.25006992 -1.19562731 -1.83001003]\n",
      "Step: 320, Reward: -0.18509021955821342\n",
      "Step: 28, State: [ 0.18589318  0.07706892 -1.09562731 -1.73001002]\n",
      "Step: 321, Reward: -0.16214836780448627\n",
      "Step: 29, State: [ 0.08633045 -0.08593208 -0.99562731 -1.63001002]\n",
      "Step: 322, Reward: -0.13665388415015156\n",
      "Step: 30, State: [-0.00323228 -0.23893309 -0.89562731 -1.53001002]\n",
      "Step: 323, Reward: -0.12182436162299784\n",
      "Step: 31, State: [-0.08279501 -0.38193409 -0.7956273  -1.43001002]\n",
      "Step: 324, Reward: -0.12668128390101568\n",
      "Step: 32, State: [-0.15235774 -0.51493509 -0.6956273  -1.33001002]\n",
      "Step: 325, Reward: -0.13504488799580133\n",
      "Step: 33, State: [-0.21192047 -0.63793609 -0.5956273  -1.23001002]\n",
      "Step: 326, Reward: -0.1428893759079514\n",
      "Step: 34, State: [-0.2614832  -0.75093709 -0.4956273  -1.13001002]\n",
      "Step: 327, Reward: -0.14969546265223854\n",
      "Step: 35, State: [-0.30104593 -0.85393809 -0.3956273  -1.03001001]\n",
      "Step: 328, Reward: -0.15535438277614236\n",
      "Step: 36, State: [-0.33060866 -0.9469391  -0.2956273  -0.93001001]\n",
      "Step: 329, Reward: -0.15985595990826676\n",
      "Step: 37, State: [-0.35017139 -1.0299401  -0.19562729 -0.83001001]\n",
      "Step: 330, Reward: -0.16323476571541531\n",
      "Step: 38, State: [-0.35973412 -1.1029411  -0.09562729 -0.73001001]\n",
      "Step: 331, Reward: -0.1655637893150142\n",
      "Step: 39, State: [-0.35929684 -1.1659421   0.00437271 -0.63001001]\n",
      "Step: 332, Reward: -0.1669668702183852\n",
      "Step: 40, State: [-0.34885957 -1.2189431   0.10437271 -0.53001001]\n",
      "Step: 333, Reward: -0.1676481157509586\n",
      "Step: 41, State: [-0.3284223  -1.2619441   0.20437271 -0.43001001]\n",
      "Step: 334, Reward: -0.1679398110008756\n",
      "Step: 42, State: [-0.29798503 -1.2949451   0.30437271 -0.33001   ]\n",
      "Step: 335, Reward: -0.1683454401479061\n",
      "Step: 43, State: [-0.25754776 -1.3179461   0.40437271 -0.23001   ]\n",
      "Step: 336, Reward: -0.1694680723069971\n",
      "Step: 44, State: [-0.20711049 -1.3309471   0.50437272 -0.13001   ]\n",
      "Step: 337, Reward: -0.1716902002704225\n",
      "Step: 45, State: [-0.16667322 -1.3339481   0.40437271 -0.03001   ]\n",
      "Step: 338, Reward: -0.17488161010339123\n",
      "Step: 46, State: [-0.13623595 -1.3269491   0.30437271  0.06999   ]\n",
      "Step: 339, Reward: -0.168848419368161\n",
      "Step: 47, State: [-0.09579867 -1.3099501   0.40437271  0.16999   ]\n",
      "Step: 340, Reward: -0.16315037468651697\n",
      "Step: 48, State: [-0.0653614  -1.2829511   0.30437271  0.26999001]\n",
      "Step: 341, Reward: -0.1674194775607289\n",
      "Step: 49, State: [-0.02492413 -1.2459521   0.40437271  0.36999001]\n",
      "Step: 342, Reward: -0.16294677379851918\n",
      "Step: 50, State: [ 0.00551314 -1.1989531   0.30437271  0.46999001]\n",
      "Step: 343, Reward: -0.16616710264218315\n",
      "Step: 51, State: [ 0.02595041 -1.1419541   0.20437271  0.56999001]\n",
      "Step: 344, Reward: -0.16203573739852556\n",
      "Step: 52, State: [ 0.03638768 -1.0749551   0.10437271  0.66999001]\n",
      "Step: 345, Reward: -0.15864312372734599\n",
      "Step: 53, State: [ 0.05682495 -0.99795609  0.20437271  0.76999001]\n",
      "Step: 346, Reward: -0.1556027641350637\n",
      "Step: 54, State: [ 0.06726222 -0.91095709  0.10437271  0.86999001]\n",
      "Step: 347, Reward: -0.15393194863974405\n",
      "Step: 55, State: [ 0.0676995  -0.81395809  0.00437271  0.96999002]\n",
      "Step: 348, Reward: -0.14929725102465993\n",
      "Step: 56, State: [ 0.07813677 -0.70695909  0.10437271  1.06999002]\n",
      "Step: 349, Reward: -0.14431899206804344\n",
      "Step: 57, State: [ 0.07857404 -0.58996009  0.00437271  1.16999002]\n",
      "Step: 350, Reward: -0.13902196304473727\n",
      "Step: 58, State: [ 0.06901131 -0.46296109 -0.09562729  1.26999002]\n",
      "Step: 351, Reward: -0.13215899916585433\n",
      "Step: 59, State: [ 0.04944858 -0.34596208 -0.19562729  1.16999002]\n",
      "Step: 352, Reward: -0.1246290360019978\n",
      "Step: 60, State: [ 0.03988585 -0.23896308 -0.09562729  1.06999002]\n",
      "Step: 353, Reward: -0.10840154981185089\n",
      "Step: 61, State: [ 0.02032312 -0.14196408 -0.19562729  0.96999002]\n",
      "Step: 354, Reward: -0.09208176493689223\n",
      "Step: 62, State: [ 0.01076039 -0.05496508 -0.09562729  0.86999001]\n",
      "Step: 355, Reward: -0.07795929649310201\n",
      "Step: 63, State: [0.01119766 0.02203392 0.00437271 0.76999001]\n",
      "Step: 356, Reward: 9.93649553004663\n",
      "Step: 1, State: [-4.39897002  1.40632016  0.3691057   0.2943038 ]\n",
      "Step: 357, Reward: -0.49520415927921635\n",
      "Step: 2, State: [-4.35205945  1.42575054  0.4691057   0.19430379]\n",
      "Step: 358, Reward: -0.4995755986079419\n",
      "Step: 3, State: [-4.29514888  1.43518092  0.5691057   0.09430379]\n",
      "Step: 359, Reward: -0.4974947469986348\n",
      "Step: 4, State: [-4.22823831  1.4346113   0.66910571 -0.00569621]\n",
      "Step: 360, Reward: -0.49584356582299727\n",
      "Step: 5, State: [-4.15132773  1.42404168  0.76910571 -0.10569621]\n",
      "Step: 361, Reward: -0.4940973310911969\n",
      "Step: 6, State: [-4.06441716  1.40347205  0.86910571 -0.20569621]\n",
      "Step: 362, Reward: -0.4918371660535628\n",
      "Step: 7, State: [-3.96750659  1.37290243  0.96910571 -0.30569621]\n",
      "Step: 363, Reward: -0.4887888588584165\n",
      "Step: 8, State: [-3.86059602  1.33233281  1.06910571 -0.40569621]\n",
      "Step: 364, Reward: -0.48478393303613276\n",
      "Step: 9, State: [-3.74368545  1.28176319  1.16910571 -0.50569622]\n",
      "Step: 365, Reward: -0.47971992838927896\n",
      "Step: 10, State: [-3.61677488  1.22119357  1.26910572 -0.60569622]\n",
      "Step: 366, Reward: -0.47353469586766844\n",
      "Step: 11, State: [-3.47986431  1.15062395  1.36910572 -0.70569622]\n",
      "Step: 367, Reward: -0.4661916844980488\n",
      "Step: 12, State: [-3.33295373  1.07005432  1.46910572 -0.80569622]\n",
      "Step: 368, Reward: -0.45767196418785816\n",
      "Step: 13, State: [-3.17604316  0.9794847   1.56910572 -0.90569622]\n",
      "Step: 369, Reward: -0.4479702723671205\n",
      "Step: 14, State: [-3.00913259  0.89891508  1.66910572 -0.80569622]\n",
      "Step: 370, Reward: -0.437093678797452\n",
      "Step: 15, State: [-2.83222202  0.82793256  1.76910572 -0.70982525]\n",
      "Step: 371, Reward: -0.42057580197934563\n",
      "Step: 16, State: [-2.64531145  0.74695003  1.86910572 -0.80982525]\n",
      "Step: 372, Reward: -0.4045274643974809\n",
      "Step: 17, State: [-2.44840087  0.6559675   1.96910573 -0.90982525]\n",
      "Step: 373, Reward: -0.3908668303081537\n",
      "Step: 18, State: [-2.2414903   0.57498498  2.06910573 -0.80982525]\n",
      "Step: 374, Reward: -0.3760740838838683\n",
      "Step: 19, State: [-2.02457973  0.50400245  2.16910573 -0.70982525]\n",
      "Step: 375, Reward: -0.356645390649454\n",
      "Step: 20, State: [-1.79766915  0.44301993  2.26910573 -0.60982525]\n",
      "Step: 376, Reward: -0.33689393968633463\n",
      "Step: 21, State: [-1.56075858  0.37203741  2.36910573 -0.70982525]\n",
      "Step: 377, Reward: -0.31676865569513457\n",
      "Step: 22, State: [-1.33384801  0.31105488  2.26910573 -0.60982525]\n",
      "Step: 378, Reward: -0.298248789541891\n",
      "Step: 23, State: [-1.11693744  0.24007236  2.16910573 -0.70982525]\n",
      "Step: 379, Reward: -0.26858698406895193\n",
      "Step: 24, State: [-0.91002686  0.17908983  2.06910573 -0.60982525]\n",
      "Step: 380, Reward: -0.24250154572947458\n",
      "Step: 25, State: [-0.71311629  0.12810731  1.96910573 -0.50982525]\n",
      "Step: 381, Reward: -0.21474534936487577\n",
      "Step: 26, State: [-0.52620572  0.06712478  1.86910572 -0.60982525]\n",
      "Step: 382, Reward: -0.18829707448149285\n",
      "Step: 27, State: [-0.34929515  0.01614226  1.76910572 -0.50982525]\n",
      "Step: 383, Reward: -0.1654927640027766\n",
      "Step: 28, State: [-0.18238457 -0.02484027  1.66910572 -0.40982524]\n",
      "Step: 384, Reward: -0.1411640334358812\n",
      "Step: 29, State: [-0.025474   -0.05582279  1.56910572 -0.30982524]\n",
      "Step: 385, Reward: -0.11848311529391083\n",
      "Step: 30, State: [ 0.12143657 -0.07680532  1.46910572 -0.20982524]\n",
      "Step: 386, Reward: 9.89975175252488\n",
      "Step: 1, State: [ 4.11285319  2.43629943  0.50498657 -0.69536632]\n",
      "Step: 387, Reward: -0.5338866737129044\n",
      "Step: 2, State: [ 4.15335185  2.3567628   0.40498657 -0.79536632]\n",
      "Step: 388, Reward: -0.5351398897610232\n",
      "Step: 3, State: [ 4.1838505   2.26722617  0.30498657 -0.89536632]\n",
      "Step: 389, Reward: -0.536311243816246\n",
      "Step: 4, State: [ 4.20434916  2.16768954  0.20498656 -0.99536632]\n",
      "Step: 390, Reward: -0.5373031478446553\n",
      "Step: 5, State: [ 4.21484781  2.0581529   0.10498656 -1.09536632]\n",
      "Step: 391, Reward: -0.5379816112004586\n",
      "Step: 6, State: [ 4.21534647  1.93861627  0.00498656 -1.19536632]\n",
      "Step: 392, Reward: -0.5382129883124576\n",
      "Step: 7, State: [ 4.20584513  1.80907964 -0.09501344 -1.29536633]\n",
      "Step: 393, Reward: -0.537887036992402\n",
      "Step: 8, State: [ 4.18634378  1.66954301 -0.19501344 -1.39536633]\n",
      "Step: 394, Reward: -0.5369261474078417\n",
      "Step: 9, State: [ 4.15684244  1.52000637 -0.29501344 -1.49536633]\n",
      "Step: 395, Reward: -0.5352862947902575\n",
      "Step: 10, State: [ 4.11734109  1.38046974 -0.39501344 -1.39536633]\n",
      "Step: 396, Reward: -0.5329547970311738\n",
      "Step: 11, State: [ 4.06783975  1.25093311 -0.49501345 -1.29536633]\n",
      "Step: 397, Reward: -0.5209124091494747\n",
      "Step: 12, State: [ 4.0083384   1.13139648 -0.59501345 -1.19536632]\n",
      "Step: 398, Reward: -0.5090622558866214\n",
      "Step: 13, State: [ 3.93883706  1.02185984 -0.69501345 -1.09536632]\n",
      "Step: 399, Reward: -0.49740086962419083\n",
      "Step: 14, State: [ 3.85933571  0.92232321 -0.79501345 -0.99536632]\n",
      "Step: 400, Reward: -0.4859279219912454\n",
      "Step: 15, State: [ 3.76983437  0.83278658 -0.89501345 -0.89536632]\n",
      "Step: 401, Reward: -0.47463834521190157\n",
      "Step: 16, State: [ 3.67033302  0.75324995 -0.99501345 -0.79536632]\n",
      "Step: 402, Reward: -0.4635139538887715\n",
      "Step: 17, State: [ 3.56083168  0.68371332 -1.09501345 -0.69536632]\n",
      "Step: 403, Reward: -0.4525168914249119\n",
      "Step: 18, State: [ 3.44133033  0.62417668 -1.19501346 -0.59536632]\n",
      "Step: 404, Reward: -0.44158718463610386\n",
      "Step: 19, State: [ 3.31182899  0.57464005 -1.29501346 -0.49536631]\n",
      "Step: 405, Reward: -0.4306454064732475\n",
      "Step: 20, State: [ 3.17232764  0.53510342 -1.39501346 -0.39536631]\n",
      "Step: 406, Reward: -0.41959957499297795\n",
      "Step: 21, State: [ 3.0228263   0.50556679 -1.49501346 -0.29536631]\n",
      "Step: 407, Reward: -0.40835414890809707\n",
      "Step: 22, State: [ 2.86332495  0.46603016 -1.59501346 -0.39536631]\n",
      "Step: 408, Reward: -0.3968189796144566\n",
      "Step: 23, State: [ 2.6938236   0.43649353 -1.69501346 -0.29536631]\n",
      "Step: 409, Reward: -0.386406559724158\n",
      "Step: 24, State: [ 2.51432226  0.4169569  -1.79501347 -0.19536631]\n",
      "Step: 410, Reward: -0.3730657281530674\n",
      "Step: 25, State: [ 2.32482091  0.38742027 -1.89501347 -0.29536631]\n",
      "Step: 411, Reward: -0.3592888600321751\n",
      "Step: 26, State: [ 2.12531956  0.34788364 -1.99501347 -0.39536631]\n",
      "Step: 412, Reward: -0.3457249060170209\n",
      "Step: 27, State: [ 1.91581822  0.318347   -2.09501347 -0.29536631]\n",
      "Step: 413, Reward: -0.33119306902548484\n",
      "Step: 28, State: [ 1.69631687  0.27881037 -2.19501347 -0.39536631]\n",
      "Step: 414, Reward: -0.3141375049629601\n",
      "Step: 29, State: [ 1.46681552  0.24927374 -2.29501347 -0.29536631]\n",
      "Step: 415, Reward: -0.29756664719117903\n",
      "Step: 30, State: [ 1.24731417  0.21291935 -2.19501347 -0.36354391]\n",
      "Step: 416, Reward: -0.27658465589106707\n",
      "Step: 31, State: [ 1.03781283  0.18656496 -2.09501347 -0.26354391]\n",
      "Step: 417, Reward: -0.25192356187288184\n",
      "Step: 32, State: [ 0.83831148  0.15021057 -1.99501347 -0.36354391]\n",
      "Step: 418, Reward: -0.22516323828967286\n",
      "Step: 33, State: [ 0.64881013  0.12385618 -1.89501347 -0.26354391]\n",
      "Step: 419, Reward: -0.20070173490196022\n",
      "Step: 34, State: [ 0.46930879  0.08750178 -1.79501347 -0.36354391]\n",
      "Step: 420, Reward: -0.1758573382461803\n",
      "Step: 35, State: [ 0.29980744  0.06114739 -1.69501346 -0.26354391]\n",
      "Step: 421, Reward: -0.15345466090691529\n",
      "Step: 36, State: [ 0.14030609  0.024793   -1.59501346 -0.36354391]\n",
      "Step: 422, Reward: -0.130509057159087\n",
      "Step: 37, State: [-0.00919525 -0.00156139 -1.49501346 -0.26354391]\n",
      "Step: 423, Reward: -0.11018608284375489\n",
      "Step: 38, State: [-0.1486966  -0.03791578 -1.39501346 -0.36354391]\n",
      "Step: 424, Reward: 9.909021938769687\n",
      "Step: 1, State: [-2.91823686  4.70494977 -0.86319585 -0.49756516]\n",
      "Step: 425, Reward: -0.6196596480387598\n",
      "Step: 2, State: [-2.99455645  4.64519325 -0.76319585 -0.59756516]\n",
      "Step: 426, Reward: -0.6176071858341347\n",
      "Step: 3, State: [-3.06087603  4.57543674 -0.66319585 -0.69756516]\n",
      "Step: 427, Reward: -0.6152843996239515\n",
      "Step: 4, State: [-3.11719562  4.49568022 -0.56319585 -0.79756516]\n",
      "Step: 428, Reward: -0.6127545517411317\n",
      "Step: 5, State: [-3.1635152   4.4059237  -0.46319585 -0.89756516]\n",
      "Step: 429, Reward: -0.6100260153150977\n",
      "Step: 6, State: [-3.19983478  4.30616719 -0.36319585 -0.99756516]\n",
      "Step: 430, Reward: -0.607045949584222\n",
      "Step: 7, State: [-3.22615437  4.19641067 -0.26319584 -1.09756517]\n",
      "Step: 431, Reward: -0.6037121372268658\n",
      "Step: 8, State: [-3.24247395  4.07665415 -0.16319584 -1.19756517]\n",
      "Step: 432, Reward: -0.5998958979323192\n",
      "Step: 9, State: [-3.24879354  3.94689764 -0.06319584 -1.29756517]\n",
      "Step: 433, Reward: -0.5954648452703134\n",
      "Step: 10, State: [-3.24511312  3.80714112  0.03680416 -1.39756517]\n",
      "Step: 434, Reward: -0.5902984331203183\n",
      "Step: 11, State: [-3.23143271  3.6573846   0.13680416 -1.49756517]\n",
      "Step: 435, Reward: -0.584295384068756\n",
      "Step: 12, State: [-3.20775229  3.49762809  0.23680416 -1.59756517]\n",
      "Step: 436, Reward: -0.5773754052675623\n",
      "Step: 13, State: [-3.17407187  3.32787157  0.33680416 -1.69756517]\n",
      "Step: 437, Reward: -0.5694779916516813\n",
      "Step: 14, State: [-3.13039146  3.14811505  0.43680417 -1.79756518]\n",
      "Step: 438, Reward: -0.5605602901783927\n",
      "Step: 15, State: [-3.07671104  2.95835853  0.53680417 -1.89756518]\n",
      "Step: 439, Reward: -0.5505951194424024\n",
      "Step: 16, State: [-3.01303062  2.75860202  0.63680417 -1.99756518]\n",
      "Step: 440, Reward: -0.5395696754262023\n",
      "Step: 17, State: [-2.93935021  2.5488455   0.73680417 -2.09756518]\n",
      "Step: 441, Reward: -0.5274851931166663\n",
      "Step: 18, State: [-2.85566979  2.32908898  0.83680417 -2.19756518]\n",
      "Step: 442, Reward: -0.5143577817765044\n",
      "Step: 19, State: [-2.76198937  2.11313026  0.93680417 -2.1595872 ]\n",
      "Step: 443, Reward: -0.49677549218976264\n",
      "Step: 20, State: [-2.65830895  1.90717154  1.03680417 -2.0595872 ]\n",
      "Step: 444, Reward: -0.47960614742024266\n",
      "Step: 21, State: [-2.54462854  1.71121282  1.13680418 -1.9595872 ]\n",
      "Step: 445, Reward: -0.4566020492326603\n",
      "Step: 22, State: [-2.42094812  1.5252541   1.23680418 -1.8595872 ]\n",
      "Step: 446, Reward: -0.43406447041162216\n",
      "Step: 23, State: [-2.2872677   1.34929538  1.33680418 -1.75958719]\n",
      "Step: 447, Reward: -0.411944635073432\n",
      "Step: 24, State: [-2.14358728  1.18333666  1.43680418 -1.65958719]\n",
      "Step: 448, Reward: -0.39019149623938476\n",
      "Step: 25, State: [-1.98990686  1.02737794  1.53680418 -1.55958719]\n",
      "Step: 449, Reward: -0.36875113181029723\n",
      "Step: 26, State: [-1.82622645  0.88141922  1.63680418 -1.45958719]\n",
      "Step: 450, Reward: -0.3475662638822842\n",
      "Step: 27, State: [-1.65254603  0.7454605   1.73680419 -1.35958719]\n",
      "Step: 451, Reward: -0.32657599609115795\n",
      "Step: 28, State: [-1.46886561  0.61950179  1.83680419 -1.25958719]\n",
      "Step: 452, Reward: -0.3057158436109113\n",
      "Step: 29, State: [-1.27518519  0.50354307  1.93680419 -1.15958718]\n",
      "Step: 453, Reward: -0.28491809871525375\n",
      "Step: 30, State: [-1.07150477  0.39758435  2.03680419 -1.05958718]\n",
      "Step: 454, Reward: -0.26411254833987213\n",
      "Step: 31, State: [-0.87782435  0.30162563  1.93680419 -0.95958718]\n",
      "Step: 455, Reward: -0.24322757712767776\n",
      "Step: 32, State: [-0.69414393  0.21566691  1.83680419 -0.85958718]\n",
      "Step: 456, Reward: -0.2150363048856962\n",
      "Step: 33, State: [-0.52046351  0.13970819  1.73680419 -0.75958718]\n",
      "Step: 457, Reward: -0.18822914143586206\n",
      "Step: 34, State: [-0.3567831   0.07374948  1.63680418 -0.65958718]\n",
      "Step: 458, Reward: -0.16281310778974417\n",
      "Step: 35, State: [-0.20310268  0.01779076  1.53680418 -0.55958718]\n",
      "Step: 459, Reward: -0.13880994024158036\n",
      "Step: 36, State: [-0.05942226 -0.02816796  1.43680418 -0.45958717]\n",
      "Step: 460, Reward: -0.11630585577535185\n",
      "Step: 37, State: [ 0.07425816 -0.06412668  1.33680418 -0.35958717]\n",
      "Step: 461, Reward: 9.903855916978111\n",
      "Step: 1, State: [-2.26808251  3.42927647 -0.37545711  0.44591671]\n",
      "Step: 462, Reward: -0.455695431887088\n",
      "Step: 2, State: [-2.29562822  3.46386814 -0.27545711  0.34591671]\n",
      "Step: 463, Reward: -0.45443512668234437\n",
      "Step: 3, State: [-2.31317393  3.48845981 -0.1754571   0.24591671]\n",
      "Step: 464, Reward: -0.4518031421781597\n",
      "Step: 4, State: [-2.32071964  3.50305148 -0.0754571   0.14591671]\n",
      "Step: 465, Reward: -0.4478172786803196\n",
      "Step: 5, State: [-2.31826535  3.50764315  0.0245429   0.0459167 ]\n",
      "Step: 466, Reward: -0.442559394483127\n",
      "Step: 6, State: [-2.30581106  3.50223482  0.1245429  -0.0540833 ]\n",
      "Step: 467, Reward: -0.43719647695357244\n",
      "Step: 7, State: [-2.28335677  3.48682649  0.2245429  -0.1540833 ]\n",
      "Step: 468, Reward: -0.44024497031986914\n",
      "Step: 8, State: [-2.25090248  3.46141816  0.3245429  -0.2540833 ]\n",
      "Step: 469, Reward: -0.4445518500713904\n",
      "Step: 9, State: [-2.20844819  3.42600983  0.4245429  -0.3540833 ]\n",
      "Step: 470, Reward: -0.44764274299778123\n",
      "Step: 10, State: [-2.1559939   3.3806015   0.52454291 -0.4540833 ]\n",
      "Step: 471, Reward: -0.4493956117839462\n",
      "Step: 11, State: [-2.09353961  3.32519317  0.62454291 -0.5540833 ]\n",
      "Step: 472, Reward: -0.44978991364860144\n",
      "Step: 12, State: [-2.02108532  3.25978484  0.72454291 -0.65408331]\n",
      "Step: 473, Reward: -0.4488225941659214\n",
      "Step: 13, State: [-1.93863103  3.18437651  0.82454291 -0.75408331]\n",
      "Step: 474, Reward: -0.44649654400654804\n",
      "Step: 14, State: [-1.84617674  3.09896818  0.92454291 -0.85408331]\n",
      "Step: 475, Reward: -0.4428180776790885\n",
      "Step: 15, State: [-1.74372244  3.00355985  1.02454291 -0.95408331]\n",
      "Step: 476, Reward: -0.4377965072054391\n",
      "Step: 16, State: [-1.65126815  2.89815152  0.92454291 -1.05408331]\n",
      "Step: 477, Reward: -0.43144451113324955\n",
      "Step: 17, State: [-1.54881386  2.78274319  1.02454291 -1.15408331]\n",
      "Step: 478, Reward: -0.41780302357640464\n",
      "Step: 18, State: [-1.44083554  2.65733486  1.07978322 -1.25408331]\n",
      "Step: 479, Reward: -0.4070590903840954\n",
      "Step: 19, State: [-1.32285722  2.52192652  1.17978323 -1.35408332]\n",
      "Step: 480, Reward: -0.39916848741762645\n",
      "Step: 20, State: [-1.21487889  2.37651819  1.07978322 -1.45408332]\n",
      "Step: 481, Reward: -0.3887212991772707\n",
      "Step: 21, State: [-1.11690057  2.22110986  0.97978322 -1.55408332]\n",
      "Step: 482, Reward: -0.37160389624131684\n",
      "Step: 22, State: [-1.02892225  2.05570153  0.87978322 -1.65408332]\n",
      "Step: 483, Reward: -0.35461210898652895\n",
      "Step: 23, State: [-0.95094393  1.8802932   0.77978322 -1.75408332]\n",
      "Step: 484, Reward: -0.3376995970330216\n",
      "Step: 24, State: [-0.88296561  1.69488486  0.67978322 -1.85408332]\n",
      "Step: 485, Reward: -0.320830468352191\n",
      "Step: 25, State: [-0.80498728  1.49947653  0.77978322 -1.95408333]\n",
      "Step: 486, Reward: -0.30398975514759446\n",
      "Step: 26, State: [-0.71700896  1.2940682   0.87978322 -2.05408333]\n",
      "Step: 487, Reward: -0.2895275640371055\n",
      "Step: 27, State: [-0.61903064  1.09865987  0.97978322 -1.95408333]\n",
      "Step: 488, Reward: -0.27381338323055654\n",
      "Step: 28, State: [-0.53105232  0.89325153  0.87978322 -2.05408333]\n",
      "Step: 489, Reward: -0.24954529746660492\n",
      "Step: 29, State: [-0.433074    0.6978432   0.97978322 -1.95408333]\n",
      "Step: 490, Reward: -0.22978929404787998\n",
      "Step: 30, State: [-0.32509567  0.51243487  1.07978322 -1.85408332]\n",
      "Step: 491, Reward: -0.20557036175660443\n",
      "Step: 31, State: [-0.20711735  0.33702654  1.17978323 -1.75408332]\n",
      "Step: 492, Reward: -0.18210744417965793\n",
      "Step: 32, State: [-0.09913903  0.17161821  1.07978322 -1.65408332]\n",
      "Step: 493, Reward: -0.15939671624376484\n",
      "Step: 33, State: [-1.16070565e-03  1.62098732e-02  9.79783223e-01 -1.55408332e+00]\n",
      "Step: 494, Reward: -0.13272809449637163\n",
      "Step: 34, State: [ 0.08681762 -0.12919846  0.87978322 -1.45408332]\n",
      "Step: 495, Reward: 9.892374818724043\n",
      "Step: 1, State: [ 0.52272044 -2.30086466 -0.03831692 -0.5583275 ]\n",
      "Step: 496, Reward: -0.27357116624581324\n",
      "Step: 2, State: [ 0.50888875 -2.34669741 -0.13831692 -0.4583275 ]\n",
      "Step: 497, Reward: -0.278073635665191\n",
      "Step: 3, State: [ 0.50505706 -2.38253016 -0.03831692 -0.3583275 ]\n",
      "Step: 498, Reward: -0.278203389588292\n",
      "Step: 4, State: [ 0.49122536 -2.40836291 -0.13831692 -0.2583275 ]\n",
      "Step: 499, Reward: -0.27570803215262246\n",
      "Step: 5, State: [ 0.48739367 -2.42419566 -0.03831692 -0.1583275 ]\n",
      "Step: 500, Reward: -0.274588392429646\n",
      "Step: 6, State: [ 0.47356198 -2.43002841 -0.13831692 -0.0583275 ]\n",
      "Step: 501, Reward: -0.2695576845249496\n",
      "Step: 7, State: [ 0.46973029 -2.42586116 -0.03831692  0.04167251]\n",
      "Step: 502, Reward: -0.2692219564379919\n",
      "Step: 8, State: [ 0.4558986  -2.41169391 -0.13831692  0.14167251]\n",
      "Step: 503, Reward: -0.2640647423415433\n",
      "Step: 9, State: [ 0.4320669  -2.38752666 -0.23831692  0.24167251]\n",
      "Step: 504, Reward: -0.269482613141852\n",
      "Step: 10, State: [ 0.41823521 -2.35335941 -0.13831692  0.34167251]\n",
      "Step: 505, Reward: -0.2737434331771675\n",
      "Step: 11, State: [ 0.39440352 -2.30919216 -0.23831692  0.44167251]\n",
      "Step: 506, Reward: -0.27159597801273533\n",
      "Step: 12, State: [ 0.36057183 -2.25502491 -0.33831693  0.54167251]\n",
      "Step: 507, Reward: -0.2734985940904606\n",
      "Step: 13, State: [ 0.31674013 -2.19085766 -0.43831693  0.64167251]\n",
      "Step: 508, Reward: -0.2744414015332074\n",
      "Step: 14, State: [ 0.26290844 -2.1166904  -0.53831693  0.74167252]\n",
      "Step: 509, Reward: -0.2743600596985145\n",
      "Step: 15, State: [ 0.21907675 -2.03252315 -0.43831693  0.84167252]\n",
      "Step: 510, Reward: -0.2732597105159624\n",
      "Step: 16, State: [ 0.18524506 -1.9383559  -0.33831693  0.94167252]\n",
      "Step: 511, Reward: -0.2660199516227417\n",
      "Step: 17, State: [ 0.16141336 -1.83418865 -0.23831692  1.04167252]\n",
      "Step: 512, Reward: -0.25889101751996635\n",
      "Step: 18, State: [ 0.14758167 -1.7200214  -0.13831692  1.14167252]\n",
      "Step: 513, Reward: -0.2516991832390507\n",
      "Step: 19, State: [ 0.12374998 -1.59585414 -0.23831692  1.24167252]\n",
      "Step: 514, Reward: -0.24427729318855276\n",
      "Step: 20, State: [ 0.10991829 -1.46168689 -0.13831692  1.34167252]\n",
      "Step: 515, Reward: -0.23742344002637197\n",
      "Step: 21, State: [ 0.10608659 -1.31751964 -0.03831692  1.44167253]\n",
      "Step: 516, Reward: -0.22816270394016036\n",
      "Step: 22, State: [ 0.0922549  -1.16335239 -0.13831692  1.54167253]\n",
      "Step: 517, Reward: -0.21842959514407223\n",
      "Step: 23, State: [ 0.08842321 -0.99918513 -0.03831692  1.64167253]\n",
      "Step: 518, Reward: -0.20823584071359438\n",
      "Step: 24, State: [ 0.07459152 -0.82501788 -0.13831692  1.74167253]\n",
      "Step: 519, Reward: -0.19655711924071026\n",
      "Step: 25, State: [ 0.07075983 -0.66085063 -0.03831692  1.64167253]\n",
      "Step: 520, Reward: -0.18433824539361965\n",
      "Step: 26, State: [ 0.05692813 -0.50668337 -0.13831692  1.54167253]\n",
      "Step: 521, Reward: -0.1627109264080604\n",
      "Step: 27, State: [ 0.05309644 -0.36251612 -0.03831692  1.44167253]\n",
      "Step: 522, Reward: -0.14252252146031685\n",
      "Step: 28, State: [ 0.03926475 -0.22834887 -0.13831692  1.34167252]\n",
      "Step: 523, Reward: -0.12288960817033082\n",
      "Step: 29, State: [ 0.01543306 -0.10418162 -0.23831692  1.24167252]\n",
      "Step: 524, Reward: -0.10475131470895631\n",
      "Step: 30, State: [ 0.00160136  0.00998563 -0.13831692  1.14167252]\n",
      "Step: 525, Reward: -0.08789078820908124\n",
      "Step: 31, State: [-0.02223033  0.11415289 -0.23831692  1.04167252]\n",
      "Step: 526, Reward: 9.927345505010111\n",
      "Step: 1, State: [ 1.9876911  -3.57409652 -0.20049361 -0.43641312]\n",
      "Step: 527, Reward: -0.44757144453560516\n",
      "Step: 2, State: [ 1.95764173 -3.60773783 -0.30049362 -0.33641312]\n",
      "Step: 528, Reward: -0.44711846775880504\n",
      "Step: 3, State: [ 1.91759237 -3.63137915 -0.40049362 -0.23641312]\n",
      "Step: 529, Reward: -0.44716074951657403\n",
      "Step: 4, State: [ 1.86754301 -3.64502046 -0.50049362 -0.13641312]\n",
      "Step: 530, Reward: -0.4480543527079487\n",
      "Step: 5, State: [ 1.80749365 -3.64866177 -0.60049362 -0.03641312]\n",
      "Step: 531, Reward: -0.4496390858208789\n",
      "Step: 6, State: [ 1.73744429 -3.64230308 -0.70049362  0.06358689]\n",
      "Step: 532, Reward: -0.4514045547893638\n",
      "Step: 7, State: [ 1.65739492 -3.62594439 -0.80049362  0.16358689]\n",
      "Step: 533, Reward: -0.4528586429240414\n",
      "Step: 8, State: [ 1.58734556 -3.5995857  -0.70049362  0.26358689]\n",
      "Step: 534, Reward: -0.4536722230753498\n",
      "Step: 9, State: [ 1.5072962  -3.56322701 -0.80049362  0.36358689]\n",
      "Step: 535, Reward: -0.444968524986937\n",
      "Step: 10, State: [ 1.41724684 -3.51686832 -0.90049362  0.46358689]\n",
      "Step: 536, Reward: -0.4449937585245042\n",
      "Step: 11, State: [ 1.33719747 -3.46050964 -0.80049362  0.56358689]\n",
      "Step: 537, Reward: -0.4439525725896848\n",
      "Step: 12, State: [ 1.26714811 -3.39415095 -0.70049362  0.6635869 ]\n",
      "Step: 538, Reward: -0.43407979911531114\n",
      "Step: 13, State: [ 1.20709875 -3.31779226 -0.60049362  0.7635869 ]\n",
      "Step: 539, Reward: -0.4246844978116581\n",
      "Step: 14, State: [ 1.1486544  -3.23143357 -0.58444347  0.8635869 ]\n",
      "Step: 540, Reward: -0.41175470449104085\n",
      "Step: 15, State: [ 1.08021006 -3.13507488 -0.68444347  0.9635869 ]\n",
      "Step: 541, Reward: -0.40923178103632657\n",
      "Step: 16, State: [ 1.00176571 -3.02871619 -0.78444347  1.0635869 ]\n",
      "Step: 542, Reward: -0.40483408068332716\n",
      "Step: 17, State: [ 0.93332136 -2.9123575  -0.68444347  1.1635869 ]\n",
      "Step: 543, Reward: -0.39922975898726365\n",
      "Step: 18, State: [ 0.85487701 -2.78599881 -0.78444347  1.2635869 ]\n",
      "Step: 544, Reward: -0.38746559217806953\n",
      "Step: 19, State: [ 0.78643267 -2.64964011 -0.68444347  1.36358691]\n",
      "Step: 545, Reward: -0.3799268904725831\n",
      "Step: 20, State: [ 0.70798832 -2.50328142 -0.78444347  1.46358691]\n",
      "Step: 546, Reward: -0.366816967945047\n",
      "Step: 21, State: [ 0.63954397 -2.34692273 -0.68444347  1.56358691]\n",
      "Step: 547, Reward: -0.35731718326367334\n",
      "Step: 22, State: [ 0.56109962 -2.18056404 -0.78444347  1.66358691]\n",
      "Step: 548, Reward: -0.34273374438058263\n",
      "Step: 23, State: [ 0.47265528 -2.00420535 -0.88444348  1.76358691]\n",
      "Step: 549, Reward: -0.33126484874109374\n",
      "Step: 24, State: [ 0.39421093 -1.81784666 -0.78444347  1.86358691]\n",
      "Step: 550, Reward: -0.31870744971558607\n",
      "Step: 25, State: [ 0.30576658 -1.62148797 -0.88444348  1.96358691]\n",
      "Step: 551, Reward: -0.3012498681270589\n",
      "Step: 26, State: [ 0.22732223 -1.41512928 -0.78444347  2.06358692]\n",
      "Step: 552, Reward: -0.2868277752918402\n",
      "Step: 27, State: [ 0.13887789 -1.19877058 -0.88444348  2.16358692]\n",
      "Step: 553, Reward: -0.2678520249106712\n",
      "Step: 28, State: [ 0.06043354 -0.99241189 -0.78444347  2.06358692]\n",
      "Step: 554, Reward: -0.2516900004096213\n",
      "Step: 29, State: [-0.00801081 -0.7960532  -0.68444347  1.96358691]\n",
      "Step: 555, Reward: -0.22394993312910066\n",
      "Step: 30, State: [-0.06645516 -0.60969451 -0.58444347  1.86358691]\n",
      "Step: 556, Reward: -0.19772427632542286\n",
      "Step: 31, State: [-0.1148995  -0.41333582 -0.48444347  1.96358691]\n",
      "Step: 557, Reward: -0.17312680274898196\n",
      "Step: 32, State: [-0.15334385 -0.22697713 -0.38444347  1.86358691]\n",
      "Step: 558, Reward: -0.15816617766058508\n",
      "Step: 33, State: [-0.1817882  -0.05061844 -0.28444347  1.76358691]\n",
      "Step: 559, Reward: -0.1366756600505543\n",
      "Step: 34, State: [-0.20023254  0.11574025 -0.18444347  1.66358691]\n",
      "Step: 560, Reward: -0.12233143601367606\n",
      "Step: 35, State: [-0.20867689  0.27209895 -0.08444346  1.56358691]\n",
      "Step: 561, Reward: -0.12095881758877178\n",
      "Step: 36, State: [-0.20712124  0.41845764  0.01555654  1.46358691]\n",
      "Step: 562, Reward: -0.12672591570485978\n",
      "Step: 37, State: [-0.21556558  0.55481633 -0.08444346  1.36358691]\n",
      "Step: 563, Reward: -0.13401672702087902\n",
      "Step: 38, State: [-0.21400993  0.68117502  0.01555654  1.2635869 ]\n",
      "Step: 564, Reward: -0.14197432738182153\n",
      "Step: 39, State: [-0.20245427  0.79753371  0.11555654  1.1635869 ]\n",
      "Step: 565, Reward: -0.14872652435345535\n",
      "Step: 40, State: [-0.18089862  0.9038924   0.21555654  1.0635869 ]\n",
      "Step: 566, Reward: -0.15489058762353974\n",
      "Step: 41, State: [-0.15802068  1.00025109  0.22877938  0.9635869 ]\n",
      "Step: 567, Reward: -0.15652922190185053\n",
      "Step: 42, State: [-0.14514274  1.08660978  0.12877938  0.8635869 ]\n",
      "Step: 568, Reward: -0.16492644123784417\n",
      "Step: 43, State: [-0.14226481  1.16296847  0.02877938  0.7635869 ]\n",
      "Step: 569, Reward: -0.16742499138408873\n",
      "Step: 44, State: [-0.14938687  1.22932716 -0.07122063  0.6635869 ]\n",
      "Step: 570, Reward: -0.1695123591053143\n",
      "Step: 45, State: [-0.16650893  1.28568585 -0.17122063  0.56358689]\n",
      "Step: 571, Reward: -0.17134908803635265\n",
      "Step: 46, State: [-0.173631    1.33204454 -0.07122063  0.46358689]\n",
      "Step: 572, Reward: -0.1732355537511609\n",
      "Step: 47, State: [-0.17075306  1.36840322  0.02877938  0.36358689]\n",
      "Step: 573, Reward: -0.1719247450125046\n",
      "Step: 48, State: [-0.17787512  1.39476191 -0.07122063  0.26358689]\n",
      "Step: 574, Reward: -0.1702798999036845\n",
      "Step: 49, State: [-0.17499718  1.4111206   0.02877938  0.16358689]\n",
      "Step: 575, Reward: -0.16839994193637825\n",
      "Step: 50, State: [-0.16211925  1.41747929  0.12877938  0.06358689]\n",
      "Step: 576, Reward: -0.1646401076806777\n",
      "Step: 51, State: [-0.13924131  1.41383798  0.22877938 -0.03641312]\n",
      "Step: 577, Reward: -0.1639952680561294\n",
      "Step: 52, State: [-0.10636337  1.40019667  0.32877938 -0.13641312]\n",
      "Step: 578, Reward: -0.16779288803684447\n",
      "Step: 53, State: [-0.08348543  1.37655536  0.22877938 -0.23641312]\n",
      "Step: 579, Reward: -0.17236298803460542\n",
      "Step: 54, State: [-0.07060749  1.34291404  0.12877938 -0.33641312]\n",
      "Step: 580, Reward: -0.16849985288369906\n",
      "Step: 55, State: [-0.06772956  1.29927273  0.02877938 -0.43641312]\n",
      "Step: 581, Reward: -0.166629994059251\n",
      "Step: 56, State: [-0.05485162  1.24563142  0.12877938 -0.53641312]\n",
      "Step: 582, Reward: -0.16611387307241093\n",
      "Step: 57, State: [-0.03197368  1.18199011  0.22877938 -0.63641312]\n",
      "Step: 583, Reward: -0.16640873562521388\n",
      "Step: 58, State: [-0.01909574  1.10834879  0.12877938 -0.73641313]\n",
      "Step: 584, Reward: -0.1661986436258131\n",
      "Step: 59, State: [-0.01621781  1.02470748  0.02877938 -0.83641313]\n",
      "Step: 585, Reward: -0.16237288378122533\n",
      "Step: 60, State: [-0.02333987  0.93106617 -0.07122063 -0.93641313]\n",
      "Step: 586, Reward: -0.15847112166287466\n",
      "Step: 61, State: [-0.02046193  0.82742486  0.02877938 -1.03641313]\n",
      "Step: 587, Reward: -0.15423388332694135\n",
      "Step: 62, State: [-0.02758399  0.71378354 -0.07122063 -1.13641313]\n",
      "Step: 588, Reward: -0.14875054943002086\n",
      "Step: 63, State: [-0.02470606  0.59014223  0.02877938 -1.23641313]\n",
      "Step: 589, Reward: -0.14250590331149843\n",
      "Step: 64, State: [-0.03182812  0.45650092 -0.07122063 -1.33641313]\n",
      "Step: 590, Reward: -0.13504545261464712\n",
      "Step: 65, State: [-0.02895018  0.3328596   0.02877938 -1.23641313]\n",
      "Step: 591, Reward: -0.12681852572321708\n",
      "Step: 66, State: [-0.01607224  0.21921829  0.12877938 -1.13641313]\n",
      "Step: 592, Reward: -0.10939115583334384\n",
      "Step: 67, State: [-0.01319431  0.11557698  0.02877938 -1.03641313]\n",
      "Step: 593, Reward: -0.09330713085962651\n",
      "Step: 68, State: [-3.16368845e-04  2.19356641e-02  1.28779377e-01 -9.36413128e-01]\n",
      "Step: 594, Reward: -0.07761553406828692\n",
      "Step: 69, State: [ 0.00256157 -0.06170565  0.02877938 -0.83641313]\n",
      "Step: 595, Reward: 9.936402730832734\n",
      "Step: 1, State: [ 4.01853405  3.64168209 -0.09245308 -0.59751382]\n",
      "Step: 596, Reward: -0.5860455168622725\n",
      "Step: 2, State: [ 3.99928874  3.57193071 -0.19245308 -0.69751382]\n",
      "Step: 597, Reward: -0.5866874977473399\n",
      "Step: 3, State: [ 3.97004343  3.49217933 -0.29245308 -0.79751382]\n",
      "Step: 598, Reward: -0.586539220856934\n",
      "Step: 4, State: [ 3.93079812  3.40242795 -0.39245308 -0.89751382]\n",
      "Step: 599, Reward: -0.5853540400720063\n",
      "Step: 5, State: [ 3.88155282  3.30267657 -0.49245308 -0.99751382]\n",
      "Step: 600, Reward: -0.5830020788616047\n",
      "Step: 6, State: [ 3.82230751  3.19292518 -0.59245309 -1.09751383]\n",
      "Step: 601, Reward: -0.5794127705480036\n",
      "Step: 7, State: [ 3.7530622   3.0731738  -0.69245309 -1.19751383]\n",
      "Step: 602, Reward: -0.5745469590822513\n",
      "Step: 8, State: [ 3.67381689  2.94342242 -0.79245309 -1.29751383]\n",
      "Step: 603, Reward: -0.5683833529444458\n",
      "Step: 9, State: [ 3.58457158  2.80367103 -0.89245309 -1.39751383]\n",
      "Step: 604, Reward: -0.560911786938993\n",
      "Step: 10, State: [ 3.48532627  2.65391965 -0.99245309 -1.49751383]\n",
      "Step: 605, Reward: -0.5521298649505795\n",
      "Step: 11, State: [ 3.37608096  2.49416827 -1.09245309 -1.59751383]\n",
      "Step: 606, Reward: -0.542041431686615\n",
      "Step: 12, State: [ 3.25683565  2.32441688 -1.1924531  -1.69751383]\n",
      "Step: 607, Reward: -0.5306561806927397\n",
      "Step: 13, State: [ 3.12759034  2.1446655  -1.2924531  -1.79751384]\n",
      "Step: 608, Reward: -0.5179901358135536\n",
      "Step: 14, State: [ 2.98834503  1.97491412 -1.3924531  -1.69751383]\n",
      "Step: 609, Reward: -0.5040670059531407\n",
      "Step: 15, State: [ 2.83909972  1.81516273 -1.4924531  -1.59751383]\n",
      "Step: 610, Reward: -0.48211683886411816\n",
      "Step: 16, State: [ 2.67985441  1.66541135 -1.5924531  -1.49751383]\n",
      "Step: 611, Reward: -0.46042839725307705\n",
      "Step: 17, State: [ 2.5106091   1.52565997 -1.6924531  -1.39751383]\n",
      "Step: 612, Reward: -0.4389593704523801\n",
      "Step: 18, State: [ 2.33136379  1.39590858 -1.7924531  -1.29751383]\n",
      "Step: 613, Reward: -0.41766767081200296\n",
      "Step: 19, State: [ 2.14211848  1.2761572  -1.89245311 -1.19751383]\n",
      "Step: 614, Reward: -0.3965133447374814\n",
      "Step: 20, State: [ 1.94287317  1.14640582 -1.99245311 -1.29751383]\n",
      "Step: 615, Reward: -0.3754618969260813\n",
      "Step: 21, State: [ 1.73362786  1.00665444 -2.09245311 -1.39751383]\n",
      "Step: 616, Reward: -0.3586148289129245\n",
      "Step: 22, State: [ 1.51438255  0.85690305 -2.19245311 -1.49751383]\n",
      "Step: 617, Reward: -0.34042346668174683\n",
      "Step: 23, State: [ 1.30513724  0.71715167 -2.09245311 -1.39751383]\n",
      "Step: 618, Reward: -0.32089672372378597\n",
      "Step: 24, State: [ 1.10589193  0.58740029 -1.99245311 -1.29751383]\n",
      "Step: 619, Reward: -0.2888726473871474\n",
      "Step: 25, State: [ 0.89664662  0.4676489  -2.09245311 -1.19751383]\n",
      "Step: 620, Reward: -0.2582479004156338\n",
      "Step: 26, State: [ 0.67740131  0.35789752 -2.19245311 -1.09751383]\n",
      "Step: 621, Reward: -0.2358139064336361\n",
      "Step: 27, State: [ 0.46815599  0.23814614 -2.09245311 -1.19751383]\n",
      "Step: 622, Reward: -0.2133463092331687\n",
      "Step: 28, State: [ 0.26891068  0.12839476 -1.99245311 -1.09751383]\n",
      "Step: 623, Reward: -0.18721135106387052\n",
      "Step: 29, State: [ 0.07966537  0.02864337 -1.89245311 -0.99751382]\n",
      "Step: 624, Reward: -0.1576777604666077\n",
      "Step: 30, State: [-0.09957994 -0.06110801 -1.7924531  -0.89751382]\n",
      "Step: 625, Reward: 9.870429285035865\n",
      "Step: 1, State: [-3.57834879  1.19601142  0.4679951  -0.63312399]\n",
      "Step: 626, Reward: -0.43029751979175823\n",
      "Step: 2, State: [-3.52154928  1.12269902  0.5679951  -0.73312399]\n",
      "Step: 627, Reward: -0.43080120044623016\n",
      "Step: 3, State: [-3.45474977  1.03938662  0.66799511 -0.833124  ]\n",
      "Step: 628, Reward: -0.43013084718895445\n",
      "Step: 4, State: [-3.37795025  0.94607423  0.76799511 -0.933124  ]\n",
      "Step: 629, Reward: -0.42830653606750496\n",
      "Step: 5, State: [-3.29115074  0.84276183  0.86799511 -1.033124  ]\n",
      "Step: 630, Reward: -0.42536192104031667\n",
      "Step: 6, State: [-3.19435123  0.74944943  0.96799511 -0.933124  ]\n",
      "Step: 631, Reward: -0.42134394266488434\n",
      "Step: 7, State: [-3.08755172  0.66613703  1.06799511 -0.833124  ]\n",
      "Step: 632, Reward: -0.40947719250506587\n",
      "Step: 8, State: [-2.97075221  0.59282463  1.16799511 -0.73312399]\n",
      "Step: 633, Reward: -0.3977272235447911\n",
      "Step: 9, State: [-2.8439527   0.50951223  1.26799512 -0.833124  ]\n",
      "Step: 634, Reward: -0.38602539994576657\n",
      "Step: 10, State: [-2.70715319  0.43619983  1.36799512 -0.73312399]\n",
      "Step: 635, Reward: -0.37892566302954056\n",
      "Step: 11, State: [-2.56035368  0.37288743  1.46799512 -0.63312399]\n",
      "Step: 636, Reward: -0.36595200769258585\n",
      "Step: 12, State: [-2.40355416  0.31957503  1.56799512 -0.53312399]\n",
      "Step: 637, Reward: -0.3528138215833977\n",
      "Step: 13, State: [-2.23675465  0.2622101   1.66799512 -0.57364924]\n",
      "Step: 638, Reward: -0.3360680355584557\n",
      "Step: 14, State: [-2.05995514  0.21484518  1.76799512 -0.47364924]\n",
      "Step: 639, Reward: -0.3275433942810635\n",
      "Step: 15, State: [-1.87315563  0.15748026  1.86799512 -0.57364924]\n",
      "Step: 640, Reward: -0.3127720738589382\n",
      "Step: 16, State: [-1.67635611  0.11011533  1.96799513 -0.47364924]\n",
      "Step: 641, Reward: -0.2998231649098669\n",
      "Step: 17, State: [-1.4695566   0.07275041  2.06799513 -0.37364924]\n",
      "Step: 642, Reward: -0.2833485567488074\n",
      "Step: 18, State: [-1.25275709  0.04538549  2.16799513 -0.27364923]\n",
      "Step: 643, Reward: -0.2663517537113335\n",
      "Step: 19, State: [-1.04595758  0.02802056  2.06799513 -0.17364923]\n",
      "Step: 644, Reward: -0.2487598893541847\n",
      "Step: 20, State: [-8.49158063e-01  6.55640365e-04  1.96799513e+00 -2.73649234e-01]\n",
      "Step: 645, Reward: -0.22253906740590274\n",
      "Step: 21, State: [-0.66235855 -0.01670928  1.86799512 -0.17364923]\n",
      "Step: 646, Reward: -0.1984044404686141\n",
      "Step: 22, State: [-0.48555904 -0.02407421  1.76799512 -0.07364923]\n",
      "Step: 647, Reward: -0.17420151314235494\n",
      "Step: 23, State: [-0.31875953 -0.02143913  1.66799512  0.02635077]\n",
      "Step: 648, Reward: -0.15123410588391661\n",
      "Step: 24, State: [-0.16196001 -0.00880405  1.56799512  0.12635077]\n",
      "Step: 649, Reward: -0.12950026684636318\n",
      "Step: 25, State: [-0.0151605   0.01383103  1.46799512  0.22635077]\n",
      "Step: 650, Reward: -0.10901592952460748\n",
      "Step: 26, State: [0.12163901 0.0264661  1.36799512 0.12635077]\n",
      "Step: 651, Reward: 9.909538541031754\n",
      "Step: 1, State: [-2.41111117 -4.36475819  0.71269041  0.84105352]\n",
      "Step: 652, Reward: -0.5716754493738623\n",
      "Step: 2, State: [-2.32984213 -4.27065283  0.81269041  0.94105352]\n",
      "Step: 653, Reward: -0.567906299262938\n",
      "Step: 3, State: [-2.23857309 -4.16654748  0.91269041  1.04105352]\n",
      "Step: 654, Reward: -0.5627959227671291\n",
      "Step: 4, State: [-2.13730405 -4.05244213  1.01269041  1.14105352]\n",
      "Step: 655, Reward: -0.5563497162025346\n",
      "Step: 5, State: [-2.02603501 -3.92833678  1.11269041  1.24105352]\n",
      "Step: 656, Reward: -0.5485759350598314\n",
      "Step: 6, State: [-1.90476596 -3.79423142  1.21269041  1.34105353]\n",
      "Step: 657, Reward: -0.539486010537788\n",
      "Step: 7, State: [-1.79349692 -3.65012607  1.11269041  1.44105353]\n",
      "Step: 658, Reward: -0.5290952553845769\n",
      "Step: 8, State: [-1.67222788 -3.49602072  1.21269041  1.54105353]\n",
      "Step: 659, Reward: -0.5118685542841283\n",
      "Step: 9, State: [-1.56095884 -3.33191537  1.11269041  1.64105353]\n",
      "Step: 660, Reward: -0.4997285936717432\n",
      "Step: 10, State: [-1.4596898  -3.15781001  1.01269041  1.74105353]\n",
      "Step: 661, Reward: -0.4812212502308631\n",
      "Step: 11, State: [-1.34842076 -2.97370466  1.11269041  1.84105353]\n",
      "Step: 662, Reward: -0.46273562529497386\n",
      "Step: 12, State: [-1.24715172 -2.77959931  1.01269041  1.94105353]\n",
      "Step: 663, Reward: -0.44821522070560704\n",
      "Step: 13, State: [-1.15588268 -2.57549395  0.91269041  2.04105354]\n",
      "Step: 664, Reward: -0.42826589890890465\n",
      "Step: 14, State: [-1.07461364 -2.3613886   0.81269041  2.14105354]\n",
      "Step: 665, Reward: -0.40823158720470876\n",
      "Step: 15, State: [-0.98334459 -2.13728324  0.91269041  2.24105354]\n",
      "Step: 666, Reward: -0.3880880870210456\n",
      "Step: 16, State: [-0.90207555 -1.90317789  0.81269041  2.34105354]\n",
      "Step: 667, Reward: -0.3703956918511829\n",
      "Step: 17, State: [-0.81080651 -1.67907254  0.91269041  2.24105354]\n",
      "Step: 668, Reward: -0.3486613309323415\n",
      "Step: 18, State: [-0.72953747 -1.46496718  0.81269041  2.14105354]\n",
      "Step: 669, Reward: -0.3215899173491208\n",
      "Step: 19, State: [-0.63826843 -1.26086183  0.91269041  2.04105354]\n",
      "Step: 670, Reward: -0.29230409913308747\n",
      "Step: 20, State: [-0.53699939 -1.06675648  1.01269041  1.94105353]\n",
      "Step: 671, Reward: -0.2672541533493914\n",
      "Step: 21, State: [-0.44573035 -0.88265112  0.91269041  1.84105353]\n",
      "Step: 672, Reward: -0.2430387575631694\n",
      "Step: 22, State: [-0.36446131 -0.70854577  0.81269041  1.74105353]\n",
      "Step: 673, Reward: -0.21576669647708738\n",
      "Step: 23, State: [-0.27319227 -0.54444042  0.91269041  1.64105353]\n",
      "Step: 674, Reward: -0.1898902283350848\n",
      "Step: 24, State: [-0.19192323 -0.39033506  0.81269041  1.54105353]\n",
      "Step: 675, Reward: -0.16894499472526675\n",
      "Step: 25, State: [-0.10065418 -0.24622971  0.91269041  1.44105353]\n",
      "Step: 676, Reward: -0.14474952980494443\n",
      "Step: 26, State: [-0.01938514 -0.11212436  0.81269041  1.34105353]\n",
      "Step: 677, Reward: -0.12603127083279161\n",
      "Step: 27, State: [0.0518839  0.01198099 0.71269041 1.24105352]\n",
      "Step: 678, Reward: -0.10392515691802176\n",
      "Step: 28, State: [0.11315294 0.12608635 0.61269041 1.14105352]\n",
      "Step: 679, Reward: 9.90897629271255\n",
      "Step: 1, State: [-3.04885974  4.82442274  0.17666236 -0.98875604]\n",
      "Step: 680, Reward: -0.6387660545007409\n",
      "Step: 2, State: [-3.0211935   4.71554714  0.27666236 -1.08875605]\n",
      "Step: 681, Reward: -0.6350694350806629\n",
      "Step: 3, State: [-2.98352727  4.59667153  0.37666237 -1.18875605]\n",
      "Step: 682, Reward: -0.6303456726971133\n",
      "Step: 4, State: [-2.93586103  4.46779593  0.47666237 -1.28875605]\n",
      "Step: 683, Reward: -0.6244961352048805\n",
      "Step: 5, State: [-2.87819479  4.32892032  0.57666237 -1.38875605]\n",
      "Step: 684, Reward: -0.6174533455261938\n",
      "Step: 6, State: [-2.81052856  4.18004472  0.67666237 -1.48875605]\n",
      "Step: 685, Reward: -0.6091701501194166\n",
      "Step: 7, State: [-2.73286232  4.02116911  0.77666237 -1.58875605]\n",
      "Step: 686, Reward: -0.59961278083835\n",
      "Step: 8, State: [-2.64519608  3.85229351  0.87666237 -1.68875606]\n",
      "Step: 687, Reward: -0.5887564485323262\n",
      "Step: 9, State: [-2.54752984  3.6734179   0.97666237 -1.78875606]\n",
      "Step: 688, Reward: -0.5765825196412823\n",
      "Step: 10, State: [-2.43986361  3.4845423   1.07666238 -1.88875606]\n",
      "Step: 689, Reward: -0.5630766769984084\n",
      "Step: 11, State: [-2.32219737  3.28566669  1.17666238 -1.98875606]\n",
      "Step: 690, Reward: -0.5482276981829451\n",
      "Step: 12, State: [-2.19453113  3.07679108  1.27666238 -2.08875606]\n",
      "Step: 691, Reward: -0.5320266276200055\n",
      "Step: 13, State: [-2.05686489  2.85791548  1.37666238 -2.18875606]\n",
      "Step: 692, Reward: -0.5144662046588417\n",
      "Step: 14, State: [-1.90919865  2.62903987  1.47666238 -2.28875606]\n",
      "Step: 693, Reward: -0.49554046176145417\n",
      "Step: 15, State: [-1.75153242  2.39016427  1.57666238 -2.38875607]\n",
      "Step: 694, Reward: -0.47524443875751154\n",
      "Step: 16, State: [-1.60386618  2.14128866  1.47666238 -2.48875607]\n",
      "Step: 695, Reward: -0.45357397936613764\n",
      "Step: 17, State: [-1.44619994  1.90241305  1.57666238 -2.38875607]\n",
      "Step: 696, Reward: -0.42637036252927774\n",
      "Step: 18, State: [-1.2985337   1.67353745  1.47666238 -2.28875606]\n",
      "Step: 697, Reward: -0.3962207342176855\n",
      "Step: 19, State: [-1.14086746  1.45466184  1.57666238 -2.18875606]\n",
      "Step: 698, Reward: -0.3621542046094042\n",
      "Step: 20, State: [-0.97354125  1.22578623  1.67326216 -2.28875606]\n",
      "Step: 699, Reward: -0.33364693662502165\n",
      "Step: 21, State: [-0.81621503  1.00691063  1.57326215 -2.18875606]\n",
      "Step: 700, Reward: -0.3124362677827981\n",
      "Step: 22, State: [-0.66888882  0.79803502  1.47326215 -2.08875606]\n",
      "Step: 701, Reward: -0.2785356843424045\n",
      "Step: 23, State: [-0.5315626   0.57915941  1.37326215 -2.18875606]\n",
      "Step: 702, Reward: -0.24607313848550927\n",
      "Step: 24, State: [-0.38423639  0.37028381  1.47326215 -2.08875606]\n",
      "Step: 703, Reward: -0.22194876120554108\n",
      "Step: 25, State: [-0.24691017  0.1714082   1.37326215 -1.98875606]\n",
      "Step: 704, Reward: -0.19530650519017081\n",
      "Step: 26, State: [-0.11958396 -0.0174674   1.27326215 -1.88875606]\n",
      "Step: 705, Reward: -0.165040447849687\n",
      "Step: 27, State: [-0.00225774 -0.19634301  1.17326215 -1.78875606]\n",
      "Step: 706, Reward: -0.14011987791828404\n",
      "Step: 28, State: [ 0.10506847 -0.36521862  1.07326215 -1.68875606]\n",
      "Step: 707, Reward: -0.1407379174181442\n",
      "Step: 29, State: [ 0.20239469 -0.52409422  0.97326215 -1.58875605]\n",
      "Step: 708, Reward: -0.1521926428687994\n",
      "Step: 30, State: [ 0.2897209  -0.67296983  0.87326214 -1.48875605]\n",
      "Step: 709, Reward: -0.1634821031354445\n",
      "Step: 31, State: [ 0.36704712 -0.81184543  0.77326214 -1.38875605]\n",
      "Step: 710, Reward: -0.17370921532067113\n",
      "Step: 32, State: [ 0.43437333 -0.94072104  0.67326214 -1.28875605]\n",
      "Step: 711, Reward: -0.18271458187139072\n",
      "Step: 33, State: [ 0.49169955 -1.05959664  0.57326214 -1.18875605]\n",
      "Step: 712, Reward: -0.1904595542059374\n",
      "Step: 34, State: [ 0.53902576 -1.16847225  0.47326214 -1.08875605]\n",
      "Step: 713, Reward: -0.19694260213350057\n",
      "Step: 35, State: [ 0.57635197 -1.26734785  0.37326214 -0.98875604]\n",
      "Step: 714, Reward: -0.20218136426726993\n",
      "Step: 36, State: [ 0.60367819 -1.35622345  0.27326214 -0.88875604]\n",
      "Step: 715, Reward: -0.20621009035351076\n",
      "Step: 37, State: [ 0.6210044  -1.43509906  0.17326213 -0.78875604]\n",
      "Step: 716, Reward: -0.20908396341358793\n",
      "Step: 38, State: [ 0.62833061 -1.50397466  0.07326213 -0.68875604]\n",
      "Step: 717, Reward: -0.21089015787230997\n",
      "Step: 39, State: [ 0.62565683 -1.56285027 -0.02673787 -0.58875604]\n",
      "Step: 718, Reward: -0.211769275230329\n",
      "Step: 40, State: [ 0.61298304 -1.61172587 -0.12673787 -0.48875604]\n",
      "Step: 719, Reward: -0.21195360104484956\n",
      "Step: 41, State: [ 0.59030925 -1.65060147 -0.22673787 -0.38875604]\n",
      "Step: 720, Reward: -0.21182391357335084\n",
      "Step: 42, State: [ 0.55763546 -1.67947708 -0.32673787 -0.28875603]\n",
      "Step: 721, Reward: -0.21194275467100193\n",
      "Step: 43, State: [ 0.51496168 -1.69835268 -0.42673787 -0.18875603]\n",
      "Step: 722, Reward: -0.2129078144387182\n",
      "Step: 44, State: [ 0.48228789 -1.70722828 -0.32673787 -0.08875603]\n",
      "Step: 723, Reward: -0.21494389444000098\n",
      "Step: 45, State: [ 0.4396141  -1.70610389 -0.42673787  0.01124397]\n",
      "Step: 724, Reward: -0.20847539182960872\n",
      "Step: 46, State: [ 0.40694032 -1.69497949 -0.32673787  0.11124397]\n",
      "Step: 725, Reward: -0.21166960703793145\n",
      "Step: 47, State: [ 0.36426653 -1.67385509 -0.42673787  0.21124397]\n",
      "Step: 726, Reward: -0.2057144896117178\n",
      "Step: 48, State: [ 0.33159274 -1.64273069 -0.32673787  0.31124397]\n",
      "Step: 727, Reward: -0.20925345010709753\n",
      "Step: 49, State: [ 0.30891895 -1.6016063  -0.22673787  0.41124398]\n",
      "Step: 728, Reward: -0.2042911831324826\n",
      "Step: 50, State: [ 0.29624517 -1.5504819  -0.12673787  0.51124398]\n",
      "Step: 729, Reward: -0.20073518494562478\n",
      "Step: 51, State: [ 0.27357138 -1.4893575  -0.22673787  0.61124398]\n",
      "Step: 730, Reward: -0.19833103276374564\n",
      "Step: 52, State: [ 0.24089759 -1.4182331  -0.32673787  0.71124398]\n",
      "Step: 731, Reward: -0.19816671319421214\n",
      "Step: 53, State: [ 0.2182238  -1.33710871 -0.22673787  0.81124398]\n",
      "Step: 732, Reward: -0.19713201428958185\n",
      "Step: 54, State: [ 0.18555002 -1.24598431 -0.32673787  0.91124398]\n",
      "Step: 733, Reward: -0.1917387805495886\n",
      "Step: 55, State: [ 0.16287623 -1.14485991 -0.22673787  1.01124398]\n",
      "Step: 734, Reward: -0.18851714368285494\n",
      "Step: 56, State: [ 0.15020244 -1.03373551 -0.12673787  1.11124399]\n",
      "Step: 735, Reward: -0.18159849677348838\n",
      "Step: 57, State: [ 0.12752866 -0.91261111 -0.22673787  1.21124399]\n",
      "Step: 736, Reward: -0.17452360699748878\n",
      "Step: 58, State: [ 0.11485487 -0.78148671 -0.12673787  1.31124399]\n",
      "Step: 737, Reward: -0.1679041474272821\n",
      "Step: 59, State: [ 0.09218108 -0.64036231 -0.22673787  1.41124399]\n",
      "Step: 738, Reward: -0.1589980395324569\n",
      "Step: 60, State: [ 0.07950729 -0.50923791 -0.12673787  1.31124399]\n",
      "Step: 739, Reward: -0.15030556411782092\n",
      "Step: 61, State: [ 0.05683351 -0.38811352 -0.22673787  1.21124399]\n",
      "Step: 740, Reward: -0.1315505960138461\n",
      "Step: 62, State: [ 0.04156412 -0.27698912 -0.15269383  1.11124399]\n",
      "Step: 741, Reward: -0.11328230673141869\n",
      "Step: 63, State: [ 0.03629474 -0.17586472 -0.05269383  1.01124398]\n",
      "Step: 742, Reward: -0.0982354406050893\n",
      "Step: 64, State: [ 0.02102536 -0.08474032 -0.15269383  0.91124398]\n",
      "Step: 743, Reward: -0.0827300220298877\n",
      "Step: 65, State: [ 0.01575598 -0.00361592 -0.05269383  0.81124398]\n",
      "Step: 744, Reward: 9.930929462786928\n",
      "Step: 1, State: [ 4.8316478  -2.60472757 -0.12295114 -0.26605374]\n",
      "Step: 745, Reward: -0.5812110874268536\n",
      "Step: 2, State: [ 4.80935268 -2.62133294 -0.22295114 -0.16605373]\n",
      "Step: 746, Reward: -0.577699400060941\n",
      "Step: 3, State: [ 4.77705757 -2.62793832 -0.32295114 -0.06605373]\n",
      "Step: 747, Reward: -0.5757759266003453\n",
      "Step: 4, State: [ 4.73476246 -2.62454369 -0.42295114  0.03394627]\n",
      "Step: 748, Reward: -0.575842645000152\n",
      "Step: 5, State: [ 4.68246734 -2.61114906 -0.52295114  0.13394627]\n",
      "Step: 749, Reward: -0.5767097549215162\n",
      "Step: 6, State: [ 4.62017223 -2.58775443 -0.62295115  0.23394627]\n",
      "Step: 750, Reward: -0.5772643571798562\n",
      "Step: 7, State: [ 4.54787711 -2.55435981 -0.72295115  0.33394627]\n",
      "Step: 751, Reward: -0.5769650680840145\n",
      "Step: 8, State: [ 4.465582   -2.51096518 -0.82295115  0.43394628]\n",
      "Step: 752, Reward: -0.5755721076287962\n",
      "Step: 9, State: [ 4.37328688 -2.45757055 -0.92295115  0.53394628]\n",
      "Step: 753, Reward: -0.5729719184219588\n",
      "Step: 10, State: [ 4.27099177 -2.39417592 -1.02295115  0.63394628]\n",
      "Step: 754, Reward: -0.5691059584772621\n",
      "Step: 11, State: [ 4.15869665 -2.3207813  -1.12295115  0.73394628]\n",
      "Step: 755, Reward: -0.5639420443429302\n",
      "Step: 12, State: [ 4.03640153 -2.23738667 -1.22295116  0.83394628]\n",
      "Step: 756, Reward: -0.5574619814096949\n",
      "Step: 13, State: [ 3.90410642 -2.14399204 -1.32295116  0.93394628]\n",
      "Step: 757, Reward: -0.5496558431470119\n",
      "Step: 14, State: [ 3.7618113  -2.04059741 -1.42295116  1.03394628]\n",
      "Step: 758, Reward: -0.5405192245770822\n",
      "Step: 15, State: [ 3.60951619 -1.92720278 -1.52295116  1.13394629]\n",
      "Step: 759, Reward: -0.5300519783029245\n",
      "Step: 16, State: [ 3.44722107 -1.80380815 -1.62295116  1.23394629]\n",
      "Step: 760, Reward: -0.5182578074116369\n",
      "Step: 17, State: [ 3.27492596 -1.69041353 -1.72295116  1.13394629]\n",
      "Step: 761, Reward: -0.5051444768717634\n",
      "Step: 18, State: [ 3.09263084 -1.5670189  -1.82295116  1.23394629]\n",
      "Step: 762, Reward: -0.48581936317839514\n",
      "Step: 19, State: [ 2.90033572 -1.45362427 -1.92295117  1.13394629]\n",
      "Step: 763, Reward: -0.4709052061194922\n",
      "Step: 20, State: [ 2.69804061 -1.35022964 -2.02295117  1.03394628]\n",
      "Step: 764, Reward: -0.45018386433822316\n",
      "Step: 21, State: [ 2.48574549 -1.25683501 -2.12295117  0.93394628]\n",
      "Step: 765, Reward: -0.4294396614041105\n",
      "Step: 22, State: [ 2.26345037 -1.15344038 -2.22295117  1.03394628]\n",
      "Step: 766, Reward: -0.408649408520841\n",
      "Step: 23, State: [ 2.03115525 -1.06004576 -2.32295117  0.93394628]\n",
      "Step: 767, Reward: -0.39076432309349407\n",
      "Step: 24, State: [ 1.80886014 -0.95665113 -2.22295117  1.03394628]\n",
      "Step: 768, Reward: -0.3684388405526157\n",
      "Step: 25, State: [ 1.57656502 -0.8632565  -2.32295117  0.93394628]\n",
      "Step: 769, Reward: -0.3413497433132151\n",
      "Step: 26, State: [ 1.3542699  -0.75986187 -2.22295117  1.03394628]\n",
      "Step: 770, Reward: -0.31906898050379845\n",
      "Step: 27, State: [ 1.14197479 -0.66646724 -2.12295117  0.93394628]\n",
      "Step: 771, Reward: -0.2920123440449999\n",
      "Step: 28, State: [ 0.93967967 -0.56307261 -2.02295117  1.03394628]\n",
      "Step: 772, Reward: -0.2623301316980481\n",
      "Step: 29, State: [ 0.74738455 -0.4681382  -1.92295117  0.94934411]\n",
      "Step: 773, Reward: -0.2362387192611188\n",
      "Step: 30, State: [ 0.54508944 -0.36320379 -2.02295117  1.04934412]\n",
      "Step: 774, Reward: -0.20955787921682167\n",
      "Step: 31, State: [ 0.35279432 -0.24826938 -1.92295117  1.14934412]\n",
      "Step: 775, Reward: -0.19358900134092877\n",
      "Step: 32, State: [ 0.1704992  -0.14333497 -1.82295116  1.04934412]\n",
      "Step: 776, Reward: -0.16929426568391764\n",
      "Step: 33, State: [-0.00179591 -0.04840056 -1.72295116  0.94934411]\n",
      "Step: 777, Reward: -0.14158632726502934\n",
      "Step: 34, State: [-0.16409103  0.03653386 -1.62295116  0.84934411]\n",
      "Step: 778, Reward: 9.882655252028108\n",
      "Step: 1, State: [ 1.55301671  4.26543431 -0.3946197  -0.83506993]\n",
      "Step: 779, Reward: -0.5168715216375229\n",
      "Step: 2, State: [ 1.50355474  4.17192732 -0.49461971 -0.93506993]\n",
      "Step: 780, Reward: -0.514258952299894\n",
      "Step: 3, State: [ 1.44409277  4.06842033 -0.59461971 -1.03506993]\n",
      "Step: 781, Reward: -0.5104933818765738\n",
      "Step: 4, State: [ 1.3746308   3.95491333 -0.69461971 -1.13506993]\n",
      "Step: 782, Reward: -0.5055387159693155\n",
      "Step: 5, State: [ 1.30096221  3.83140634 -0.7366859  -1.23506994]\n",
      "Step: 783, Reward: -0.496085739828062\n",
      "Step: 6, State: [ 1.21729362  3.69789935 -0.8366859  -1.33506994]\n",
      "Step: 784, Reward: -0.49067212445062963\n",
      "Step: 7, State: [ 1.12362503  3.55439235 -0.93668591 -1.43506994]\n",
      "Step: 785, Reward: -0.4822316369897778\n",
      "Step: 8, State: [ 1.01995644  3.40088536 -1.03668591 -1.53506994]\n",
      "Step: 786, Reward: -0.47260428190232645\n",
      "Step: 9, State: [ 0.92628784  3.23737836 -0.93668591 -1.63506994]\n",
      "Step: 787, Reward: -0.461813025955159\n",
      "Step: 10, State: [ 0.84261925  3.06387137 -0.8366859  -1.73506994]\n",
      "Step: 788, Reward: -0.4450892124762279\n",
      "Step: 11, State: [ 0.76895066  2.88036438 -0.7366859  -1.83506995]\n",
      "Step: 789, Reward: -0.428218294777653\n",
      "Step: 12, State: [ 0.70528207  2.68685738 -0.6366859  -1.93506995]\n",
      "Step: 790, Reward: -0.4111369775162762\n",
      "Step: 13, State: [ 0.65161348  2.48335039 -0.5366859  -2.03506995]\n",
      "Step: 791, Reward: -0.3937863637718262\n",
      "Step: 14, State: [ 0.58794489  2.26984339 -0.6366859  -2.13506995]\n",
      "Step: 792, Reward: -0.37611619932039486\n",
      "Step: 15, State: [ 0.5342763   2.0463364  -0.5366859  -2.23506995]\n",
      "Step: 793, Reward: -0.36001644390540444\n",
      "Step: 16, State: [ 0.49060771  1.8128294  -0.4366859  -2.33506995]\n",
      "Step: 794, Reward: -0.3405655691963557\n",
      "Step: 17, State: [ 0.43693912  1.58932241 -0.5366859  -2.23506995]\n",
      "Step: 795, Reward: -0.32072404709402424\n",
      "Step: 18, State: [ 0.37327053  1.35581541 -0.6366859  -2.33506995]\n",
      "Step: 796, Reward: -0.2939012647318049\n",
      "Step: 19, State: [ 0.31960194  1.13230841 -0.5366859  -2.23506995]\n",
      "Step: 797, Reward: -0.2757838123078937\n",
      "Step: 20, State: [ 0.27593335  0.91880142 -0.4366859  -2.13506995]\n",
      "Step: 798, Reward: -0.24672712522588736\n",
      "Step: 21, State: [ 0.22226476  0.71529442 -0.5366859  -2.03506995]\n",
      "Step: 799, Reward: -0.21903974723999142\n",
      "Step: 22, State: [ 0.15859617  0.52178743 -0.6366859  -1.93506995]\n",
      "Step: 800, Reward: -0.19427763461741973\n",
      "Step: 23, State: [ 0.08492758  0.33828044 -0.7366859  -1.83506995]\n",
      "Step: 801, Reward: -0.17053397416344473\n",
      "Step: 24, State: [ 0.02125899  0.16477344 -0.6366859  -1.73506994]\n",
      "Step: 802, Reward: -0.1478909461499826\n",
      "Step: 25, State: [-3.24095966e-02  1.26644718e-03 -5.36685900e-01 -1.63506994e+00]\n",
      "Step: 803, Reward: -0.12316596560074693\n",
      "Step: 26, State: [-0.07607819 -0.15224055 -0.4366859  -1.53506994]\n",
      "Step: 804, Reward: 9.896569596224658\n",
      "Step: 1, State: [ 0.10938699 -3.0215904   0.39493471 -0.1527828 ]\n",
      "Step: 805, Reward: -0.3426421491530515\n",
      "Step: 2, State: [ 0.13888046 -3.02686868  0.29493471 -0.0527828 ]\n",
      "Step: 806, Reward: -0.33767197139261734\n",
      "Step: 3, State: [ 0.15837394 -3.02214696  0.19493471  0.0472172 ]\n",
      "Step: 807, Reward: -0.33212847560804243\n",
      "Step: 4, State: [ 0.16786741 -3.00742524  0.09493471  0.1472172 ]\n",
      "Step: 808, Reward: -0.32680010642340823\n",
      "Step: 5, State: [ 0.16736088 -2.98270352 -0.00506529  0.2472172 ]\n",
      "Step: 809, Reward: -0.3241114321469915\n",
      "Step: 6, State: [ 0.15685435 -2.9479818  -0.1050653   0.3472172 ]\n",
      "Step: 810, Reward: -0.32524510755517694\n",
      "Step: 7, State: [ 0.15634782 -2.90326008 -0.00506529  0.4472172 ]\n",
      "Step: 811, Reward: -0.3274955646426033\n",
      "Step: 8, State: [ 0.14584129 -2.84853836 -0.1050653   0.54721721]\n",
      "Step: 812, Reward: -0.3272511189557825\n",
      "Step: 9, State: [ 0.14533476 -2.78381664 -0.00506529  0.64721721]\n",
      "Step: 813, Reward: -0.3272296784115279\n",
      "Step: 10, State: [ 0.13482823 -2.70909492 -0.1050653   0.74721721]\n",
      "Step: 814, Reward: -0.325264767057373\n",
      "Step: 11, State: [ 0.1343217  -2.62437319 -0.00506529  0.84721721]\n",
      "Step: 815, Reward: -0.32311531137770416\n",
      "Step: 12, State: [ 0.12381517 -2.52965147 -0.1050653   0.94721721]\n",
      "Step: 816, Reward: -0.3192845929769206\n",
      "Step: 13, State: [ 0.12330864 -2.42492975 -0.00506529  1.04721721]\n",
      "Step: 817, Reward: -0.3150614274562713\n",
      "Step: 14, State: [ 0.13280211 -2.31020803  0.09493471  1.14721722]\n",
      "Step: 818, Reward: -0.3093098960596461\n",
      "Step: 15, State: [ 0.13229558 -2.18548631 -0.00506529  1.24721722]\n",
      "Step: 819, Reward: -0.3031012565194888\n",
      "Step: 16, State: [ 0.14178905 -2.05076459  0.09493471  1.34721722]\n",
      "Step: 820, Reward: -0.2954521923436778\n",
      "Step: 17, State: [ 0.14128252 -1.90604287 -0.00506529  1.44721722]\n",
      "Step: 821, Reward: -0.2872360701922898\n",
      "Step: 18, State: [ 0.13077599 -1.75132114 -0.1050653   1.54721722]\n",
      "Step: 822, Reward: -0.2776306264303892\n",
      "Step: 19, State: [ 0.11026946 -1.58659942 -0.2050653   1.64721722]\n",
      "Step: 823, Reward: -0.26730086113372\n",
      "Step: 20, State: [ 0.07976293 -1.4118777  -0.3050653   1.74721722]\n",
      "Step: 824, Reward: -0.2561814368041402\n",
      "Step: 21, State: [ 0.0592564  -1.22715598 -0.2050653   1.84721723]\n",
      "Step: 825, Reward: -0.24423751243535136\n",
      "Step: 22, State: [ 0.04874987 -1.05243425 -0.1050653   1.74721722]\n",
      "Step: 826, Reward: -0.22992895897495016\n",
      "Step: 23, State: [ 0.02824334 -0.88771253 -0.2050653   1.64721722]\n",
      "Step: 827, Reward: -0.20701707330910948\n",
      "Step: 24, State: [ 0.01773681 -0.73299081 -0.1050653   1.54721722]\n",
      "Step: 828, Reward: -0.18595493822989095\n",
      "Step: 25, State: [ 0.01723029 -0.58826909 -0.00506529  1.44721722]\n",
      "Step: 829, Reward: -0.16500169273731558\n",
      "Step: 26, State: [ 0.00672376 -0.45354736 -0.1050653   1.34721722]\n",
      "Step: 830, Reward: -0.14535557644601033\n",
      "Step: 27, State: [ 0.00621723 -0.32882564 -0.00506529  1.24721722]\n",
      "Step: 831, Reward: -0.1270672488506206\n",
      "Step: 28, State: [ 0.0157107  -0.21410392  0.09493471  1.14721722]\n",
      "Step: 832, Reward: -0.10939195188569624\n",
      "Step: 29, State: [ 0.01520417 -0.1093822  -0.00506529  1.04721721]\n",
      "Step: 833, Reward: -0.09316701879983669\n",
      "Step: 30, State: [ 0.02469764 -0.01466048  0.09493471  0.94721721]\n",
      "Step: 834, Reward: -0.07754699233434727\n",
      "Step: 31, State: [0.04419111 0.07006124 0.19493471 0.84721721]\n",
      "Step: 835, Reward: 9.935387615500039\n",
      "Step: 1, State: [-2.87039616 -4.15655754  1.01392489 -0.23139672]\n",
      "Step: 836, Reward: -0.5718340004773004\n",
      "Step: 2, State: [-2.75900367 -4.16969722  1.11392489 -0.13139672]\n",
      "Step: 837, Reward: -0.5712769284184475\n",
      "Step: 3, State: [-2.63761118 -4.17283689  1.21392489 -0.03139672]\n",
      "Step: 838, Reward: -0.570209286076345\n",
      "Step: 4, State: [-2.50621869 -4.16597656  1.31392489  0.06860328]\n",
      "Step: 839, Reward: -0.5685140276042158\n",
      "Step: 5, State: [-2.3648262  -4.14911623  1.4139249   0.16860328]\n",
      "Step: 840, Reward: -0.5661016315320391\n",
      "Step: 6, State: [-2.21343372 -4.1222559   1.5139249   0.26860328]\n",
      "Step: 841, Reward: -0.5629119340801897\n",
      "Step: 7, State: [-2.06559696 -4.08539558  1.47836753  0.36860328]\n",
      "Step: 842, Reward: -0.5553836640532606\n",
      "Step: 8, State: [-1.90776021 -4.03853525  1.57836753  0.46860329]\n",
      "Step: 843, Reward: -0.5481132556162924\n",
      "Step: 9, State: [-1.75992346 -3.98167492  1.47836753  0.56860329]\n",
      "Step: 844, Reward: -0.543111745691331\n",
      "Step: 10, State: [-1.6220867  -3.91481459  1.37836753  0.66860329]\n",
      "Step: 845, Reward: -0.5286675794356406\n",
      "Step: 11, State: [-1.49424995 -3.83795426  1.27836753  0.76860329]\n",
      "Step: 846, Reward: -0.5144968397489158\n",
      "Step: 12, State: [-1.3764132  -3.75109393  1.17836753  0.86860329]\n",
      "Step: 847, Reward: -0.5005815700396368\n",
      "Step: 13, State: [-1.26857644 -3.6542336   1.07836752  0.96860329]\n",
      "Step: 848, Reward: -0.48690245187063497\n",
      "Step: 14, State: [-1.17073969 -3.54737327  0.97836752  1.06860329]\n",
      "Step: 849, Reward: -0.4734340719936352\n",
      "Step: 15, State: [-1.08290294 -3.43051294  0.87836752  1.1686033 ]\n",
      "Step: 850, Reward: -0.4601408387281892\n",
      "Step: 16, State: [-1.00506619 -3.30365261  0.77836752  1.2686033 ]\n",
      "Step: 851, Reward: -0.4469747071048573\n",
      "Step: 17, State: [-0.93722944 -3.16679228  0.67836752  1.3686033 ]\n",
      "Step: 852, Reward: -0.43387553671529133\n",
      "Step: 18, State: [-0.85939268 -3.01993195  0.77836752  1.4686033 ]\n",
      "Step: 853, Reward: -0.4207742127307137\n",
      "Step: 19, State: [-0.77155593 -2.86307162  0.87836752  1.5686033 ]\n",
      "Step: 854, Reward: -0.41123146392472726\n",
      "Step: 20, State: [-0.69120688 -2.69621129  0.80349054  1.6686033 ]\n",
      "Step: 855, Reward: -0.3989032031992365\n",
      "Step: 21, State: [-0.62085782 -2.51935096  0.70349054  1.76860331]\n",
      "Step: 856, Reward: -0.3850813117362463\n",
      "Step: 22, State: [-0.56050877 -2.33249063  0.60349054  1.86860331]\n",
      "Step: 857, Reward: -0.3687835713920336\n",
      "Step: 23, State: [-0.51015972 -2.1356303   0.50349054  1.96860331]\n",
      "Step: 858, Reward: -0.3522132942881283\n",
      "Step: 24, State: [-0.44981066 -1.92876997  0.60349054  2.06860331]\n",
      "Step: 859, Reward: -0.3353124804708627\n",
      "Step: 25, State: [-0.39946161 -1.71190964  0.50349054  2.16860331]\n",
      "Step: 860, Reward: -0.3199365618236566\n",
      "Step: 26, State: [-0.35911255 -1.48504931  0.40349054  2.26860331]\n",
      "Step: 861, Reward: -0.30124613064862715\n",
      "Step: 27, State: [-0.3087635  -1.26818898  0.50349054  2.16860331]\n",
      "Step: 862, Reward: -0.28213768912770976\n",
      "Step: 28, State: [-0.24841445 -1.06132865  0.60349054  2.06860331]\n",
      "Step: 863, Reward: -0.25597985585773064\n",
      "Step: 29, State: [-0.19806539 -0.86446831  0.50349054  1.96860331]\n",
      "Step: 864, Reward: -0.23088525702445967\n",
      "Step: 30, State: [-0.15771634 -0.67760798  0.40349054  1.86860331]\n",
      "Step: 865, Reward: -0.2044274599518164\n",
      "Step: 31, State: [-0.10736729 -0.50074765  0.50349054  1.76860331]\n",
      "Step: 866, Reward: -0.17929769576474672\n",
      "Step: 32, State: [-0.06701823 -0.33388732  0.40349054  1.6686033 ]\n",
      "Step: 867, Reward: -0.1572987570179221\n",
      "Step: 33, State: [-0.03666918 -0.17702699  0.30349054  1.5686033 ]\n",
      "Step: 868, Reward: -0.13403157309447675\n",
      "Step: 34, State: [ 0.00367988 -0.03016666  0.40349054  1.4686033 ]\n",
      "Step: 869, Reward: -0.11210527517121928\n",
      "Step: 35, State: [0.05402893 0.10669367 0.50349054 1.3686033 ]\n",
      "Step: 870, Reward: 9.906667666914824\n",
      "Step: 1, State: [ 3.14971169e+00  3.47577915e+00 -4.09047830e-02 -1.41991205e-03]\n",
      "Step: 871, Reward: -0.48923417885699844\n",
      "Step: 2, State: [ 3.13562121  3.46563715 -0.14090478 -0.10141991]\n",
      "Step: 872, Reward: -0.48524856413295064\n",
      "Step: 3, State: [ 3.11153073  3.44549516 -0.24090479 -0.20141992]\n",
      "Step: 873, Reward: -0.49018499548231326\n",
      "Step: 4, State: [ 3.07744025  3.41535317 -0.34090479 -0.30141992]\n",
      "Step: 874, Reward: -0.4940955971103728\n",
      "Step: 5, State: [ 3.03334978  3.37521118 -0.44090479 -0.40141992]\n",
      "Step: 875, Reward: -0.4966257901205678\n",
      "Step: 6, State: [ 2.9792593   3.32506919 -0.54090479 -0.50141992]\n",
      "Step: 876, Reward: -0.49775350023486115\n",
      "Step: 7, State: [ 2.91516882  3.26492719 -0.64090479 -0.60141992]\n",
      "Step: 877, Reward: -0.4974737915797071\n",
      "Step: 8, State: [ 2.84107834  3.1947852  -0.74090479 -0.70141992]\n",
      "Step: 878, Reward: -0.4957851817857024\n",
      "Step: 9, State: [ 2.75698786  3.11464321 -0.84090479 -0.80141992]\n",
      "Step: 879, Reward: -0.4926873243048939\n",
      "Step: 10, State: [ 2.66289738  3.02450122 -0.9409048  -0.90141993]\n",
      "Step: 880, Reward: -0.48818040234056753\n",
      "Step: 11, State: [ 2.5588069   2.92435922 -1.0409048  -1.00141993]\n",
      "Step: 881, Reward: -0.4822649445227515\n",
      "Step: 12, State: [ 2.44471642  2.81421723 -1.1409048  -1.10141993]\n",
      "Step: 882, Reward: -0.4749417852100466\n",
      "Step: 13, State: [ 2.32062594  2.69407524 -1.2409048  -1.20141993]\n",
      "Step: 883, Reward: -0.46621209575153283\n",
      "Step: 14, State: [ 2.18653546  2.56393325 -1.3409048  -1.30141993]\n",
      "Step: 884, Reward: -0.4560774704934158\n",
      "Step: 15, State: [ 2.04244498  2.42379125 -1.4409048  -1.40141993]\n",
      "Step: 885, Reward: -0.4445400760008951\n",
      "Step: 16, State: [ 1.8883545   2.27364926 -1.54090481 -1.50141993]\n",
      "Step: 886, Reward: -0.43160289219646275\n",
      "Step: 17, State: [ 1.72426402  2.11350727 -1.64090481 -1.60141994]\n",
      "Step: 887, Reward: -0.41727010307851203\n",
      "Step: 18, State: [ 1.55017354  1.94336527 -1.74090481 -1.70141994]\n",
      "Step: 888, Reward: -0.40154774815424393\n",
      "Step: 19, State: [ 1.38608306  1.76322328 -1.64090481 -1.80141994]\n",
      "Step: 889, Reward: -0.3844448561355046\n",
      "Step: 20, State: [ 1.23199258  1.57308128 -1.54090481 -1.90141994]\n",
      "Step: 890, Reward: -0.36025962083845153\n",
      "Step: 21, State: [ 1.06790209  1.37293929 -1.64090481 -2.00141994]\n",
      "Step: 891, Reward: -0.3363219960859106\n",
      "Step: 22, State: [ 0.91381161  1.1827973  -1.54090481 -1.90141994]\n",
      "Step: 892, Reward: -0.31748314083021284\n",
      "Step: 23, State: [ 0.76972113  0.9826553  -1.4409048  -2.00141994]\n",
      "Step: 893, Reward: -0.28598008522246227\n",
      "Step: 24, State: [ 0.62970082  0.79251331 -1.40020313 -1.90141994]\n",
      "Step: 894, Reward: -0.2589271689154528\n",
      "Step: 25, State: [ 0.49968051  0.61237131 -1.30020313 -1.80141994]\n",
      "Step: 895, Reward: -0.23343210895673305\n",
      "Step: 26, State: [ 0.3596602   0.44222932 -1.40020313 -1.70141994]\n",
      "Step: 896, Reward: -0.20426031110802614\n",
      "Step: 27, State: [ 0.22963988  0.28208733 -1.30020313 -1.60141994]\n",
      "Step: 897, Reward: -0.18131893028186122\n",
      "Step: 28, State: [ 0.10961957  0.13194533 -1.20020312 -1.50141993]\n",
      "Step: 898, Reward: -0.15365541900139118\n",
      "Step: 29, State: [-4.00742074e-04 -8.19666044e-03 -1.10020312e+00 -1.40141993e+00]\n",
      "Step: 899, Reward: -0.1274048039286538\n",
      "Step: 30, State: [-0.10042105 -0.13833865 -1.00020312 -1.30141993]\n",
      "Step: 900, Reward: 9.895952642570299\n",
      "Step: 1, State: [ 2.23260552 -1.91955674  0.80172546 -0.24760826]\n",
      "Step: 901, Reward: -0.34922398937089294\n",
      "Step: 2, State: [ 2.30277807 -1.93431756  0.70172546 -0.14760826]\n",
      "Step: 902, Reward: -0.350532165921034\n",
      "Step: 3, State: [ 2.36295061 -1.93907839  0.60172546 -0.04760826]\n",
      "Step: 903, Reward: -0.35073485471064614\n",
      "Step: 4, State: [ 2.41312316 -1.93383921  0.50172545  0.05239175]\n",
      "Step: 904, Reward: -0.3499948131083289\n",
      "Step: 5, State: [ 2.4532957  -1.91860004  0.40172545  0.15239175]\n",
      "Step: 905, Reward: -0.3486041586540317\n",
      "Step: 6, State: [ 2.48346825 -1.89336086  0.30172545  0.25239175]\n",
      "Step: 906, Reward: -0.34706825715025574\n",
      "Step: 7, State: [ 2.50364079 -1.85812169  0.20172545  0.35239175]\n",
      "Step: 907, Reward: -0.346099435098933\n",
      "Step: 8, State: [ 2.51381334 -1.81288251  0.10172545  0.45239175]\n",
      "Step: 908, Reward: -0.3462269310704224\n",
      "Step: 9, State: [ 2.51398588e+00 -1.75764334e+00  1.72544652e-03  5.52391753e-01]\n",
      "Step: 909, Reward: -0.34725878349180894\n",
      "Step: 10, State: [ 2.50415843 -1.69240416 -0.09827455  0.65239175]\n",
      "Step: 910, Reward: -0.3485098833398788\n",
      "Step: 11, State: [ 2.48433097 -1.61716499 -0.19827456  0.75239176]\n",
      "Step: 911, Reward: -0.3493720505099978\n",
      "Step: 12, State: [ 2.45450351 -1.53192581 -0.29827456  0.85239176]\n",
      "Step: 912, Reward: -0.34947687814410516\n",
      "Step: 13, State: [ 2.41467606 -1.43668664 -0.39827456  0.95239176]\n",
      "Step: 913, Reward: -0.3486291902401802\n",
      "Step: 14, State: [ 2.3648486  -1.33144746 -0.49827456  1.05239176]\n",
      "Step: 914, Reward: -0.3467334504966095\n",
      "Step: 15, State: [ 2.30502115 -1.21620828 -0.59827456  1.15239176]\n",
      "Step: 915, Reward: -0.34375182397879706\n",
      "Step: 16, State: [ 2.23519369 -1.11096911 -0.69827456  1.05239176]\n",
      "Step: 916, Reward: -0.3396841238715448\n",
      "Step: 17, State: [ 2.15536623 -1.01572993 -0.79827457  0.95239176]\n",
      "Step: 917, Reward: -0.3268976362052367\n",
      "Step: 18, State: [ 2.06553878 -0.93049076 -0.89827457  0.85239176]\n",
      "Step: 918, Reward: -0.31454799807521955\n",
      "Step: 19, State: [ 1.96571132 -0.85525158 -0.99827457  0.75239176]\n",
      "Step: 919, Reward: -0.3026037863736417\n",
      "Step: 20, State: [ 1.85588386 -0.79001241 -1.09827457  0.65239175]\n",
      "Step: 920, Reward: -0.29101566437494697\n",
      "Step: 21, State: [ 1.73605641 -0.73477323 -1.19827457  0.55239175]\n",
      "Step: 921, Reward: -0.2797168894633466\n",
      "Step: 22, State: [ 1.60622895 -0.66953405 -1.29827457  0.65239175]\n",
      "Step: 922, Reward: -0.26863040320177173\n",
      "Step: 23, State: [ 1.46640149 -0.61429488 -1.39827457  0.55239175]\n",
      "Step: 923, Reward: -0.26080940738772657\n",
      "Step: 24, State: [ 1.31657403 -0.5490557  -1.49827458  0.65239175]\n",
      "Step: 924, Reward: -0.24830090082761028\n",
      "Step: 25, State: [ 1.15674658 -0.47381653 -1.59827458  0.75239176]\n",
      "Step: 925, Reward: -0.23849701109220925\n",
      "Step: 26, State: [ 0.98691912 -0.40857735 -1.69827458  0.65239175]\n",
      "Step: 926, Reward: -0.22747047128531384\n",
      "Step: 27, State: [ 0.82709166 -0.33333818 -1.59827458  0.75239176]\n",
      "Step: 927, Reward: -0.21192076582752745\n",
      "Step: 28, State: [ 0.6572642  -0.268099   -1.69827458  0.65239175]\n",
      "Step: 928, Reward: -0.1916415859384204\n",
      "Step: 29, State: [ 0.47743674 -0.19285983 -1.79827458  0.75239176]\n",
      "Step: 929, Reward: -0.17608978209034018\n",
      "Step: 30, State: [ 0.30760929 -0.12762065 -1.69827458  0.65239175]\n",
      "Step: 930, Reward: -0.16310042210078204\n",
      "Step: 31, State: [ 0.14778183 -0.07238148 -1.59827458  0.55239175]\n",
      "Step: 931, Reward: -0.13840897683263242\n",
      "Step: 32, State: [-0.00204563 -0.0271423  -1.49827458  0.45239175]\n",
      "Step: 932, Reward: -0.11514972522362184\n",
      "Step: 33, State: [-0.14187309  0.00809687 -1.39827457  0.35239175]\n",
      "Step: 933, Reward: 9.904881783578162\n",
      "Step: 1, State: [ 3.42633072 -4.6623482  -0.87351765  0.57380383]\n",
      "Step: 934, Reward: -0.6478997824492424\n",
      "Step: 2, State: [ 3.32897896 -4.59496781 -0.97351765  0.67380383]\n",
      "Step: 935, Reward: -0.6449934635533611\n",
      "Step: 3, State: [ 3.22162719 -4.51758743 -1.07351766  0.77380383]\n",
      "Step: 936, Reward: -0.6407535545425733\n",
      "Step: 4, State: [ 3.10427543 -4.43020705 -1.17351766  0.87380383]\n",
      "Step: 937, Reward: -0.635173478621087\n",
      "Step: 5, State: [ 2.97692366 -4.33282666 -1.27351766  0.97380383]\n",
      "Step: 938, Reward: -0.6282526654300835\n",
      "Step: 6, State: [ 2.8395719  -4.22544628 -1.37351766  1.07380383]\n",
      "Step: 939, Reward: -0.6199948451241003\n",
      "Step: 7, State: [ 2.69222013 -4.1080659  -1.47351766  1.17380384]\n",
      "Step: 940, Reward: -0.6104074228791758\n",
      "Step: 8, State: [ 2.53486836 -3.98068551 -1.57351766  1.27380384]\n",
      "Step: 941, Reward: -0.5995014898258229\n",
      "Step: 9, State: [ 2.3675166  -3.84330513 -1.67351766  1.37380384]\n",
      "Step: 942, Reward: -0.5872923161663859\n",
      "Step: 10, State: [ 2.19016483 -3.69592475 -1.77351767  1.47380384]\n",
      "Step: 943, Reward: -0.5738003249379291\n",
      "Step: 11, State: [ 2.02281306 -3.53854436 -1.67351766  1.57380384]\n",
      "Step: 944, Reward: -0.559052659660725\n",
      "Step: 12, State: [ 1.8454613  -3.37116398 -1.77351767  1.67380384]\n",
      "Step: 945, Reward: -0.5365977279932957\n",
      "Step: 13, State: [ 1.67810953 -3.19378359 -1.67351766  1.77380384]\n",
      "Step: 946, Reward: -0.5203980751914009\n",
      "Step: 14, State: [ 1.52075777 -3.00640321 -1.57351766  1.87380385]\n",
      "Step: 947, Reward: -0.49685608833815154\n",
      "Step: 15, State: [ 1.373406   -2.80902282 -1.47351766  1.97380385]\n",
      "Step: 948, Reward: -0.4733997700618139\n",
      "Step: 16, State: [ 1.23605423 -2.60164244 -1.37351766  2.07380385]\n",
      "Step: 949, Reward: -0.44997972324628766\n",
      "Step: 17, State: [ 1.10870247 -2.38426205 -1.27351766  2.17380385]\n",
      "Step: 950, Reward: -0.426546941442806\n",
      "Step: 18, State: [ 0.9913507  -2.15688167 -1.17351766  2.27380385]\n",
      "Step: 951, Reward: -0.4030545514099257\n",
      "Step: 19, State: [ 0.88399894 -1.91950128 -1.07351766  2.37380385]\n",
      "Step: 952, Reward: -0.37946062103248335\n",
      "Step: 20, State: [ 0.78664717 -1.6921209  -0.97351765  2.27380385]\n",
      "Step: 953, Reward: -0.3557328765070783\n",
      "Step: 21, State: [ 0.69929541 -1.45474051 -0.87351765  2.37380385]\n",
      "Step: 954, Reward: -0.324417796142491\n",
      "Step: 22, State: [ 0.60194364 -1.22736013 -0.97351765  2.27380385]\n",
      "Step: 955, Reward: -0.30202217931863384\n",
      "Step: 23, State: [ 0.49459187 -1.00997974 -1.07351766  2.17380385]\n",
      "Step: 956, Reward: -0.2745164841633924\n",
      "Step: 24, State: [ 0.39724011 -0.78259936 -0.97351765  2.27380385]\n",
      "Step: 957, Reward: -0.24782166253678672\n",
      "Step: 25, State: [ 0.28988834 -0.56521897 -1.07351766  2.17380385]\n",
      "Step: 958, Reward: -0.2255788291443196\n",
      "Step: 26, State: [ 0.17253658 -0.35783859 -1.17351766  2.07380385]\n",
      "Step: 959, Reward: -0.1988859203432079\n",
      "Step: 27, State: [ 0.04518481 -0.1604582  -1.27351766  1.97380385]\n",
      "Step: 960, Reward: -0.17300910137136333\n",
      "Step: 28, State: [-0.07216695  0.02692218 -1.17351766  1.87380385]\n",
      "Step: 961, Reward: -0.1482614641455012\n",
      "Step: 29, State: [-0.17951872  0.20430257 -1.07351766  1.77380384]\n",
      "Step: 962, Reward: 9.867608023828145\n",
      "Step: 1, State: [3.7535998  1.34435667 0.40985708 0.10228414]\n",
      "Step: 963, Reward: -0.4360728597945177\n",
      "Step: 2, State: [3.78458551e+00 1.34458508e+00 3.09857081e-01 2.28413623e-03]\n",
      "Step: 964, Reward: -0.43397149577724475\n",
      "Step: 3, State: [ 3.80557122  1.3348135   0.20985708 -0.09771587]\n",
      "Step: 965, Reward: -0.43126952903787896\n",
      "Step: 4, State: [ 3.81655693  1.31504191  0.10985708 -0.19771587]\n",
      "Step: 966, Reward: -0.42900444849451824\n",
      "Step: 5, State: [ 3.81754263  1.28527032  0.00985708 -0.29771587]\n",
      "Step: 967, Reward: -0.4291275717086415\n",
      "Step: 6, State: [ 3.80852834  1.24549874 -0.09014293 -0.39771587]\n",
      "Step: 968, Reward: -0.43184561321438564\n",
      "Step: 7, State: [ 3.78951405  1.19572715 -0.19014293 -0.49771587]\n",
      "Step: 969, Reward: -0.43523363374591756\n",
      "Step: 8, State: [ 3.76049976  1.13595556 -0.29014293 -0.59771587]\n",
      "Step: 970, Reward: -0.4381507120670573\n",
      "Step: 9, State: [ 3.72148546  1.06618398 -0.39014293 -0.69771587]\n",
      "Step: 971, Reward: -0.4401955867439464\n",
      "Step: 10, State: [ 3.67247117  0.98641239 -0.49014293 -0.79771588]\n",
      "Step: 972, Reward: -0.4412316319816863\n",
      "Step: 11, State: [ 3.61345688  0.8966408  -0.59014293 -0.89771588]\n",
      "Step: 973, Reward: -0.44121912232532534\n",
      "Step: 12, State: [ 3.54444258  0.81686921 -0.69014293 -0.79771588]\n",
      "Step: 974, Reward: -0.4401622262746836\n",
      "Step: 13, State: [ 3.46542829  0.74709763 -0.79014294 -0.69771587]\n",
      "Step: 975, Reward: -0.43061865891331963\n",
      "Step: 14, State: [ 3.376414    0.66732604 -0.89014294 -0.79771588]\n",
      "Step: 976, Reward: -0.4213518461920151\n",
      "Step: 15, State: [ 3.2773997   0.59755445 -0.99014294 -0.69771587]\n",
      "Step: 977, Reward: -0.4180792173970339\n",
      "Step: 16, State: [ 3.16838541  0.53778286 -1.09014294 -0.59771587]\n",
      "Step: 978, Reward: -0.40784886872193793\n",
      "Step: 17, State: [ 3.04937111  0.48801128 -1.19014294 -0.49771587]\n",
      "Step: 979, Reward: -0.39767487960281767\n",
      "Step: 18, State: [ 2.92035682  0.44823969 -1.29014294 -0.39771587]\n",
      "Step: 980, Reward: -0.38746073222229627\n",
      "Step: 19, State: [ 2.78134252  0.4184681  -1.39014294 -0.29771587]\n",
      "Step: 981, Reward: -0.3771004797334075\n",
      "Step: 20, State: [ 2.63232823  0.39869652 -1.49014295 -0.19771587]\n",
      "Step: 982, Reward: -0.3664900748401526\n",
      "Step: 21, State: [ 2.47331393  0.38892493 -1.59014295 -0.09771587]\n",
      "Step: 983, Reward: -0.3555373191113844\n",
      "Step: 22, State: [ 2.30429964  0.36915334 -1.69014295 -0.19771587]\n",
      "Step: 984, Reward: -0.344169873442267\n",
      "Step: 23, State: [ 2.12528535  0.33938176 -1.79014295 -0.29771587]\n",
      "Step: 985, Reward: -0.33259373263637126\n",
      "Step: 24, State: [ 1.93627105  0.29961017 -1.89014295 -0.39771587]\n",
      "Step: 986, Reward: -0.32009988646480386\n",
      "Step: 25, State: [ 1.73725675  0.26983858 -1.99014295 -0.29771587]\n",
      "Step: 987, Reward: -0.30665017903603364\n",
      "Step: 26, State: [ 1.52824246  0.23006699 -2.09014295 -0.39771587]\n",
      "Step: 988, Reward: -0.29056535782625886\n",
      "Step: 27, State: [ 1.30922816  0.20029541 -2.19014296 -0.29771587]\n",
      "Step: 989, Reward: -0.27507071010957224\n",
      "Step: 28, State: [ 1.08021387  0.18052382 -2.29014296 -0.19771587]\n",
      "Step: 990, Reward: -0.257102486556669\n",
      "Step: 29, State: [ 0.86119957  0.15075223 -2.19014296 -0.29771587]\n",
      "Step: 991, Reward: -0.23859467168383391\n",
      "Step: 30, State: [ 0.65218528  0.13098065 -2.09014295 -0.19771587]\n",
      "Step: 992, Reward: -0.21208585190500542\n",
      "Step: 31, State: [ 0.45317098  0.10120906 -1.99014295 -0.29771587]\n",
      "Step: 993, Reward: -0.18563660337347554\n",
      "Step: 32, State: [ 0.26415669  0.07429396 -1.89014295 -0.26915103]\n",
      "Step: 994, Reward: -0.15744790837863676\n",
      "Step: 33, State: [ 0.08514239  0.03737885 -1.79014295 -0.36915103]\n",
      "Step: 995, Reward: -0.1370431774424394\n",
      "Step: 34, State: [-0.0838719  -0.00953625 -1.69014295 -0.46915104]\n",
      "Step: 996, Reward: 9.885168829762383\n",
      "Step: 1, State: [-4.87483524 -4.43204409  1.05046807 -0.89477213]\n",
      "Step: 997, Reward: -0.7436698866327355\n",
      "Step: 2, State: [-4.75978843 -4.5115213   1.15046807 -0.79477213]\n",
      "Step: 998, Reward: -0.7419768491422728\n",
      "Step: 3, State: [-4.63474162 -4.58099852  1.25046807 -0.69477213]\n",
      "Step: 999, Reward: -0.7398726767624735\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store data\n",
    "positions = []\n",
    "rewards = []\n",
    "steps = []\n",
    "\n",
    "# Evaluation\n",
    "obs = env.reset()\n",
    "for step in range(1000):\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    \n",
    "    # Store data for plotting\n",
    "    positions.append(obs[:2])  # Store x, y position\n",
    "    rewards.append(reward)     # Store reward\n",
    "    steps.append(step)         # Store step number\n",
    "    \n",
    "    # Render and print (optional)\n",
    "    env.render()\n",
    "    print(f\"Step: {step}, Reward: {reward}\")\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c86c960-bfab-4e1c-bac3-97a94b3f2ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positions = np.array(positions)\n",
    "rewards = np.array(rewards)\n",
    "steps = np.array(steps)\n",
    "\n",
    "# Plot the trajectory\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(positions[:, 0], positions[:, 1], label=\"Trajectory\")\n",
    "plt.scatter([env.target_position[0]], [env.target_position[1]], color=\"red\", label=\"Target\")\n",
    "plt.xlabel(\"X Position\")\n",
    "plt.ylabel(\"Y Position\")\n",
    "plt.title(\"Agent Trajectory During Evaluation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot the rewards over time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, rewards, label=\"Reward\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Rewards Over Time During Evaluation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Calculate distance to target at each step\n",
    "distances = np.linalg.norm(positions - env.target_position, axis=1)\n",
    "\n",
    "# Plot distance to target over time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(steps, distances, label=\"Distance to Target\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.title(\"Distance to Target Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc9ca4-c0ea-4d43-bea6-b7b140c727a8",
   "metadata": {},
   "source": [
    "1. General Observations\n",
    "Negative Rewards:\n",
    "\n",
    "Most rewards are negative, which is expected in a docking scenario where the agent is penalized for distance, velocity, and fuel usage.\n",
    "\n",
    "The rewards are relatively small in magnitude (e.g., -0.59, -0.39), suggesting the agent is not failing catastrophically but also not making significant progress.\n",
    "\n",
    "State Transitions:\n",
    "\n",
    "The agent's position (x, y) and velocity (vx, vy) change gradually, indicating the agent is exploring the environment.\n",
    "\n",
    "The velocity components (vx, vy) fluctuate, suggesting the agent is attempting to control its movement but not yet effectively.\n",
    "\n",
    "Occasional Positive Rewards:\n",
    "\n",
    "There are a few instances of large positive rewards (e.g., 9.90), which likely correspond to successful docking or significant progress toward the target.\n",
    "\n",
    "2. Key Insights\n",
    "A. Agent is Exploring but Not Learning Effectively\n",
    "The agent is exploring the state space, as seen by the gradual changes in position and velocity.\n",
    "\n",
    "However, the rewards are not improving significantly over time, indicating the agent is not learning effective policies.\n",
    "\n",
    "B. Reward Function is Providing Feedback\n",
    "The reward function is penalizing the agent for distance, velocity, and fuel usage, as intended.\n",
    "\n",
    "The occasional large positive rewards suggest the reward function is correctly identifying successful behaviors.\n",
    "\n",
    "C. Agent Struggles with Fine-Grained Control\n",
    "The agent's velocity components (vx, vy) fluctuate significantly, indicating it is struggling to control its movement precisely.\n",
    "\n",
    "This is common in early training when the agent has not yet learned to balance thrust and orientation.\n",
    "\n",
    "D. Episodes are Terminating Prematurely\n",
    "The agent often reaches the maximum episode length without docking successfully.\n",
    "\n",
    "This suggests the task might be too complex for the current training setup.\n",
    "\n",
    "3. Detailed Analysis of Specific Episodes\n",
    "Episode 1 (Steps 1-39):\n",
    "Initial State: [-2.95, 4.74, -0.45, 0.20]\n",
    "\n",
    "The agent starts far from the target (x, y = -2.95, 4.74) with moderate velocity.\n",
    "\n",
    "Behavior:\n",
    "\n",
    "The agent reduces its distance to the target but overshoots and moves away again.\n",
    "\n",
    "The velocity components fluctuate, indicating poor control.\n",
    "\n",
    "Rewards:\n",
    "\n",
    "Rewards are consistently negative but improve slightly as the agent gets closer to the target.\n",
    "\n",
    "A large positive reward (9.90) is achieved at step 39, suggesting the agent briefly succeeded in docking.\n",
    "\n",
    "Episode 2 (Steps 1-36):\n",
    "Initial State: [-3.21, -1.29, -0.71, 0.23]\n",
    "\n",
    "The agent starts far from the target with high velocity.\n",
    "\n",
    "Behavior:\n",
    "\n",
    "The agent reduces its distance to the target but struggles to control its velocity.\n",
    "\n",
    "The velocity components fluctuate, and the agent does not stabilize its movement.\n",
    "\n",
    "Rewards:\n",
    "\n",
    "Rewards are consistently negative, with no significant improvement over time.\n",
    "\n",
    "A large positive reward (9.90) is achieved at step 36, suggesting the agent briefly succeeded in docking.\n",
    "\n",
    "4. Recommendations for Improvement\n",
    "A. Reward Function Tuning\n",
    "Add Intermediate Rewards:\n",
    "\n",
    "Provide rewards for reducing distance to the target and aligning velocity.\n",
    "\n",
    "Example: Reward the agent for getting closer to the target, not just for docking.\n",
    "\n",
    "Reduce Penalties:\n",
    "\n",
    "Make penalties less harsh to encourage exploration.\n",
    "\n",
    "Example: Reduce the fuel penalty or velocity penalty.\n",
    "\n",
    "B. Exploration Strategies\n",
    "Increase Exploration:\n",
    "\n",
    "Use a higher entropy coefficient or add noise to actions.\n",
    "\n",
    "Example: Increase the entropy coefficient to 0.1.\n",
    "\n",
    "Curriculum Learning:\n",
    "\n",
    "Start with simpler tasks (e.g., 2D docking) and gradually increase complexity.\n",
    "\n",
    "C. Algorithm Adjustments\n",
    "Adjust Learning Rate:\n",
    "\n",
    "Try a higher learning rate (e.g., 1e-3) to allow for faster policy updates.\n",
    "\n",
    "Increase Batch Size:\n",
    "\n",
    "Use a larger batch size (e.g., 512 or 1024) to stabilize training.\n",
    "\n",
    "D. Environment Modifications\n",
    "Simplify the Task:\n",
    "\n",
    "Start with a 2D version of the task and gradually increase complexity.\n",
    "\n",
    "Increase Episode Length:\n",
    "\n",
    "Allow more steps per episode to give the agent time to learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a6fee72-e6b0-4b8e-9626-3b9781b387ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the environment\n",
    "env = env_creator(Environments_enum.Docking_simple.value)\n",
    "state = env.reset()\n",
    "\n",
    "# Storage for trajectory data\n",
    "trajectory = [state[:2]]\n",
    "\n",
    "# Run the simulation\n",
    "for _ in range(env.max_steps):\n",
    "    action = np.random.uniform(-0.5, 0.5, 2)  # Random thrust action\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    trajectory.append(state[:2])  # Store position\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "# Convert to numpy array\n",
    "trajectory = np.array(trajectory)\n",
    "\n",
    "# Plot using matplotlib (Poliastro's plotting tools)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(trajectory[:, 0], trajectory[:, 1], label=\"Trajectory\", marker=\".\")\n",
    "ax.scatter(0, 0, color='red', marker=\"*\", s=100, label=\"Docking Port\")  # Target location\n",
    "ax.set_xlabel(\"X Position\")\n",
    "ax.set_ylabel(\"Y Position\")\n",
    "ax.set_title(\"Docking Simulation Trajectory\")\n",
    "ax.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00c0f1-76c7-4571-a005-f6a6f16e4f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
